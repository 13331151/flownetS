{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import scipy.io as sio   \n",
    "# gpu_id = 0\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "config = Config()\n",
    "config.input_height = 384\n",
    "config.input_width = 512\n",
    "config.input_channel = 6\n",
    "config.label_height = 384\n",
    "config.label_width = 512\n",
    "config.label_channel = 2\n",
    "config.batch_size = 4\n",
    "config.num_batches = 1200000\n",
    "config.learning_rate = 1e-5\n",
    "config.min_queue_examples = 20\n",
    "config.num_threads = 16\n",
    "config.EPS = 1e-8\n",
    "\n",
    "config.train_data_path = './train_tfrecord'\n",
    "config.test_data_path = './test_tfrecord'\n",
    "config.finetune_data_path = './finetune_tfrecord'\n",
    "config.isFinetune = False\n",
    "\n",
    "if config.isFinetune:\n",
    "    config.learning_rate *= .5\n",
    "\n",
    "config.save_dir ='./model/'\n",
    "config.log_dir = './log'\n",
    "config.result_dir = './result'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(config.log_dir)\n",
    "except:\n",
    "    if not config.isFinetune:\n",
    "        os.system(\"rm \"+config.log_dir+\"/*\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(config.save_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(config.result_dir)\n",
    "except:\n",
    "    os.system(\"rm \"+config.result_dir+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename, shuffle=False):\n",
    "    \"\"\" Return tensor to read from TFRecord \"\"\"\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'input' : tf.FixedLenFeature([], tf.string),\n",
    "                                           'label' : tf.FixedLenFeature([], tf.string)\n",
    "                                       })\n",
    "    \n",
    "    img = tf.decode_raw(features['input'], tf.uint8)\n",
    "    img = tf.reshape(img, [config.input_height, config.input_width, config.input_channel])\n",
    "    img = tf.to_float(img)\n",
    "    img = (img-127.)/255.\n",
    "    \n",
    "    dep = tf.decode_raw(features['label'], tf.float32)\n",
    "    dep = tf.reshape(dep, [config.label_height, config.label_width, config.label_channel])\n",
    "    dep = tf.to_float(dep)\n",
    "\n",
    "    \n",
    "    return _generate_image_and_label_batch(img, dep, config.min_queue_examples,\n",
    "                                           config.batch_size, shuffle = shuffle, num_threads = config.num_threads)\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle, num_threads):\n",
    "    num_preprocess_threads = num_threads\n",
    "    if shuffle:\n",
    "        images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads, capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, labels = tf.train.batch([image, label], batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads, capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leakyrelu(inputs, alpha=0.1):\n",
    "    return tf.maximum(alpha*inputs, inputs)\n",
    "\n",
    "def msra(ks, output_num):\n",
    "    return tf.truncated_normal_initializer(mean=0, stddev=np.sqrt(2./(ks[0]*ks[1]*output_num)))\n",
    "\n",
    "def conv(inputs, output_num, ks, stride, padding, scope, alpha=0.1):\n",
    "    initializer =  msra(ks, output_num)\n",
    "    conv_val = slim.conv2d(inputs, output_num, ks, stride, padding, scope=scope, activation_fn=None, weights_initializer=initializer)\n",
    "    conv_val = leakyrelu(conv_val, alpha=alpha)\n",
    "    return conv_val\n",
    "\n",
    "def deconv(inputs, output_num, ks, stride, padding, scope, alpha=0.1):\n",
    "    initializer = msra(ks, output_num)\n",
    "    conv_val = slim.conv2d_transpose(inputs, output_num, ks, stride, padding, scope=scope, activation_fn=None, weights_initializer=initializer)\n",
    "    conv_val = leakyrelu(conv_val, alpha=alpha)\n",
    "    return conv_val\n",
    "\n",
    "def epe_loss(predict, labels):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum((predict-labels)**2, axis=3)+config.EPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "#         \n",
    "        tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "        tfconfig.gpu_options.allow_growth=True\n",
    "        self.sess = tf.Session(config = tfconfig)\n",
    "        \n",
    "        self.inputs, self.labels = read_and_decode(config.train_data_path, shuffle=True)\n",
    "        self.labels_small_64 = tf.image.resize_images(self.labels, [config.input_height/64, config.input_width/64])\n",
    "        self.labels_small_32 = tf.image.resize_images(self.labels, [config.input_height/32, config.input_width/32])\n",
    "        self.labels_small_16 = tf.image.resize_images(self.labels, [config.input_height/16, config.input_width/16])\n",
    "        self.labels_small_8 = tf.image.resize_images(self.labels, [config.input_height/8, config.input_width/8])\n",
    "        self.labels_small_4 = tf.image.resize_images(self.labels, [config.input_height/4, config.input_width/4])\n",
    "        \n",
    "        self.summary_inputs_0 = tf.summary.image('train/input/image1', self.inputs[:, :, :, :3], max_outputs=1)\n",
    "        self.summary_inputs_1 = tf.summary.image('train/input/image2', self.inputs[:, :, :, 3:], max_outputs=1)\n",
    "        self.summary_labels = tf.summary.image('train/labels', self.labels[:, :, :, :1], max_outputs=1)\n",
    "        self.summary_labels_small_4 = tf.summary.image('train/labels_small_4', self.labels_small_4[:, :, :, :1], max_outputs=1)\n",
    "        \n",
    "        predict_64, predict_32, predict_16, predict_8, predict_4 = self.FLOWNETS(self.inputs)\n",
    "        self.summary_outputs = tf.summary.image('train/predict_4', predict_4[:, :, :, :1], max_outputs=1)\n",
    "        \n",
    "        self.predict_4 = predict_4\n",
    "        \n",
    "#         loss_train_4 = tf.losses.absolute_difference(predict_4, self.labels_small_4)\n",
    "#         loss_train_8 = tf.losses.absolute_difference(predict_8, self.labels_small_8)\n",
    "#         loss_train_16 = tf.losses.absolute_difference(predict_16, self.labels_small_16)\n",
    "#         loss_train_32 = tf.losses.absolute_difference(predict_32, self.labels_small_32)\n",
    "#         loss_train_64 = tf.losses.absolute_difference(predict_64, self.labels_small_64)\n",
    "\n",
    "        loss_train_4 = epe_loss(predict_4, self.labels_small_4)\n",
    "        loss_train_8 = epe_loss(predict_8, self.labels_small_8)\n",
    "        loss_train_16 = epe_loss(predict_16, self.labels_small_16)\n",
    "        loss_train_32 = epe_loss(predict_32, self.labels_small_32)\n",
    "        loss_train_64 = epe_loss(predict_64, self.labels_small_64)\n",
    "        \n",
    "        self.loss_train = 0.005*loss_train_4+0.01*loss_train_8+0.02*loss_train_16+0.08*loss_train_32+0.32*loss_train_64\n",
    "        self.summary_loss_train = tf.summary.scalar('train/loss', self.loss_train)\n",
    "        \n",
    "        update_vars = tf.global_variables()\n",
    "        print \"All variables \", [v.name for v in update_vars]\n",
    "        update_vars1 = []\n",
    "        update_vars2 = []\n",
    "        for var in update_vars:\n",
    "            if 'bias' in var.name or 'deconv' in var.name:\n",
    "                update_vars2.append(var)\n",
    "            else:\n",
    "                update_vars1.append(var)\n",
    "        print \"Learning rate = \", config.learning_rate, \" vars: \", [v.name for v in update_vars1]\n",
    "        print \"Learning rate = \", config.learning_rate*.1, \" vars: \", [v.name for v in update_vars2]\n",
    "        \n",
    "        \n",
    "        self.learning_rate_mult = tf.placeholder(tf.float32)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate_mult*config.learning_rate)\n",
    "        \n",
    "        grads1 = tf.gradients(self.loss_train, update_vars1)\n",
    "        grads2 = tf.gradients(self.loss_train, update_vars2)\n",
    "        grads2 = [v*.1 for v in grads2]\n",
    "        \n",
    "        train_op1 = opt.apply_gradients(zip(grads1, update_vars1))\n",
    "        train_op2 = opt.apply_gradients(zip(grads2, update_vars2))\n",
    "        self.opt = tf.group(train_op1, train_op2)\n",
    "        \n",
    "        self.merge_summary_train = tf.summary.merge([self.summary_loss_train])\n",
    "        \n",
    "    \n",
    "    \n",
    "            \n",
    "    def FLOWNETS(self, inputs, reuse = False):\n",
    "        with tf.variable_scope('FSRCNN') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "            \n",
    "            # shrink part\n",
    "            conv1 = conv(inputs, 64, [7, 7], 2, 'SAME', scope='conv1')\n",
    "            conv2 = conv(conv1, 128, [5, 5], 2, 'SAME', scope='conv2')\n",
    "            conv3 = conv(conv2, 256, [5, 5], 2, 'SAME', scope='conv3')\n",
    "            conv3_1 = conv(conv3, 256, [3, 3], 1, 'SAME', scope='conv3_1')\n",
    "            conv4 = conv(conv3_1, 512, [3, 3], 2, 'SAME', scope='conv4')\n",
    "            conv4_1 = conv(conv4, 512, [3, 3], 1, 'SAME', scope='conv4_1')\n",
    "            conv5 = conv(conv4_1, 512, [3, 3], 2, 'SAME', scope='conv5')\n",
    "            conv5_1 = conv(conv5, 512, [3, 3], 1, 'SAME', scope='conv5_1')\n",
    "            conv6 = conv(conv5_1, 1024, [3, 3], 2, 'SAME', scope='conv6')\n",
    "            conv6_1 = conv(conv6, 1024, [3, 3], 1, 'SAME', scope='conv6_1')\n",
    "            # 6 * 8 flow\n",
    "            predict6 = conv(conv6_1, 2, [3, 3], 1, 'SAME', scope='predict6')\n",
    "            # 12 * 16 flow\n",
    "            deconv5 = deconv(conv6_1, 512, [4, 4], 2, 'SAME', scope='deconv5')\n",
    "            deconvflow6 = deconv(predict6, 2, [4, 4], 2, 'SAME', scope='deconvflow6')\n",
    "            concat5 = tf.concat([deconv5, conv5_1, deconvflow6], 3, name='concat5')\n",
    "            predict5 = conv(concat5, 2, [5, 5], 1, 'SAME', scope='predict5')\n",
    "            # 24 * 32 flow\n",
    "            deconv4 = deconv(concat5, 256, [5, 5], 2, 'SAME', scope='deconv4')\n",
    "            deconvflow5 = deconv(predict5, 2, [5, 5], 2, 'SAME', scope='deconvflow5')\n",
    "            concat4 = tf.concat([deconv4, conv4_1, deconvflow5], 3, name='concat4')\n",
    "            predict4 = conv(concat4, 2, [5, 5], 1, 'SAME', scope='predict4')\n",
    "            # 48 * 64 flow\n",
    "            deconv3 = deconv(concat4, 128, [5, 5], 2, 'SAME', scope='deconv3')\n",
    "            deconvflow4 = deconv(predict4, 2, [5, 5], 2, 'SAME', scope='deconvflow4')\n",
    "            concat3 = tf.concat([deconv3, conv3_1, deconvflow4], 3, name='concat3')\n",
    "            predict3 = conv(concat3, 2, [5, 5], 1, 'SAME', scope='predict3')\n",
    "            # 96 * 128 flow\n",
    "            deconv2 = deconv(concat3, 64, [5, 5], 2, 'SAME', scope='deconv2')\n",
    "            deconvflow3 = deconv(predict3, 2, [5, 5], 2, 'SAME', scope='deconvflow3')\n",
    "            concat2 = tf.concat([deconv2, conv2, deconvflow3], 3, name='concat2')\n",
    "            predict2 = conv(concat2, 2, [5, 5], 1, 'SAME', scope='predict2')\n",
    "\n",
    "            return predict6, predict5, predict4, predict3, predict2\n",
    "    \n",
    "    def test(self):\n",
    "        writer = tf.summary.FileWriter(config.log_dir, tf.get_default_graph())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        self.sess.run(init_op)\n",
    "        \n",
    "        ckpt = tf.train.get_checkpoint_state(config.save_dir)\n",
    "        saver.restore(self.sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=self.sess, coord=coord)\n",
    "        \n",
    "        time_ = time.clock()\n",
    "        \n",
    "        input_data = np.zeros((config.batch_size, config.input_height, config.input_width, config.input_channel))\n",
    "        input_label = np.zeros((config.batch_size, config.label_height, config.label_width, config.label_channel))\n",
    "    \n",
    "        \n",
    "        learning_rate_mult = 1.\n",
    "        \n",
    "        \n",
    "        predict_ = self.sess.run(self.predict_4[:, :, :, 0], feed_dict={self.inputs:input_data, self.labels:input_label, self.learning_rate_mult:learning_rate_mult})\n",
    "        \n",
    "        for i in xrange(predict_.shape[0]):\n",
    "            cv2.imwrite('./result/test/'+str(i)+'_pred.jpg', np.clip(predict_*20, 0, 255).astype(uint8))\n",
    "                \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "        writer.close()\n",
    "\n",
    "  \n",
    "    def train(self):\n",
    "        writer = tf.summary.FileWriter(config.log_dir, tf.get_default_graph())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        self.sess.run(init_op)\n",
    "        \n",
    "        if config.isFinetune:\n",
    "            ckpt = tf.train.get_checkpoint_state(config.save_dir)\n",
    "            saver.restore(self.sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=self.sess, coord=coord)\n",
    "        \n",
    "        time_ = time.clock()\n",
    "        \n",
    "#         input_data = np.zeros((config.batch_size, config.input_height, config.input_width, config.input_channel))\n",
    "#         input_label = np.zeros((config.batch_size, config.label_height, config.label_width, config.label_channel))\n",
    "    \n",
    "        \n",
    "        learning_rate_mult = 1.\n",
    "        for t in range(0, config.num_batches):\n",
    "            if t % 100 == 0:\n",
    "                print \"iter \", t, \" time \", time.clock()-time_\n",
    "                time_ = time.clock()\n",
    "            \n",
    "            if t > 2000000 and (t % 1000000 == 0):\n",
    "                learning_rate_mult/=2\n",
    "\n",
    "#             _, merge_summary = \\\n",
    "#                 self.sess.run([self.opt, self.merge_summary_train], feed_dict={self.inputs:input_data, self.labels:input_label, self.learning_rate:config.learning_rate})\n",
    "            if t % 1000 == 0:\n",
    "                _, merge_summary, loss, label_, predict_ = \\\n",
    "                   self.sess.run([self.opt, self.merge_summary_train, self.loss_train, self.labels_small_4[0, :, :, 0], self.predict_4[0, :, :, 0]], feed_dict={self.learning_rate_mult:learning_rate_mult})\n",
    "                cv2.imwrite('./result/'+str(t)+'_label.jpg', np.clip(label_*20, 0, 255).astype(uint8))\n",
    "                cv2.imwrite('./result/'+str(t)+'_pred.jpg', np.clip(predict_*20, 0, 255).astype(uint8))\n",
    "            else:\n",
    "                _, merge_summary, loss = \\\n",
    "                    self.sess.run([self.opt, self.summary_loss_train, self.loss_train], feed_dict={self.learning_rate_mult:learning_rate_mult})\n",
    "            \n",
    "            if t%100 == 0:\n",
    "                print \"train loss is: \", loss\n",
    "                writer.add_summary(merge_summary, t)\n",
    "                \n",
    "           \n",
    "            if t%10000 == 0:\n",
    "                saver.save(self.sess, config.save_dir, global_step=t)\n",
    "                \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "        writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All variables  [u'FSRCNN/conv1/weights:0', u'FSRCNN/conv1/biases:0', u'FSRCNN/conv2/weights:0', u'FSRCNN/conv2/biases:0', u'FSRCNN/conv3/weights:0', u'FSRCNN/conv3/biases:0', u'FSRCNN/conv3_1/weights:0', u'FSRCNN/conv3_1/biases:0', u'FSRCNN/conv4/weights:0', u'FSRCNN/conv4/biases:0', u'FSRCNN/conv4_1/weights:0', u'FSRCNN/conv4_1/biases:0', u'FSRCNN/conv5/weights:0', u'FSRCNN/conv5/biases:0', u'FSRCNN/conv5_1/weights:0', u'FSRCNN/conv5_1/biases:0', u'FSRCNN/conv6/weights:0', u'FSRCNN/conv6/biases:0', u'FSRCNN/conv6_1/weights:0', u'FSRCNN/conv6_1/biases:0', u'FSRCNN/predict6/weights:0', u'FSRCNN/predict6/biases:0', u'FSRCNN/deconv5/weights:0', u'FSRCNN/deconv5/biases:0', u'FSRCNN/deconvflow6/weights:0', u'FSRCNN/deconvflow6/biases:0', u'FSRCNN/predict5/weights:0', u'FSRCNN/predict5/biases:0', u'FSRCNN/deconv4/weights:0', u'FSRCNN/deconv4/biases:0', u'FSRCNN/deconvflow5/weights:0', u'FSRCNN/deconvflow5/biases:0', u'FSRCNN/predict4/weights:0', u'FSRCNN/predict4/biases:0', u'FSRCNN/deconv3/weights:0', u'FSRCNN/deconv3/biases:0', u'FSRCNN/deconvflow4/weights:0', u'FSRCNN/deconvflow4/biases:0', u'FSRCNN/predict3/weights:0', u'FSRCNN/predict3/biases:0', u'FSRCNN/deconv2/weights:0', u'FSRCNN/deconv2/biases:0', u'FSRCNN/deconvflow3/weights:0', u'FSRCNN/deconvflow3/biases:0', u'FSRCNN/predict2/weights:0', u'FSRCNN/predict2/biases:0']\n",
      "Learning rate =  1e-05  vars:  [u'FSRCNN/conv1/weights:0', u'FSRCNN/conv2/weights:0', u'FSRCNN/conv3/weights:0', u'FSRCNN/conv3_1/weights:0', u'FSRCNN/conv4/weights:0', u'FSRCNN/conv4_1/weights:0', u'FSRCNN/conv5/weights:0', u'FSRCNN/conv5_1/weights:0', u'FSRCNN/conv6/weights:0', u'FSRCNN/conv6_1/weights:0', u'FSRCNN/predict6/weights:0', u'FSRCNN/predict5/weights:0', u'FSRCNN/predict4/weights:0', u'FSRCNN/predict3/weights:0', u'FSRCNN/predict2/weights:0']\n",
      "Learning rate =  1e-06  vars:  [u'FSRCNN/conv1/biases:0', u'FSRCNN/conv2/biases:0', u'FSRCNN/conv3/biases:0', u'FSRCNN/conv3_1/biases:0', u'FSRCNN/conv4/biases:0', u'FSRCNN/conv4_1/biases:0', u'FSRCNN/conv5/biases:0', u'FSRCNN/conv5_1/biases:0', u'FSRCNN/conv6/biases:0', u'FSRCNN/conv6_1/biases:0', u'FSRCNN/predict6/biases:0', u'FSRCNN/deconv5/weights:0', u'FSRCNN/deconv5/biases:0', u'FSRCNN/deconvflow6/weights:0', u'FSRCNN/deconvflow6/biases:0', u'FSRCNN/predict5/biases:0', u'FSRCNN/deconv4/weights:0', u'FSRCNN/deconv4/biases:0', u'FSRCNN/deconvflow5/weights:0', u'FSRCNN/deconvflow5/biases:0', u'FSRCNN/predict4/biases:0', u'FSRCNN/deconv3/weights:0', u'FSRCNN/deconv3/biases:0', u'FSRCNN/deconvflow4/weights:0', u'FSRCNN/deconvflow4/biases:0', u'FSRCNN/predict3/biases:0', u'FSRCNN/deconv2/weights:0', u'FSRCNN/deconv2/biases:0', u'FSRCNN/deconvflow3/weights:0', u'FSRCNN/deconvflow3/biases:0', u'FSRCNN/predict2/biases:0']\n",
      "iter  0  time  0.025974\n",
      "train loss is:  2.11922\n",
      "iter  100  time  126.394148\n",
      "train loss is:  6.61814\n",
      "iter  200  time  120.887839\n",
      "train loss is:  5.22337\n",
      "iter  300  time  122.050164\n",
      "train loss is:  3.09412\n",
      "iter  400  time  119.29083\n",
      "train loss is:  2.05624\n",
      "iter  500  time  119.684023\n",
      "train loss is:  1.28968\n",
      "iter  600  time  120.969864\n",
      "train loss is:  1.65296\n",
      "iter  700  time  118.815034\n",
      "train loss is:  1.0311\n",
      "iter  800  time  121.533755\n",
      "train loss is:  1.60568\n",
      "iter  900  time  128.136591\n",
      "train loss is:  1.05756\n",
      "iter  1000  time  123.405441\n",
      "train loss is:  0.929369\n",
      "iter  1100  time  129.882392\n",
      "train loss is:  0.961011\n",
      "iter  1200  time  123.958838\n",
      "train loss is:  0.798527\n",
      "iter  1300  time  125.58052\n",
      "train loss is:  1.21061\n",
      "iter  1400  time  122.631695\n",
      "train loss is:  0.769869\n",
      "iter  1500  time  120.776219\n",
      "train loss is:  1.29363\n",
      "iter  1600  time  122.942856\n",
      "train loss is:  1.19567\n",
      "iter  1700  time  119.789974\n",
      "train loss is:  0.666697\n",
      "iter  1800  time  126.054241\n",
      "train loss is:  0.674904\n",
      "iter  1900  time  122.419943\n",
      "train loss is:  1.54309\n",
      "iter  2000  time  121.698338\n",
      "train loss is:  0.51926\n",
      "iter  2100  time  121.236902\n",
      "train loss is:  0.692253\n",
      "iter  2200  time  124.880113\n",
      "train loss is:  0.53315\n",
      "iter  2300  time  124.203921\n",
      "train loss is:  1.1314\n",
      "iter  2400  time  119.155693\n",
      "train loss is:  1.00052\n",
      "iter  2500  time  120.796901\n",
      "train loss is:  0.532956\n",
      "iter  2600  time  122.095413\n",
      "train loss is:  0.8483\n",
      "iter  2700  time  119.819265\n",
      "train loss is:  0.635343\n",
      "iter  2800  time  123.754792\n",
      "train loss is:  0.901404\n",
      "iter  2900  time  126.559894\n",
      "train loss is:  0.540923\n",
      "iter  3000  time  131.873485\n",
      "train loss is:  1.15316\n",
      "iter  3100  time  127.248288\n",
      "train loss is:  0.386359\n",
      "iter  3200  time  121.625414\n",
      "train loss is:  0.503387\n",
      "iter  3300  time  121.805664\n",
      "train loss is:  0.415281\n",
      "iter  3400  time  119.43649\n",
      "train loss is:  0.521571\n",
      "iter  3500  time  121.983128\n",
      "train loss is:  0.800164\n",
      "iter  3600  time  118.692741\n",
      "train loss is:  0.388457\n",
      "iter  3700  time  125.191168\n",
      "train loss is:  0.972001\n",
      "iter  3800  time  118.915885\n",
      "train loss is:  0.408218\n",
      "iter  3900  time  119.852126\n",
      "train loss is:  0.609547\n",
      "iter  4000  time  123.727671\n",
      "train loss is:  0.467098\n",
      "iter  4100  time  124.141343\n",
      "train loss is:  0.629936\n",
      "iter  4200  time  122.257225\n",
      "train loss is:  0.365435\n",
      "iter  4300  time  120.567332\n",
      "train loss is:  0.400316\n",
      "iter  4400  time  124.411609\n",
      "train loss is:  0.335607\n",
      "iter  4500  time  124.984422\n",
      "train loss is:  0.823711\n",
      "iter  4600  time  124.520594\n",
      "train loss is:  1.01152\n",
      "iter  4700  time  124.809283\n",
      "train loss is:  0.70232\n",
      "iter  4800  time  122.930732\n",
      "train loss is:  0.702561\n",
      "iter  4900  time  124.120759\n",
      "train loss is:  0.895376\n",
      "iter  5000  time  127.970167\n",
      "train loss is:  0.692341\n",
      "iter  5100  time  122.786508\n",
      "train loss is:  0.293475\n",
      "iter  5200  time  117.616904\n",
      "train loss is:  0.828623\n",
      "iter  5300  time  123.837781\n",
      "train loss is:  0.303099\n",
      "iter  5400  time  109.232856\n",
      "train loss is:  0.438493\n",
      "iter  5500  time  121.045167\n",
      "train loss is:  0.304946\n",
      "iter  5600  time  109.603671\n",
      "train loss is:  0.504845\n",
      "iter  5700  time  112.197651\n",
      "train loss is:  0.529452\n",
      "iter  5800  time  113.497729\n",
      "train loss is:  0.452867\n",
      "iter  5900  time  111.458686\n",
      "train loss is:  0.387792\n",
      "iter  6000  time  116.830327\n",
      "train loss is:  0.396622\n",
      "iter  6100  time  113.278925\n",
      "train loss is:  0.435565\n",
      "iter  6200  time  112.189538\n",
      "train loss is:  0.435061\n",
      "iter  6300  time  114.446202\n",
      "train loss is:  0.425934\n",
      "iter  6400  time  113.39236\n",
      "train loss is:  0.267866\n",
      "iter  6500  time  109.985647\n",
      "train loss is:  0.434573\n",
      "iter  6600  time  106.426637\n",
      "train loss is:  0.34668\n",
      "iter  6700  time  111.14471\n",
      "train loss is:  0.43599\n",
      "iter  6800  time  111.779462\n",
      "train loss is:  0.345035\n",
      "iter  6900  time  113.674082\n",
      "train loss is:  0.467314\n",
      "iter  7000  time  115.425462\n",
      "train loss is:  0.404432\n",
      "iter  7100  time  119.585515\n",
      "train loss is:  0.391647\n",
      "iter  7200  time  114.958051\n",
      "train loss is:  0.432921\n",
      "iter  7300  time  113.077431\n",
      "train loss is:  0.442929\n",
      "iter  7400  time  115.386495\n",
      "train loss is:  0.360829\n",
      "iter  7500  time  116.252733\n",
      "train loss is:  0.479811\n",
      "iter  7600  time  115.658019\n",
      "train loss is:  0.243691\n",
      "iter  7700  time  113.287196\n",
      "train loss is:  0.372514\n",
      "iter  7800  time  112.637893\n",
      "train loss is:  0.374095\n",
      "iter  7900  time  119.086772\n",
      "train loss is:  0.322546\n",
      "iter  8000  time  109.2588\n",
      "train loss is:  0.378044\n",
      "iter  8100  time  111.111667\n",
      "train loss is:  0.334944\n",
      "iter  8200  time  109.026443\n",
      "train loss is:  0.305163\n",
      "iter  8300  time  110.799684\n",
      "train loss is:  0.272567\n",
      "iter  8400  time  118.890384\n",
      "train loss is:  0.390758\n",
      "iter  8500  time  104.975259\n",
      "train loss is:  0.379547\n",
      "iter  8600  time  105.110009\n",
      "train loss is:  0.29054\n",
      "iter  8700  time  110.869852\n",
      "train loss is:  0.459363\n",
      "iter  8800  time  112.670279\n",
      "train loss is:  0.297731\n",
      "iter  8900  time  109.982018\n",
      "train loss is:  0.353588\n",
      "iter  9000  time  108.30815\n",
      "train loss is:  0.295903\n",
      "iter  9100  time  113.992718\n",
      "train loss is:  0.31707\n",
      "iter  9200  time  109.894764\n",
      "train loss is:  0.314956\n",
      "iter  9300  time  111.871721\n",
      "train loss is:  0.25593\n",
      "iter  9400  time  109.597982\n",
      "train loss is:  0.333988\n",
      "iter  9500  time  112.772887\n",
      "train loss is:  0.436537\n",
      "iter  9600  time  113.356026\n",
      "train loss is:  0.315719\n",
      "iter  9700  time  115.556061\n",
      "train loss is:  0.315021\n",
      "iter  9800  time  117.412682\n",
      "train loss is:  0.351666\n",
      "iter  9900  time  111.403519\n",
      "train loss is:  0.289415\n",
      "iter  10000  time  117.880608\n",
      "train loss is:  0.294386\n",
      "iter  10100  time  124.622917\n",
      "train loss is:  0.266321\n",
      "iter  10200  time  112.494348\n",
      "train loss is:  0.283708\n",
      "iter  10300  time  102.132048\n",
      "train loss is:  0.364192\n",
      "iter  10400  time  111.045632\n",
      "train loss is:  0.278406\n",
      "iter  10500  time  120.680402\n",
      "train loss is:  0.262703\n",
      "iter  10600  time  108.646529\n",
      "train loss is:  0.247104\n",
      "iter  10700  time  116.014505\n",
      "train loss is:  0.334847\n",
      "iter  10800  time  116.057597\n",
      "train loss is:  0.32474\n",
      "iter  10900  time  110.782376\n",
      "train loss is:  0.2937\n",
      "iter  11000  time  115.896342\n",
      "train loss is:  0.202418\n",
      "iter  11100  time  115.216218\n",
      "train loss is:  0.324859\n",
      "iter  11200  time  108.22714\n",
      "train loss is:  0.38179\n",
      "iter  11300  time  115.123844\n",
      "train loss is:  0.293989\n",
      "iter  11400  time  107.767011\n",
      "train loss is:  0.275426\n",
      "iter  11500  time  108.071767\n",
      "train loss is:  0.229012\n",
      "iter  11600  time  115.924943\n",
      "train loss is:  0.322777\n",
      "iter  11700  time  114.784469\n",
      "train loss is:  0.236372\n",
      "iter  11800  time  117.996126\n",
      "train loss is:  0.285682\n",
      "iter  11900  time  118.306907\n",
      "train loss is:  0.337943\n",
      "iter  12000  time  114.428464\n",
      "train loss is:  0.217748\n",
      "iter  12100  time  116.931144\n",
      "train loss is:  0.176793\n",
      "iter  12200  time  119.932449\n",
      "train loss is:  0.248183\n",
      "iter  12300  time  113.579039\n",
      "train loss is:  0.198833\n",
      "iter  12400  time  116.173427\n",
      "train loss is:  0.346585\n",
      "iter  12500  time  109.939492\n",
      "train loss is:  0.291888\n",
      "iter  12600  time  116.694544\n",
      "train loss is:  0.259513\n",
      "iter  12700  time  117.140285\n",
      "train loss is:  0.268551\n",
      "iter  12800  time  120.088531\n",
      "train loss is:  0.399704\n",
      "iter  12900  time  108.520612\n",
      "train loss is:  0.257543\n",
      "iter  13000  time  115.559321\n",
      "train loss is:  0.217669\n",
      "iter  13100  time  127.186375\n",
      "train loss is:  0.288214\n",
      "iter  13200  time  115.505935\n",
      "train loss is:  0.270085\n",
      "iter  13300  time  110.064952\n",
      "train loss is:  0.284321\n",
      "iter  13400  time  118.382675\n",
      "train loss is:  0.163611\n",
      "iter  13500  time  119.960483\n",
      "train loss is:  0.311059\n",
      "iter  13600  time  118.141292\n",
      "train loss is:  0.203561\n",
      "iter  13700  time  115.297679\n",
      "train loss is:  0.451652\n",
      "iter  13800  time  116.132446\n",
      "train loss is:  0.264393\n",
      "iter  13900  time  114.299986\n",
      "train loss is:  0.263806\n",
      "iter  14000  time  115.130014\n",
      "train loss is:  0.25715\n",
      "iter  14100  time  113.513453\n",
      "train loss is:  0.257442\n",
      "iter  14200  time  119.417905\n",
      "train loss is:  0.384177\n",
      "iter  14300  time  119.86202\n",
      "train loss is:  0.217064\n",
      "iter  14400  time  117.057563\n",
      "train loss is:  0.249043\n",
      "iter  14500  time  113.804145\n",
      "train loss is:  0.451446\n",
      "iter  14600  time  111.627737\n",
      "train loss is:  0.423561\n",
      "iter  14700  time  118.641928\n",
      "train loss is:  0.206733\n",
      "iter  14800  time  117.19089\n",
      "train loss is:  0.232846\n",
      "iter  14900  time  109.539591\n",
      "train loss is:  0.334563\n",
      "iter  15000  time  117.433559\n",
      "train loss is:  0.302139\n",
      "iter  15100  time  112.334414\n",
      "train loss is:  0.276527\n",
      "iter  15200  time  116.8027\n",
      "train loss is:  0.282775\n",
      "iter  15300  time  113.576707\n",
      "train loss is:  0.214069\n",
      "iter  15400  time  109.438807\n",
      "train loss is:  0.256597\n",
      "iter  15500  time  108.241816\n",
      "train loss is:  0.23318\n",
      "iter  15600  time  115.230374\n",
      "train loss is:  0.246182\n",
      "iter  15700  time  115.064384\n",
      "train loss is:  0.259192\n",
      "iter  15800  time  114.833978\n",
      "train loss is:  0.245322\n",
      "iter  15900  time  109.622297\n",
      "train loss is:  0.279008\n",
      "iter  16000  time  115.121139\n",
      "train loss is:  0.163492\n",
      "iter  16100  time  113.238636\n",
      "train loss is:  0.209169\n",
      "iter  16200  time  121.342035\n",
      "train loss is:  0.245244\n",
      "iter  16300  time  106.835268\n",
      "train loss is:  0.177384\n",
      "iter  16400  time  113.743686\n",
      "train loss is:  0.235371\n",
      "iter  16500  time  111.689987\n",
      "train loss is:  0.245364\n",
      "iter  16600  time  110.631676\n",
      "train loss is:  0.333561\n",
      "iter  16700  time  112.354407\n",
      "train loss is:  0.273982\n",
      "iter  16800  time  112.436012\n",
      "train loss is:  0.321248\n",
      "iter  16900  time  121.529201\n",
      "train loss is:  0.193802\n",
      "iter  17000  time  113.15156\n",
      "train loss is:  0.219133\n",
      "iter  17100  time  122.363806\n",
      "train loss is:  0.193931\n",
      "iter  17200  time  111.076756\n",
      "train loss is:  0.242825\n",
      "iter  17300  time  112.68327\n",
      "train loss is:  0.260316\n",
      "iter  17400  time  113.398892\n",
      "train loss is:  0.208274\n",
      "iter  17500  time  113.228345\n",
      "train loss is:  0.20948\n",
      "iter  17600  time  115.578316\n",
      "train loss is:  0.430605\n",
      "iter  17700  time  111.576395\n",
      "train loss is:  0.273547\n",
      "iter  17800  time  113.393958\n",
      "train loss is:  0.262044\n",
      "iter  17900  time  116.453138\n",
      "train loss is:  0.170754\n",
      "iter  18000  time  111.63052\n",
      "train loss is:  0.244171\n",
      "iter  18100  time  106.041727\n",
      "train loss is:  0.190242\n",
      "iter  18200  time  114.470237\n",
      "train loss is:  0.180769\n",
      "iter  18300  time  111.712305\n",
      "train loss is:  0.297337\n",
      "iter  18400  time  117.905964\n",
      "train loss is:  0.305599\n",
      "iter  18500  time  114.811315\n",
      "train loss is:  0.199256\n",
      "iter  18600  time  108.497952\n",
      "train loss is:  0.213972\n",
      "iter  18700  time  112.86401\n",
      "train loss is:  0.14155\n",
      "iter  18800  time  114.26123\n",
      "train loss is:  0.249072\n",
      "iter  18900  time  116.533145\n",
      "train loss is:  0.186213\n",
      "iter  19000  time  107.147488\n",
      "train loss is:  0.167176\n",
      "iter  19100  time  111.485761\n",
      "train loss is:  0.211135\n",
      "iter  19200  time  116.241245\n",
      "train loss is:  0.24661\n",
      "iter  19300  time  110.547804\n",
      "train loss is:  0.258914\n",
      "iter  19400  time  112.688178\n",
      "train loss is:  0.166643\n",
      "iter  19500  time  118.513351\n",
      "train loss is:  0.204648\n",
      "iter  19600  time  107.425887\n",
      "train loss is:  0.201916\n",
      "iter  19700  time  109.401962\n",
      "train loss is:  0.224386\n",
      "iter  19800  time  119.35272\n",
      "train loss is:  0.263038\n",
      "iter  19900  time  111.397609\n",
      "train loss is:  0.276222\n",
      "iter  20000  time  116.041943\n",
      "train loss is:  0.14962\n",
      "iter  20100  time  110.698683\n",
      "train loss is:  0.140496\n",
      "iter  20200  time  114.745666\n",
      "train loss is:  0.12755\n",
      "iter  20300  time  108.648272\n",
      "train loss is:  0.20932\n",
      "iter  20400  time  108.251856\n",
      "train loss is:  0.43164\n",
      "iter  20500  time  119.407419\n",
      "train loss is:  0.160281\n",
      "iter  20600  time  117.714385\n",
      "train loss is:  0.241294\n",
      "iter  20700  time  107.463242\n",
      "train loss is:  0.176219\n",
      "iter  20800  time  112.358619\n",
      "train loss is:  0.165226\n",
      "iter  20900  time  109.556783\n",
      "train loss is:  0.349881\n",
      "iter  21000  time  111.221\n",
      "train loss is:  0.32442\n",
      "iter  21100  time  116.693481\n",
      "train loss is:  0.202679\n",
      "iter  21200  time  113.21402\n",
      "train loss is:  0.153453\n",
      "iter  21300  time  105.923526\n",
      "train loss is:  0.211522\n",
      "iter  21400  time  104.50519\n",
      "train loss is:  0.302863\n",
      "iter  21500  time  120.847716\n",
      "train loss is:  0.164223\n",
      "iter  21600  time  110.735401\n",
      "train loss is:  0.188031\n",
      "iter  21700  time  112.193681\n",
      "train loss is:  0.242763\n",
      "iter  21800  time  114.90432\n",
      "train loss is:  0.182281\n",
      "iter  21900  time  116.282617\n",
      "train loss is:  0.191595\n",
      "iter  22000  time  108.532337\n",
      "train loss is:  0.19996\n",
      "iter  22100  time  119.291197\n",
      "train loss is:  0.158919\n",
      "iter  22200  time  110.718468\n",
      "train loss is:  0.216512\n",
      "iter  22300  time  113.4044\n",
      "train loss is:  0.185235\n",
      "iter  22400  time  111.557555\n",
      "train loss is:  0.161633\n",
      "iter  22500  time  111.843777\n",
      "train loss is:  0.184451\n",
      "iter  22600  time  115.373596\n",
      "train loss is:  0.19695\n",
      "iter  22700  time  102.103511\n",
      "train loss is:  0.23771\n",
      "iter  22800  time  111.699013\n",
      "train loss is:  0.299618\n",
      "iter  22900  time  107.3713\n",
      "train loss is:  0.147925\n",
      "iter  23000  time  104.717755\n",
      "train loss is:  0.211912\n",
      "iter  23100  time  110.32027\n",
      "train loss is:  0.178047\n",
      "iter  23200  time  113.287282\n",
      "train loss is:  0.141619\n",
      "iter  23300  time  114.686666\n",
      "train loss is:  0.288951\n",
      "iter  23400  time  112.945075\n",
      "train loss is:  0.300475\n",
      "iter  23500  time  108.057551\n",
      "train loss is:  0.304737\n",
      "iter  23600  time  101.841501\n",
      "train loss is:  0.269377\n",
      "iter  23700  time  110.229145\n",
      "train loss is:  0.249254\n",
      "iter  23800  time  115.036837\n",
      "train loss is:  0.166346\n",
      "iter  23900  time  114.068631\n",
      "train loss is:  0.239336\n",
      "iter  24000  time  116.648885\n",
      "train loss is:  0.285582\n",
      "iter  24100  time  112.675925\n",
      "train loss is:  0.197138\n",
      "iter  24200  time  109.62167\n",
      "train loss is:  0.201884\n",
      "iter  24300  time  105.510688\n",
      "train loss is:  0.176768\n",
      "iter  24400  time  106.752711\n",
      "train loss is:  0.299499\n",
      "iter  24500  time  112.037031\n",
      "train loss is:  0.184477\n",
      "iter  24600  time  113.763856\n",
      "train loss is:  0.170187\n",
      "iter  24700  time  117.17853\n",
      "train loss is:  0.238904\n",
      "iter  24800  time  110.09767\n",
      "train loss is:  0.228059\n",
      "iter  24900  time  117.977428\n",
      "train loss is:  0.288947\n",
      "iter  25000  time  111.189512\n",
      "train loss is:  0.15903\n",
      "iter  25100  time  115.553484\n",
      "train loss is:  0.164489\n",
      "iter  25200  time  117.346313\n",
      "train loss is:  0.169651\n",
      "iter  25300  time  112.998224\n",
      "train loss is:  0.259727\n",
      "iter  25400  time  104.211648\n",
      "train loss is:  0.18708\n",
      "iter  25500  time  98.935461\n",
      "train loss is:  0.191489\n",
      "iter  25600  time  100.137968\n",
      "train loss is:  0.206951\n",
      "iter  25700  time  97.959984\n",
      "train loss is:  0.14896\n",
      "iter  25800  time  102.083367\n",
      "train loss is:  0.178928\n",
      "iter  25900  time  102.627357\n",
      "train loss is:  0.15121\n",
      "iter  26000  time  106.739949\n",
      "train loss is:  0.173383\n",
      "iter  26100  time  105.405926\n",
      "train loss is:  0.251259\n",
      "iter  26200  time  108.016796\n",
      "train loss is:  0.192945\n",
      "iter  26300  time  103.778375\n",
      "train loss is:  0.142375\n",
      "iter  26400  time  101.889474\n",
      "train loss is:  0.178282\n",
      "iter  26500  time  102.596199\n",
      "train loss is:  0.186048\n",
      "iter  26600  time  104.201117\n",
      "train loss is:  0.175028\n",
      "iter  26700  time  109.123534\n",
      "train loss is:  0.226874\n",
      "iter  26800  time  111.23501\n",
      "train loss is:  0.243124\n",
      "iter  26900  time  109.599319\n",
      "train loss is:  0.192066\n",
      "iter  27000  time  112.273677\n",
      "train loss is:  0.157751\n",
      "iter  27100  time  107.358256\n",
      "train loss is:  0.136809\n",
      "iter  27200  time  99.863639\n",
      "train loss is:  0.159545\n",
      "iter  27300  time  114.303656\n",
      "train loss is:  0.170087\n",
      "iter  27400  time  105.124565\n",
      "train loss is:  0.26307\n",
      "iter  27500  time  113.934351\n",
      "train loss is:  0.184564\n",
      "iter  27600  time  106.695475\n",
      "train loss is:  0.181231\n",
      "iter  27700  time  106.91109\n",
      "train loss is:  0.208798\n",
      "iter  27800  time  111.704933\n",
      "train loss is:  0.195074\n",
      "iter  27900  time  123.333164\n",
      "train loss is:  0.22864\n",
      "iter  28000  time  126.46405\n",
      "train loss is:  0.181899\n",
      "iter  28100  time  129.817999\n",
      "train loss is:  0.188814\n",
      "iter  28200  time  126.590604\n",
      "train loss is:  0.25126\n",
      "iter  28300  time  126.711463\n",
      "train loss is:  0.202352\n",
      "iter  28400  time  128.269663\n",
      "train loss is:  0.213547\n",
      "iter  28500  time  120.767233\n",
      "train loss is:  0.201626\n",
      "iter  28600  time  121.200098\n",
      "train loss is:  0.16751\n",
      "iter  28700  time  123.253977\n",
      "train loss is:  0.123881\n",
      "iter  28800  time  124.311348\n",
      "train loss is:  0.167395\n",
      "iter  28900  time  120.271417\n",
      "train loss is:  0.145534\n",
      "iter  29000  time  124.586038\n",
      "train loss is:  0.176071\n",
      "iter  29100  time  126.778038\n",
      "train loss is:  0.170114\n",
      "iter  29200  time  124.281718\n",
      "train loss is:  0.149657\n",
      "iter  29300  time  122.479009\n",
      "train loss is:  0.179329\n",
      "iter  29400  time  125.093188\n",
      "train loss is:  0.167687\n",
      "iter  29500  time  121.268202\n",
      "train loss is:  0.337875\n",
      "iter  29600  time  123.553915\n",
      "train loss is:  0.192412\n",
      "iter  29700  time  131.695881\n",
      "train loss is:  0.175759\n",
      "iter  29800  time  122.371314\n",
      "train loss is:  0.182683\n",
      "iter  29900  time  124.908802\n",
      "train loss is:  0.149048\n",
      "iter  30000  time  123.775497\n",
      "train loss is:  0.170421\n",
      "iter  30100  time  137.374073\n",
      "train loss is:  0.230103\n",
      "iter  30200  time  126.203668\n",
      "train loss is:  0.183788\n",
      "iter  30300  time  122.571629\n",
      "train loss is:  0.548631\n",
      "iter  30400  time  122.025693\n",
      "train loss is:  0.123206\n",
      "iter  30500  time  121.164062\n",
      "train loss is:  0.147152\n",
      "iter  30600  time  125.376403\n",
      "train loss is:  0.138736\n",
      "iter  30700  time  117.38427\n",
      "train loss is:  0.141434\n",
      "iter  30800  time  129.06954\n",
      "train loss is:  0.124894\n",
      "iter  30900  time  119.25781\n",
      "train loss is:  0.191171\n",
      "iter  31000  time  106.978346\n",
      "train loss is:  0.162459\n",
      "iter  31100  time  108.102931\n",
      "train loss is:  0.212598\n",
      "iter  31200  time  105.205073\n",
      "train loss is:  0.285015\n",
      "iter  31300  time  103.364852\n",
      "train loss is:  0.200642\n",
      "iter  31400  time  101.772951\n",
      "train loss is:  0.154338\n",
      "iter  31500  time  103.327231\n",
      "train loss is:  0.180782\n",
      "iter  31600  time  104.077978\n",
      "train loss is:  0.0973643\n",
      "iter  31700  time  110.15152\n",
      "train loss is:  0.138237\n",
      "iter  31800  time  103.561172\n",
      "train loss is:  0.169591\n",
      "iter  31900  time  107.105819\n",
      "train loss is:  0.171462\n",
      "iter  32000  time  111.77388\n",
      "train loss is:  0.263414\n",
      "iter  32100  time  106.224111\n",
      "train loss is:  0.215814\n",
      "iter  32200  time  110.979322\n",
      "train loss is:  0.185715\n",
      "iter  32300  time  103.589414\n",
      "train loss is:  0.169403\n",
      "iter  32400  time  104.841717\n",
      "train loss is:  0.331696\n",
      "iter  32500  time  107.623298\n",
      "train loss is:  0.172626\n",
      "iter  32600  time  108.699735\n",
      "train loss is:  0.258877\n",
      "iter  32700  time  107.065371\n",
      "train loss is:  0.116745\n",
      "iter  32800  time  104.811982\n",
      "train loss is:  0.141754\n",
      "iter  32900  time  109.101135\n",
      "train loss is:  0.223806\n",
      "iter  33000  time  94.74005\n",
      "train loss is:  0.246714\n",
      "iter  33100  time  96.64638\n",
      "train loss is:  0.118833\n",
      "iter  33200  time  103.843542\n",
      "train loss is:  0.172045\n",
      "iter  33300  time  109.430038\n",
      "train loss is:  0.24634\n",
      "iter  33400  time  114.583442\n",
      "train loss is:  0.099382\n",
      "iter  33500  time  112.928334\n",
      "train loss is:  0.111823\n",
      "iter  33600  time  102.607383\n",
      "train loss is:  0.172188\n",
      "iter  33700  time  102.192572\n",
      "train loss is:  0.24437\n",
      "iter  33800  time  107.916252\n",
      "train loss is:  0.146435\n",
      "iter  33900  time  107.090262\n",
      "train loss is:  0.139309\n",
      "iter  34000  time  110.370461\n",
      "train loss is:  0.151892\n",
      "iter  34100  time  105.426474\n",
      "train loss is:  0.212497\n",
      "iter  34200  time  107.793109\n",
      "train loss is:  0.175581\n",
      "iter  34300  time  108.022425\n",
      "train loss is:  0.130124\n",
      "iter  34400  time  110.99638\n",
      "train loss is:  0.227892\n",
      "iter  34500  time  101.027096\n",
      "train loss is:  0.115753\n",
      "iter  34600  time  107.964266\n",
      "train loss is:  0.150797\n",
      "iter  34700  time  109.275721\n",
      "train loss is:  0.142104\n",
      "iter  34800  time  103.187366\n",
      "train loss is:  0.146309\n",
      "iter  34900  time  106.823845\n",
      "train loss is:  0.118745\n",
      "iter  35000  time  107.95692\n",
      "train loss is:  0.193914\n",
      "iter  35100  time  104.780174\n",
      "train loss is:  0.183423\n",
      "iter  35200  time  106.174396\n",
      "train loss is:  0.174751\n",
      "iter  35300  time  103.883281\n",
      "train loss is:  0.157403\n",
      "iter  35400  time  104.058552\n",
      "train loss is:  0.229479\n",
      "iter  35500  time  101.541971\n",
      "train loss is:  0.247605\n",
      "iter  35600  time  129.789434\n",
      "train loss is:  0.129058\n",
      "iter  35700  time  125.168581\n",
      "train loss is:  0.118543\n",
      "iter  35800  time  118.956298\n",
      "train loss is:  0.230375\n",
      "iter  35900  time  127.689496\n",
      "train loss is:  0.13368\n",
      "iter  36000  time  127.850787\n",
      "train loss is:  0.159143\n",
      "iter  36100  time  127.708211\n",
      "train loss is:  0.19867\n",
      "iter  36200  time  119.758998\n",
      "train loss is:  0.20224\n",
      "iter  36300  time  124.451724\n",
      "train loss is:  0.119705\n",
      "iter  36400  time  117.456435\n",
      "train loss is:  0.168575\n",
      "iter  36500  time  119.864464\n",
      "train loss is:  0.156085\n",
      "iter  36600  time  123.653224\n",
      "train loss is:  0.146339\n",
      "iter  36700  time  122.124063\n",
      "train loss is:  0.283648\n",
      "iter  36800  time  124.887377\n",
      "train loss is:  0.169703\n",
      "iter  36900  time  123.693834\n",
      "train loss is:  0.123865\n",
      "iter  37000  time  122.105435\n",
      "train loss is:  0.128432\n",
      "iter  37100  time  129.43618\n",
      "train loss is:  0.156611\n",
      "iter  37200  time  124.900503\n",
      "train loss is:  0.16469\n",
      "iter  37300  time  118.187704\n",
      "train loss is:  0.146161\n",
      "iter  37400  time  120.367915\n",
      "train loss is:  0.15867\n",
      "iter  37500  time  127.161858\n",
      "train loss is:  0.171677\n",
      "iter  37600  time  121.732907\n",
      "train loss is:  0.141539\n",
      "iter  37700  time  123.645255\n",
      "train loss is:  0.100888\n",
      "iter  37800  time  121.80563\n",
      "train loss is:  0.140391\n",
      "iter  37900  time  126.547165\n",
      "train loss is:  0.135474\n",
      "iter  38000  time  115.983628\n",
      "train loss is:  0.118357\n",
      "iter  38100  time  124.995553\n",
      "train loss is:  0.166296\n",
      "iter  38200  time  109.777558\n",
      "train loss is:  0.185266\n",
      "iter  38300  time  118.144289\n",
      "train loss is:  0.141107\n",
      "iter  38400  time  119.006871\n",
      "train loss is:  0.2271\n",
      "iter  38500  time  109.400818\n",
      "train loss is:  0.101769\n",
      "iter  38600  time  112.195572\n",
      "train loss is:  0.429383\n",
      "iter  38700  time  119.60177\n",
      "train loss is:  0.138667\n",
      "iter  38800  time  113.89558\n",
      "train loss is:  0.181825\n",
      "iter  38900  time  111.784606\n",
      "train loss is:  0.142392\n",
      "iter  39000  time  111.260259\n",
      "train loss is:  0.140265\n",
      "iter  39100  time  111.934223\n",
      "train loss is:  0.13812\n",
      "iter  39200  time  112.465067\n",
      "train loss is:  0.100761\n",
      "iter  39300  time  116.353133\n",
      "train loss is:  0.183421\n",
      "iter  39400  time  111.828337\n",
      "train loss is:  0.16572\n",
      "iter  39500  time  113.748483\n",
      "train loss is:  0.181084\n",
      "iter  39600  time  108.087582\n",
      "train loss is:  0.149774\n",
      "iter  39700  time  111.261719\n",
      "train loss is:  0.21292\n",
      "iter  39800  time  117.596248\n",
      "train loss is:  0.173016\n",
      "iter  39900  time  115.067879\n",
      "train loss is:  0.202759\n",
      "iter  40000  time  109.091698\n",
      "train loss is:  0.121632\n",
      "iter  40100  time  124.831273\n",
      "train loss is:  0.150265\n",
      "iter  40200  time  116.839974\n",
      "train loss is:  0.170083\n",
      "iter  40300  time  113.636582\n",
      "train loss is:  0.179439\n",
      "iter  40400  time  113.0223\n",
      "train loss is:  0.115065\n",
      "iter  40500  time  108.675304\n",
      "train loss is:  0.17636\n",
      "iter  40600  time  106.637952\n",
      "train loss is:  0.131574\n",
      "iter  40700  time  113.167784\n",
      "train loss is:  0.205193\n",
      "iter  40800  time  113.733013\n",
      "train loss is:  0.167231\n",
      "iter  40900  time  112.990472\n",
      "train loss is:  0.177814\n",
      "iter  41000  time  110.43934\n",
      "train loss is:  0.186197\n",
      "iter  41100  time  107.930462\n",
      "train loss is:  0.23684\n",
      "iter  41200  time  112.770782\n",
      "train loss is:  0.112122\n",
      "iter  41300  time  108.805205\n",
      "train loss is:  0.151582\n",
      "iter  41400  time  112.61992\n",
      "train loss is:  0.186521\n",
      "iter  41500  time  120.325292\n",
      "train loss is:  0.127709\n",
      "iter  41600  time  126.282359\n",
      "train loss is:  0.144435\n",
      "iter  41700  time  125.797924\n",
      "train loss is:  0.218251\n",
      "iter  41800  time  125.139411\n",
      "train loss is:  0.135995\n",
      "iter  41900  time  122.718836\n",
      "train loss is:  0.145671\n",
      "iter  42000  time  122.068837\n",
      "train loss is:  0.141426\n",
      "iter  42100  time  122.624027\n",
      "train loss is:  0.164344\n",
      "iter  42200  time  123.515172\n",
      "train loss is:  0.200814\n",
      "iter  42300  time  127.888326\n",
      "train loss is:  0.111139\n",
      "iter  42400  time  123.33472\n",
      "train loss is:  0.28587\n",
      "iter  42500  time  123.978868\n",
      "train loss is:  0.163028\n",
      "iter  42600  time  117.91892\n",
      "train loss is:  0.151426\n",
      "iter  42700  time  117.697121\n",
      "train loss is:  0.151856\n",
      "iter  42800  time  117.449857\n",
      "train loss is:  0.131756\n",
      "iter  42900  time  118.515832\n",
      "train loss is:  0.148909\n",
      "iter  43000  time  115.942147\n",
      "train loss is:  0.23072\n",
      "iter  43100  time  119.135577\n",
      "train loss is:  0.130534\n",
      "iter  43200  time  114.798872\n",
      "train loss is:  0.0717807\n",
      "iter  43300  time  114.406905\n",
      "train loss is:  0.171412\n",
      "iter  43400  time  115.937018\n",
      "train loss is:  0.158518\n",
      "iter  43500  time  115.73202\n",
      "train loss is:  0.162684\n",
      "iter  43600  time  112.706312\n",
      "train loss is:  0.126249\n",
      "iter  43700  time  112.53554\n",
      "train loss is:  0.194747\n",
      "iter  43800  time  109.72445\n",
      "train loss is:  0.180863\n",
      "iter  43900  time  116.80948\n",
      "train loss is:  0.122675\n",
      "iter  44000  time  122.346381\n",
      "train loss is:  0.133903\n",
      "iter  44100  time  120.914276\n",
      "train loss is:  0.139571\n",
      "iter  44200  time  118.200012\n",
      "train loss is:  0.102943\n",
      "iter  44300  time  120.350033\n",
      "train loss is:  0.154757\n",
      "iter  44400  time  123.466247\n",
      "train loss is:  0.103776\n",
      "iter  44500  time  125.101806\n",
      "train loss is:  0.118988\n",
      "iter  44600  time  123.63943\n",
      "train loss is:  0.160084\n",
      "iter  44700  time  123.758827\n",
      "train loss is:  0.170655\n",
      "iter  44800  time  118.293365\n",
      "train loss is:  0.143482\n",
      "iter  44900  time  123.548447\n",
      "train loss is:  0.146089\n",
      "iter  45000  time  121.109276\n",
      "train loss is:  0.0773745\n",
      "iter  45100  time  123.593517\n",
      "train loss is:  0.121046\n",
      "iter  45200  time  115.433114\n",
      "train loss is:  0.0886715\n",
      "iter  45300  time  116.006257\n",
      "train loss is:  0.116783\n",
      "iter  45400  time  123.017121\n",
      "train loss is:  0.139743\n",
      "iter  45500  time  118.645351\n",
      "train loss is:  0.134489\n",
      "iter  45600  time  126.737715\n",
      "train loss is:  0.134777\n",
      "iter  45700  time  125.452707\n",
      "train loss is:  0.134531\n",
      "iter  45800  time  121.447083\n",
      "train loss is:  0.239538\n",
      "iter  45900  time  123.531918\n",
      "train loss is:  0.126277\n",
      "iter  46000  time  120.669853\n",
      "train loss is:  0.117902\n",
      "iter  46100  time  126.37203\n",
      "train loss is:  0.114235\n",
      "iter  46200  time  122.582985\n",
      "train loss is:  0.216096\n",
      "iter  46300  time  126.675932\n",
      "train loss is:  0.145477\n",
      "iter  46400  time  118.253035\n",
      "train loss is:  0.176598\n",
      "iter  46500  time  121.785828\n",
      "train loss is:  0.118188\n",
      "iter  46600  time  119.953648\n",
      "train loss is:  0.134495\n",
      "iter  46700  time  118.804657\n",
      "train loss is:  0.074114\n",
      "iter  46800  time  123.788055\n",
      "train loss is:  0.141085\n",
      "iter  46900  time  118.366989\n",
      "train loss is:  0.210447\n",
      "iter  47000  time  117.217829\n",
      "train loss is:  0.157294\n",
      "iter  47100  time  131.819269\n",
      "train loss is:  0.142734\n",
      "iter  47200  time  127.638849\n",
      "train loss is:  0.189003\n",
      "iter  47300  time  130.38257\n",
      "train loss is:  0.186311\n",
      "iter  47400  time  130.295382\n",
      "train loss is:  0.136577\n",
      "iter  47500  time  127.859766\n",
      "train loss is:  0.139102\n",
      "iter  47600  time  128.110434\n",
      "train loss is:  0.122812\n",
      "iter  47700  time  122.24539\n",
      "train loss is:  0.0951962\n",
      "iter  47800  time  122.237525\n",
      "train loss is:  0.111851\n",
      "iter  47900  time  120.237218\n",
      "train loss is:  0.167748\n",
      "iter  48000  time  116.111494\n",
      "train loss is:  0.151109\n",
      "iter  48100  time  121.338294\n",
      "train loss is:  0.154275\n",
      "iter  48200  time  126.332917\n",
      "train loss is:  0.145095\n",
      "iter  48300  time  119.022477\n",
      "train loss is:  0.154924\n",
      "iter  48400  time  116.371866\n",
      "train loss is:  0.113256\n",
      "iter  48500  time  118.247463\n",
      "train loss is:  0.21408\n",
      "iter  48600  time  116.576286\n",
      "train loss is:  0.191283\n",
      "iter  48700  time  114.458866\n",
      "train loss is:  0.151537\n",
      "iter  48800  time  126.59156\n",
      "train loss is:  0.127145\n",
      "iter  48900  time  124.274637\n",
      "train loss is:  0.141466\n",
      "iter  49000  time  123.987795\n",
      "train loss is:  0.161845\n",
      "iter  49100  time  123.684233\n",
      "train loss is:  0.246161\n",
      "iter  49200  time  123.934799\n",
      "train loss is:  0.133571\n",
      "iter  49300  time  122.528862\n",
      "train loss is:  0.189316\n",
      "iter  49400  time  119.991542\n",
      "train loss is:  0.0949584\n",
      "iter  49500  time  119.30713\n",
      "train loss is:  0.109396\n",
      "iter  49600  time  117.628647\n",
      "train loss is:  0.133665\n",
      "iter  49700  time  116.89727\n",
      "train loss is:  0.154626\n",
      "iter  49800  time  122.434271\n",
      "train loss is:  0.128738\n",
      "iter  49900  time  123.396447\n",
      "train loss is:  0.100485\n",
      "iter  50000  time  117.649877\n",
      "train loss is:  0.163611\n",
      "iter  50100  time  127.655208\n",
      "train loss is:  0.191312\n",
      "iter  50200  time  119.187225\n",
      "train loss is:  0.188771\n",
      "iter  50300  time  122.435822\n",
      "train loss is:  0.134859\n",
      "iter  50400  time  122.56017\n",
      "train loss is:  0.169728\n",
      "iter  50500  time  120.930731\n",
      "train loss is:  0.146708\n",
      "iter  50600  time  121.872221\n",
      "train loss is:  0.155166\n",
      "iter  50700  time  121.149223\n",
      "train loss is:  0.144394\n",
      "iter  50800  time  120.712284\n",
      "train loss is:  0.0811188\n",
      "iter  50900  time  119.470943\n",
      "train loss is:  0.128072\n",
      "iter  51000  time  115.693556\n",
      "train loss is:  0.0632281\n",
      "iter  51100  time  119.79044\n",
      "train loss is:  0.156627\n",
      "iter  51200  time  111.674155\n",
      "train loss is:  0.13128\n",
      "iter  51300  time  109.307936\n",
      "train loss is:  0.219294\n",
      "iter  51400  time  115.264909\n",
      "train loss is:  0.338538\n",
      "iter  51500  time  111.378412\n",
      "train loss is:  0.145359\n",
      "iter  51600  time  106.317944\n",
      "train loss is:  0.139222\n",
      "iter  51700  time  113.04649\n",
      "train loss is:  0.123683\n",
      "iter  51800  time  115.098131\n",
      "train loss is:  0.0778369\n",
      "iter  51900  time  118.394469\n",
      "train loss is:  0.148912\n",
      "iter  52000  time  107.870299\n",
      "train loss is:  0.139794\n",
      "iter  52100  time  115.056298\n",
      "train loss is:  0.0861998\n",
      "iter  52200  time  110.175694\n",
      "train loss is:  0.0838299\n",
      "iter  52300  time  114.448048\n",
      "train loss is:  0.182962\n",
      "iter  52400  time  105.741789\n",
      "train loss is:  0.0884181\n",
      "iter  52500  time  116.320358\n",
      "train loss is:  0.188335\n",
      "iter  52600  time  117.426399\n",
      "train loss is:  0.0855468\n",
      "iter  52700  time  109.163242\n",
      "train loss is:  0.103236\n",
      "iter  52800  time  115.764327\n",
      "train loss is:  0.18968\n",
      "iter  52900  time  114.596305\n",
      "train loss is:  0.115201\n",
      "iter  53000  time  118.21252\n",
      "train loss is:  0.134418\n",
      "iter  53100  time  118.311377\n",
      "train loss is:  0.092604\n",
      "iter  53200  time  114.442886\n",
      "train loss is:  0.174119\n",
      "iter  53300  time  114.264991\n",
      "train loss is:  0.165823\n",
      "iter  53400  time  107.588008\n",
      "train loss is:  0.0769034\n",
      "iter  53500  time  111.98146\n",
      "train loss is:  0.106883\n",
      "iter  53600  time  113.452954\n",
      "train loss is:  0.143635\n",
      "iter  53700  time  115.153902\n",
      "train loss is:  0.218906\n",
      "iter  53800  time  116.663489\n",
      "train loss is:  0.135546\n",
      "iter  53900  time  116.247686\n",
      "train loss is:  0.162481\n",
      "iter  54000  time  117.182519\n",
      "train loss is:  0.140426\n",
      "iter  54100  time  117.063217\n",
      "train loss is:  0.149444\n",
      "iter  54200  time  115.446401\n",
      "train loss is:  0.125782\n",
      "iter  54300  time  110.018517\n",
      "train loss is:  0.132275\n",
      "iter  54400  time  108.473598\n",
      "train loss is:  0.105517\n",
      "iter  54500  time  112.143448\n",
      "train loss is:  0.0811993\n",
      "iter  54600  time  117.372482\n",
      "train loss is:  0.144468\n",
      "iter  54700  time  112.278331\n",
      "train loss is:  0.118416\n",
      "iter  54800  time  114.957219\n",
      "train loss is:  0.108756\n",
      "iter  54900  time  115.99684\n",
      "train loss is:  0.0969435\n",
      "iter  55000  time  119.161725\n",
      "train loss is:  0.089406\n",
      "iter  55100  time  113.843226\n",
      "train loss is:  0.124659\n",
      "iter  55200  time  117.780962\n",
      "train loss is:  0.0878152\n",
      "iter  55300  time  114.584293\n",
      "train loss is:  0.124934\n",
      "iter  55400  time  112.788874\n",
      "train loss is:  0.074451\n",
      "iter  55500  time  109.764465\n",
      "train loss is:  0.170171\n",
      "iter  55600  time  112.234002\n",
      "train loss is:  0.143182\n",
      "iter  55700  time  109.946529\n",
      "train loss is:  0.248183\n",
      "iter  55800  time  118.650616\n",
      "train loss is:  0.144007\n",
      "iter  55900  time  107.286641\n",
      "train loss is:  0.0986008\n",
      "iter  56000  time  107.22215\n",
      "train loss is:  0.175872\n",
      "iter  56100  time  110.983059\n",
      "train loss is:  0.188524\n",
      "iter  56200  time  109.073803\n",
      "train loss is:  0.118318\n",
      "iter  56300  time  112.983862\n",
      "train loss is:  0.0583639\n",
      "iter  56400  time  115.562497\n",
      "train loss is:  0.164017\n",
      "iter  56500  time  119.350085\n",
      "train loss is:  0.141341\n",
      "iter  56600  time  113.328653\n",
      "train loss is:  0.130638\n",
      "iter  56700  time  108.853102\n",
      "train loss is:  0.164674\n",
      "iter  56800  time  115.139152\n",
      "train loss is:  0.094543\n",
      "iter  56900  time  114.375927\n",
      "train loss is:  0.125315\n",
      "iter  57000  time  118.443218\n",
      "train loss is:  0.11415\n",
      "iter  57100  time  118.705367\n",
      "train loss is:  0.127839\n",
      "iter  57200  time  116.692081\n",
      "train loss is:  0.122062\n",
      "iter  57300  time  116.054587\n",
      "train loss is:  0.174314\n",
      "iter  57400  time  115.030376\n",
      "train loss is:  0.129355\n",
      "iter  57500  time  115.727733\n",
      "train loss is:  0.12307\n",
      "iter  57600  time  109.898118\n",
      "train loss is:  0.136833\n",
      "iter  57700  time  118.015307\n",
      "train loss is:  0.116033\n",
      "iter  57800  time  113.53996\n",
      "train loss is:  0.281072\n",
      "iter  57900  time  114.539982\n",
      "train loss is:  0.148905\n",
      "iter  58000  time  119.546573\n",
      "train loss is:  0.180961\n",
      "iter  58100  time  119.523883\n",
      "train loss is:  0.166746\n",
      "iter  58200  time  112.934389\n",
      "train loss is:  0.135183\n",
      "iter  58300  time  110.135316\n",
      "train loss is:  0.121099\n",
      "iter  58400  time  117.316232\n",
      "train loss is:  0.107887\n",
      "iter  58500  time  111.10465\n",
      "train loss is:  0.0559107\n",
      "iter  58600  time  115.16611\n",
      "train loss is:  0.209869\n",
      "iter  58700  time  116.829949\n",
      "train loss is:  0.110303\n",
      "iter  58800  time  122.811401\n",
      "train loss is:  0.165087\n",
      "iter  58900  time  117.146463\n",
      "train loss is:  0.204724\n",
      "iter  59000  time  115.27919\n",
      "train loss is:  0.0981329\n",
      "iter  59100  time  113.648134\n",
      "train loss is:  0.15079\n",
      "iter  59200  time  111.807477\n",
      "train loss is:  0.0655516\n",
      "iter  59300  time  112.545091\n",
      "train loss is:  0.165424\n",
      "iter  59400  time  105.444183\n",
      "train loss is:  0.110078\n",
      "iter  59500  time  114.470486\n",
      "train loss is:  0.211174\n",
      "iter  59600  time  115.693394\n",
      "train loss is:  0.130203\n",
      "iter  59700  time  120.589018\n",
      "train loss is:  0.122365\n",
      "iter  59800  time  112.14509\n",
      "train loss is:  0.105944\n",
      "iter  59900  time  105.397267\n",
      "train loss is:  0.11218\n",
      "iter  60000  time  114.106313\n",
      "train loss is:  0.145955\n",
      "iter  60100  time  117.484755\n",
      "train loss is:  0.145632\n",
      "iter  60200  time  117.425126\n",
      "train loss is:  0.140586\n",
      "iter  60300  time  116.934815\n",
      "train loss is:  0.103928\n",
      "iter  60400  time  113.361765\n",
      "train loss is:  0.112849\n",
      "iter  60500  time  113.944898\n",
      "train loss is:  0.108007\n",
      "iter  60600  time  112.49407\n",
      "train loss is:  0.121175\n",
      "iter  60700  time  112.594198\n",
      "train loss is:  0.230354\n",
      "iter  60800  time  114.970644\n",
      "train loss is:  0.108693\n",
      "iter  60900  time  105.619266\n",
      "train loss is:  0.105482\n",
      "iter  61000  time  110.354467\n",
      "train loss is:  0.149808\n",
      "iter  61100  time  108.989607\n",
      "train loss is:  0.141879\n",
      "iter  61200  time  112.837754\n",
      "train loss is:  0.158555\n",
      "iter  61300  time  114.681391\n",
      "train loss is:  0.100832\n",
      "iter  61400  time  113.354475\n",
      "train loss is:  0.166386\n",
      "iter  61500  time  116.270889\n",
      "train loss is:  0.14573\n",
      "iter  61600  time  114.498636\n",
      "train loss is:  0.128431\n",
      "iter  61700  time  108.383057\n",
      "train loss is:  0.103576\n",
      "iter  61800  time  114.606938\n",
      "train loss is:  0.162756\n",
      "iter  61900  time  108.830708\n",
      "train loss is:  0.116046\n",
      "iter  62000  time  112.333932\n",
      "train loss is:  0.119695\n",
      "iter  62100  time  108.436619\n",
      "train loss is:  0.0969038\n",
      "iter  62200  time  102.9674\n",
      "train loss is:  0.140853\n",
      "iter  62300  time  115.456038\n",
      "train loss is:  0.115268\n",
      "iter  62400  time  116.833188\n",
      "train loss is:  0.160154\n",
      "iter  62500  time  119.810888\n",
      "train loss is:  0.169272\n",
      "iter  62600  time  112.536366\n",
      "train loss is:  0.140811\n",
      "iter  62700  time  120.279517\n",
      "train loss is:  0.0989696\n",
      "iter  62800  time  116.891183\n",
      "train loss is:  0.153113\n",
      "iter  62900  time  117.404724\n",
      "train loss is:  0.11779\n",
      "iter  63000  time  114.392956\n",
      "train loss is:  0.0874717\n",
      "iter  63100  time  117.796356\n",
      "train loss is:  0.219364\n",
      "iter  63200  time  112.579194\n",
      "train loss is:  0.121201\n",
      "iter  63300  time  113.900438\n",
      "train loss is:  0.174232\n",
      "iter  63400  time  113.600981\n",
      "train loss is:  0.141589\n",
      "iter  63500  time  114.701672\n",
      "train loss is:  0.113569\n",
      "iter  63600  time  111.34812\n",
      "train loss is:  0.103799\n",
      "iter  63700  time  117.147988\n",
      "train loss is:  0.178338\n",
      "iter  63800  time  116.509785\n",
      "train loss is:  0.088592\n",
      "iter  63900  time  112.651351\n",
      "train loss is:  0.108978\n",
      "iter  64000  time  117.789889\n",
      "train loss is:  0.0798726\n",
      "iter  64100  time  108.564067\n",
      "train loss is:  0.155652\n",
      "iter  64200  time  108.210316\n",
      "train loss is:  0.113567\n",
      "iter  64300  time  117.603933\n",
      "train loss is:  0.152465\n",
      "iter  64400  time  110.739969\n",
      "train loss is:  0.0994158\n",
      "iter  64500  time  118.835764\n",
      "train loss is:  0.10534\n",
      "iter  64600  time  114.365731\n",
      "train loss is:  0.135534\n",
      "iter  64700  time  112.082079\n",
      "train loss is:  0.12849\n",
      "iter  64800  time  112.227733\n",
      "train loss is:  0.103159\n",
      "iter  64900  time  113.950319\n",
      "train loss is:  0.103183\n",
      "iter  65000  time  109.007765\n",
      "train loss is:  0.0987359\n",
      "iter  65100  time  117.883914\n",
      "train loss is:  0.0931635\n",
      "iter  65200  time  114.909847\n",
      "train loss is:  0.108704\n",
      "iter  65300  time  114.111898\n",
      "train loss is:  0.176184\n",
      "iter  65400  time  118.621839\n",
      "train loss is:  0.132893\n",
      "iter  65500  time  112.281729\n",
      "train loss is:  0.231101\n",
      "iter  65600  time  102.527426\n",
      "train loss is:  0.126718\n",
      "iter  65700  time  104.99523\n",
      "train loss is:  0.0947814\n",
      "iter  65800  time  111.893642\n",
      "train loss is:  0.127432\n",
      "iter  65900  time  113.102936\n",
      "train loss is:  0.112173\n",
      "iter  66000  time  110.548344\n",
      "train loss is:  0.0917271\n",
      "iter  66100  time  112.176918\n",
      "train loss is:  0.145878\n",
      "iter  66200  time  113.911306\n",
      "train loss is:  0.126487\n",
      "iter  66300  time  109.805246\n",
      "train loss is:  0.295458\n",
      "iter  66400  time  106.221854\n",
      "train loss is:  0.105263\n",
      "iter  66500  time  107.727793\n",
      "train loss is:  0.217876\n",
      "iter  66600  time  111.386492\n",
      "train loss is:  0.130484\n",
      "iter  66700  time  102.116312\n",
      "train loss is:  0.160759\n",
      "iter  66800  time  112.965082\n",
      "train loss is:  0.103691\n",
      "iter  66900  time  108.614513\n",
      "train loss is:  0.0992188\n",
      "iter  67000  time  109.805107\n",
      "train loss is:  0.134697\n",
      "iter  67100  time  109.391866\n",
      "train loss is:  0.161524\n",
      "iter  67200  time  107.963611\n",
      "train loss is:  0.117705\n",
      "iter  67300  time  111.867534\n",
      "train loss is:  0.128791\n",
      "iter  67400  time  110.077958\n",
      "train loss is:  0.0906167\n",
      "iter  67500  time  116.194164\n",
      "train loss is:  0.151398\n",
      "iter  67600  time  121.121541\n",
      "train loss is:  0.159128\n",
      "iter  67700  time  121.649288\n",
      "train loss is:  0.123622\n",
      "iter  67800  time  119.983346\n",
      "train loss is:  0.0821575\n",
      "iter  67900  time  120.476655\n",
      "train loss is:  0.168089\n",
      "iter  68000  time  106.914844\n",
      "train loss is:  0.0784431\n",
      "iter  68100  time  112.746296\n",
      "train loss is:  0.0813603\n",
      "iter  68200  time  110.47028\n",
      "train loss is:  0.146435\n",
      "iter  68300  time  110.350217\n",
      "train loss is:  0.104108\n",
      "iter  68400  time  108.109186\n",
      "train loss is:  0.104674\n",
      "iter  68500  time  107.546911\n",
      "train loss is:  0.192641\n",
      "iter  68600  time  114.531583\n",
      "train loss is:  0.0598037\n",
      "iter  68700  time  114.950641\n",
      "train loss is:  0.117106\n",
      "iter  68800  time  107.05463\n",
      "train loss is:  0.0891245\n",
      "iter  68900  time  104.024697\n",
      "train loss is:  0.0930388\n",
      "iter  69000  time  107.371543\n",
      "train loss is:  0.119696\n",
      "iter  69100  time  113.547032\n",
      "train loss is:  0.279325\n",
      "iter  69200  time  111.709419\n",
      "train loss is:  0.104685\n",
      "iter  69300  time  104.880937\n",
      "train loss is:  0.145766\n",
      "iter  69400  time  105.182062\n",
      "train loss is:  0.115623\n",
      "iter  69500  time  108.834359\n",
      "train loss is:  0.106812\n",
      "iter  69600  time  109.434386\n",
      "train loss is:  0.0955283\n",
      "iter  69700  time  110.793086\n",
      "train loss is:  0.129218\n",
      "iter  69800  time  102.436504\n",
      "train loss is:  0.194604\n",
      "iter  69900  time  115.715303\n",
      "train loss is:  0.107738\n",
      "iter  70000  time  121.036175\n",
      "train loss is:  0.13699\n",
      "iter  70100  time  125.194967\n",
      "train loss is:  0.10178\n",
      "iter  70200  time  121.854391\n",
      "train loss is:  0.122108\n",
      "iter  70300  time  124.524515\n",
      "train loss is:  0.126746\n",
      "iter  70400  time  127.011175\n",
      "train loss is:  0.111861\n",
      "iter  70500  time  128.387114\n",
      "train loss is:  0.222545\n",
      "iter  70600  time  126.413378\n",
      "train loss is:  0.190572\n",
      "iter  70700  time  131.796369\n",
      "train loss is:  0.0904402\n",
      "iter  70800  time  128.091652\n",
      "train loss is:  0.101325\n",
      "iter  70900  time  122.572395\n",
      "train loss is:  0.127443\n",
      "iter  71000  time  130.414294\n",
      "train loss is:  0.126106\n",
      "iter  71100  time  133.692438\n",
      "train loss is:  0.287854\n",
      "iter  71200  time  130.111541\n",
      "train loss is:  0.102138\n",
      "iter  71300  time  118.340252\n",
      "train loss is:  0.142409\n",
      "iter  71400  time  105.810697\n",
      "train loss is:  0.166347\n",
      "iter  71500  time  108.287977\n",
      "train loss is:  0.113364\n",
      "iter  71600  time  110.389979\n",
      "train loss is:  0.0850062\n",
      "iter  71700  time  104.402179\n",
      "train loss is:  0.140907\n",
      "iter  71800  time  98.320328\n",
      "train loss is:  0.0808439\n",
      "iter  71900  time  105.731834\n",
      "train loss is:  0.0838598\n",
      "iter  72000  time  112.272446\n",
      "train loss is:  0.126691\n",
      "iter  72100  time  102.416184\n",
      "train loss is:  0.0755418\n",
      "iter  72200  time  96.989119\n",
      "train loss is:  0.0908352\n",
      "iter  72300  time  104.584452\n",
      "train loss is:  0.213057\n",
      "iter  72400  time  106.229687\n",
      "train loss is:  0.134595\n",
      "iter  72500  time  103.819892\n",
      "train loss is:  0.10665\n",
      "iter  72600  time  112.931667\n",
      "train loss is:  0.111665\n",
      "iter  72700  time  104.876792\n",
      "train loss is:  0.203891\n",
      "iter  72800  time  103.779652\n",
      "train loss is:  0.118178\n",
      "iter  72900  time  102.613741\n",
      "train loss is:  0.121708\n",
      "iter  73000  time  105.211009\n",
      "train loss is:  0.0891502\n",
      "iter  73100  time  102.917884\n",
      "train loss is:  0.10983\n",
      "iter  73200  time  112.624823\n",
      "train loss is:  0.0890553\n",
      "iter  73300  time  97.788128\n",
      "train loss is:  0.102994\n",
      "iter  73400  time  104.868465\n",
      "train loss is:  0.102911\n",
      "iter  73500  time  105.758255\n",
      "train loss is:  0.104117\n",
      "iter  73600  time  100.657801\n",
      "train loss is:  0.121158\n",
      "iter  73700  time  98.181809\n",
      "train loss is:  0.0876609\n",
      "iter  73800  time  101.751085\n",
      "train loss is:  0.078669\n",
      "iter  73900  time  104.6869\n",
      "train loss is:  0.120135\n",
      "iter  74000  time  101.571017\n",
      "train loss is:  0.125788\n",
      "iter  74100  time  108.326088\n",
      "train loss is:  0.107472\n",
      "iter  74200  time  100.305503\n",
      "train loss is:  0.105757\n",
      "iter  74300  time  100.60989\n",
      "train loss is:  0.10509\n",
      "iter  74400  time  109.19275\n",
      "train loss is:  0.136097\n",
      "iter  74500  time  101.228774\n",
      "train loss is:  0.13676\n",
      "iter  74600  time  101.766764\n",
      "train loss is:  0.107974\n",
      "iter  74700  time  106.864438\n",
      "train loss is:  0.151345\n",
      "iter  74800  time  105.571117\n",
      "train loss is:  0.117811\n",
      "iter  74900  time  106.940753\n",
      "train loss is:  0.107833\n",
      "iter  75000  time  105.163544\n",
      "train loss is:  0.107856\n",
      "iter  75100  time  108.619119\n",
      "train loss is:  0.0934502\n",
      "iter  75200  time  101.603676\n",
      "train loss is:  0.112443\n",
      "iter  75300  time  99.610379\n",
      "train loss is:  0.0984393\n",
      "iter  75400  time  106.912246\n",
      "train loss is:  0.124149\n",
      "iter  75500  time  97.896475\n",
      "train loss is:  0.0889744\n",
      "iter  75600  time  104.719938\n",
      "train loss is:  0.0880197\n",
      "iter  75700  time  104.1952\n",
      "train loss is:  0.0768737\n",
      "iter  75800  time  107.978348\n",
      "train loss is:  0.180289\n",
      "iter  75900  time  103.617592\n",
      "train loss is:  0.0935811\n",
      "iter  76000  time  107.67898\n",
      "train loss is:  0.112407\n",
      "iter  76100  time  111.02932\n",
      "train loss is:  0.135824\n",
      "iter  76200  time  103.700651\n",
      "train loss is:  0.0807295\n",
      "iter  76300  time  107.807103\n",
      "train loss is:  0.179078\n",
      "iter  76400  time  101.208252\n",
      "train loss is:  0.122413\n",
      "iter  76500  time  107.939133\n",
      "train loss is:  0.0645798\n",
      "iter  76600  time  102.957804\n",
      "train loss is:  0.0998239\n",
      "iter  76700  time  103.07306\n",
      "train loss is:  0.16067\n",
      "iter  76800  time  103.102127\n",
      "train loss is:  0.212443\n",
      "iter  76900  time  106.415795\n",
      "train loss is:  0.104558\n",
      "iter  77000  time  101.401944\n",
      "train loss is:  0.0701458\n",
      "iter  77100  time  111.939553\n",
      "train loss is:  0.0750359\n",
      "iter  77200  time  105.354123\n",
      "train loss is:  0.131263\n",
      "iter  77300  time  96.48917\n",
      "train loss is:  0.103349\n",
      "iter  77400  time  103.286497\n",
      "train loss is:  0.0973611\n",
      "iter  77500  time  106.00624\n",
      "train loss is:  0.16116\n",
      "iter  77600  time  102.48308\n",
      "train loss is:  0.329918\n",
      "iter  77700  time  103.651113\n",
      "train loss is:  0.103375\n",
      "iter  77800  time  104.67192\n",
      "train loss is:  0.118536\n",
      "iter  77900  time  102.370868\n",
      "train loss is:  0.0976242\n",
      "iter  78000  time  104.042361\n",
      "train loss is:  0.188009\n",
      "iter  78100  time  111.688631\n",
      "train loss is:  0.10276\n",
      "iter  78200  time  104.101421\n",
      "train loss is:  0.135755\n",
      "iter  78300  time  109.56614\n",
      "train loss is:  0.120885\n",
      "iter  78400  time  105.276871\n",
      "train loss is:  0.0925492\n",
      "iter  78500  time  99.709813\n",
      "train loss is:  0.141569\n",
      "iter  78600  time  104.123921\n",
      "train loss is:  0.0650295\n",
      "iter  78700  time  104.792933\n",
      "train loss is:  0.12048\n",
      "iter  78800  time  98.143126\n",
      "train loss is:  0.10263\n",
      "iter  78900  time  103.674506\n",
      "train loss is:  0.095884\n",
      "iter  79000  time  98.465693\n",
      "train loss is:  0.11455\n",
      "iter  79100  time  103.207744\n",
      "train loss is:  0.129658\n",
      "iter  79200  time  107.980092\n",
      "train loss is:  0.0821974\n",
      "iter  79300  time  96.528262\n",
      "train loss is:  0.0991913\n",
      "iter  79400  time  100.312869\n",
      "train loss is:  0.083172\n",
      "iter  79500  time  104.854411\n",
      "train loss is:  0.0924913\n",
      "iter  79600  time  108.590805\n",
      "train loss is:  0.117766\n",
      "iter  79700  time  99.14266\n",
      "train loss is:  0.110505\n",
      "iter  79800  time  111.03941\n",
      "train loss is:  0.0960945\n",
      "iter  79900  time  102.142141\n",
      "train loss is:  0.0661999\n",
      "iter  80000  time  100.472272\n",
      "train loss is:  0.0864822\n",
      "iter  80100  time  108.136536\n",
      "train loss is:  0.159566\n",
      "iter  80200  time  105.156238\n",
      "train loss is:  0.168917\n",
      "iter  80300  time  106.504782\n",
      "train loss is:  0.116281\n",
      "iter  80400  time  108.068694\n",
      "train loss is:  0.100623\n",
      "iter  80500  time  103.371055\n",
      "train loss is:  0.0971712\n",
      "iter  80600  time  107.20136\n",
      "train loss is:  0.0827703\n",
      "iter  80700  time  104.054072\n",
      "train loss is:  0.15667\n",
      "iter  80800  time  102.782511\n",
      "train loss is:  0.114451\n",
      "iter  80900  time  105.20606\n",
      "train loss is:  0.124214\n",
      "iter  81000  time  99.566183\n",
      "train loss is:  0.109881\n",
      "iter  81100  time  104.083546\n",
      "train loss is:  0.172483\n",
      "iter  81200  time  105.152524\n",
      "train loss is:  0.0912249\n",
      "iter  81300  time  101.676917\n",
      "train loss is:  0.152633\n",
      "iter  81400  time  105.693141\n",
      "train loss is:  0.118225\n",
      "iter  81500  time  109.576877\n",
      "train loss is:  0.0829904\n",
      "iter  81600  time  109.926611\n",
      "train loss is:  0.125251\n",
      "iter  81700  time  99.499094\n",
      "train loss is:  0.0820358\n",
      "iter  81800  time  104.641594\n",
      "train loss is:  0.127248\n",
      "iter  81900  time  106.587748\n",
      "train loss is:  0.135597\n",
      "iter  82000  time  105.862424\n",
      "train loss is:  0.124333\n",
      "iter  82100  time  109.627224\n",
      "train loss is:  0.0998567\n",
      "iter  82200  time  104.357057\n",
      "train loss is:  0.0900826\n",
      "iter  82300  time  100.205068\n",
      "train loss is:  0.145524\n",
      "iter  82400  time  102.322512\n",
      "train loss is:  0.0583664\n",
      "iter  82500  time  104.428298\n",
      "train loss is:  0.114508\n",
      "iter  82600  time  110.73005\n",
      "train loss is:  0.110037\n",
      "iter  82700  time  106.497239\n",
      "train loss is:  0.0664642\n",
      "iter  82800  time  106.721148\n",
      "train loss is:  0.0843105\n",
      "iter  82900  time  102.29457\n",
      "train loss is:  0.0943859\n",
      "iter  83000  time  106.187758\n",
      "train loss is:  0.0837405\n",
      "iter  83100  time  112.211418\n",
      "train loss is:  0.116136\n",
      "iter  83200  time  104.458624\n",
      "train loss is:  0.14769\n",
      "iter  83300  time  112.99897\n",
      "train loss is:  0.0782062\n",
      "iter  83400  time  106.452393\n",
      "train loss is:  0.113077\n",
      "iter  83500  time  107.056599\n",
      "train loss is:  0.0987636\n",
      "iter  83600  time  105.959979\n",
      "train loss is:  0.105447\n",
      "iter  83700  time  99.812415\n",
      "train loss is:  0.0811721\n",
      "iter  83800  time  105.663701\n",
      "train loss is:  0.162054\n",
      "iter  83900  time  106.842803\n",
      "train loss is:  0.0781702\n",
      "iter  84000  time  99.78541\n",
      "train loss is:  0.151037\n",
      "iter  84100  time  105.706572\n",
      "train loss is:  0.107605\n",
      "iter  84200  time  109.284257\n",
      "train loss is:  0.0761991\n",
      "iter  84300  time  111.560219\n",
      "train loss is:  0.0954471\n",
      "iter  84400  time  104.521127\n",
      "train loss is:  0.0960423\n",
      "iter  84500  time  105.741374\n",
      "train loss is:  0.0881649\n",
      "iter  84600  time  107.632002\n",
      "train loss is:  0.174218\n",
      "iter  84700  time  103.75931\n",
      "train loss is:  0.10562\n",
      "iter  84800  time  110.24603\n",
      "train loss is:  0.219532\n",
      "iter  84900  time  104.064312\n",
      "train loss is:  0.102731\n",
      "iter  85000  time  112.421789\n",
      "train loss is:  0.0892841\n",
      "iter  85100  time  112.174242\n",
      "train loss is:  0.186057\n",
      "iter  85200  time  112.433569\n",
      "train loss is:  0.136585\n",
      "iter  85300  time  110.153836\n",
      "train loss is:  0.0974821\n",
      "iter  85400  time  104.728522\n",
      "train loss is:  0.107845\n",
      "iter  85500  time  108.668737\n",
      "train loss is:  0.118065\n",
      "iter  85600  time  105.039249\n",
      "train loss is:  0.109529\n",
      "iter  85700  time  113.213461\n",
      "train loss is:  0.116568\n",
      "iter  85800  time  101.767271\n",
      "train loss is:  0.10152\n",
      "iter  85900  time  104.544735\n",
      "train loss is:  0.110245\n",
      "iter  86000  time  105.612867\n",
      "train loss is:  0.080686\n",
      "iter  86100  time  109.867846\n",
      "train loss is:  0.281633\n",
      "iter  86200  time  105.012787\n",
      "train loss is:  0.137879\n",
      "iter  86300  time  106.615476\n",
      "train loss is:  0.0696876\n",
      "iter  86400  time  102.828563\n",
      "train loss is:  0.0614128\n",
      "iter  86500  time  101.769787\n",
      "train loss is:  0.100105\n",
      "iter  86600  time  102.691649\n",
      "train loss is:  0.0849157\n",
      "iter  86700  time  107.271366\n",
      "train loss is:  0.0873156\n",
      "iter  86800  time  101.561144\n",
      "train loss is:  0.101183\n",
      "iter  86900  time  103.174919\n",
      "train loss is:  0.0927676\n",
      "iter  87000  time  101.388436\n",
      "train loss is:  0.104352\n",
      "iter  87100  time  110.789971\n",
      "train loss is:  0.0712018\n",
      "iter  87200  time  105.391231\n",
      "train loss is:  0.12597\n",
      "iter  87300  time  105.984776\n",
      "train loss is:  0.111189\n",
      "iter  87400  time  109.203971\n",
      "train loss is:  0.332559\n",
      "iter  87500  time  105.500922\n",
      "train loss is:  0.122593\n",
      "iter  87600  time  104.892357\n",
      "train loss is:  0.0883833\n",
      "iter  87700  time  101.933132\n",
      "train loss is:  0.0937048\n",
      "iter  87800  time  104.489482\n",
      "train loss is:  0.119986\n",
      "iter  87900  time  104.650995\n",
      "train loss is:  0.0970627\n",
      "iter  88000  time  99.268786\n",
      "train loss is:  0.116525\n",
      "iter  88100  time  106.758859\n",
      "train loss is:  0.090867\n",
      "iter  88200  time  100.386242\n",
      "train loss is:  0.0992875\n",
      "iter  88300  time  99.951344\n",
      "train loss is:  0.130384\n",
      "iter  88400  time  99.73928\n",
      "train loss is:  0.113927\n",
      "iter  88500  time  106.384964\n",
      "train loss is:  0.0793533\n",
      "iter  88600  time  110.150156\n",
      "train loss is:  0.142834\n",
      "iter  88700  time  107.871986\n",
      "train loss is:  0.0912026\n",
      "iter  88800  time  98.873808\n",
      "train loss is:  0.10069\n",
      "iter  88900  time  104.347232\n",
      "train loss is:  0.121768\n",
      "iter  89000  time  102.273902\n",
      "train loss is:  0.0959236\n",
      "iter  89100  time  101.590453\n",
      "train loss is:  0.0849825\n",
      "iter  89200  time  102.502972\n",
      "train loss is:  0.180946\n",
      "iter  89300  time  101.157862\n",
      "train loss is:  0.171048\n",
      "iter  89400  time  108.707997\n",
      "train loss is:  0.1345\n",
      "iter  89500  time  104.31707\n",
      "train loss is:  0.0790134\n",
      "iter  89600  time  104.037464\n",
      "train loss is:  0.106579\n",
      "iter  89700  time  105.97287\n",
      "train loss is:  0.0795828\n",
      "iter  89800  time  103.157371\n",
      "train loss is:  0.134248\n",
      "iter  89900  time  97.536794\n",
      "train loss is:  0.0796956\n",
      "iter  90000  time  110.71206\n",
      "train loss is:  0.0699395\n",
      "iter  90100  time  103.326331\n",
      "train loss is:  0.0903387\n",
      "iter  90200  time  109.176672\n",
      "train loss is:  0.0774694\n",
      "iter  90300  time  112.06754\n",
      "train loss is:  0.0774716\n",
      "iter  90400  time  106.281362\n",
      "train loss is:  0.0980955\n",
      "iter  90500  time  100.185402\n",
      "train loss is:  0.135598\n",
      "iter  90600  time  107.8215\n",
      "train loss is:  0.0994278\n",
      "iter  90700  time  104.00566\n",
      "train loss is:  0.0988777\n",
      "iter  90800  time  103.154652\n",
      "train loss is:  0.0840545\n",
      "iter  90900  time  109.231174\n",
      "train loss is:  0.107463\n",
      "iter  91000  time  102.453578\n",
      "train loss is:  0.112228\n",
      "iter  91100  time  108.725097\n",
      "train loss is:  0.091116\n",
      "iter  91200  time  109.831801\n",
      "train loss is:  0.0928281\n",
      "iter  91300  time  98.484048\n",
      "train loss is:  0.125626\n",
      "iter  91400  time  106.842271\n",
      "train loss is:  0.0831496\n",
      "iter  91500  time  109.552135\n",
      "train loss is:  0.0734916\n",
      "iter  91600  time  110.980279\n",
      "train loss is:  0.184026\n",
      "iter  91700  time  106.982664\n",
      "train loss is:  0.125365\n",
      "iter  91800  time  100.554808\n",
      "train loss is:  0.163459\n",
      "iter  91900  time  102.237389\n",
      "train loss is:  0.106597\n",
      "iter  92000  time  102.788815\n",
      "train loss is:  0.087718\n",
      "iter  92100  time  109.427858\n",
      "train loss is:  0.129529\n",
      "iter  92200  time  102.799128\n",
      "train loss is:  0.100147\n",
      "iter  92300  time  100.899772\n",
      "train loss is:  0.0780442\n",
      "iter  92400  time  99.477571\n",
      "train loss is:  0.141813\n",
      "iter  92500  time  104.804724\n",
      "train loss is:  0.102991\n",
      "iter  92600  time  107.460475\n",
      "train loss is:  0.0810296\n",
      "iter  92700  time  103.316772\n",
      "train loss is:  0.100291\n",
      "iter  92800  time  103.662844\n",
      "train loss is:  0.1003\n",
      "iter  92900  time  109.295599\n",
      "train loss is:  0.1123\n",
      "iter  93000  time  112.03699\n",
      "train loss is:  0.099122\n",
      "iter  93100  time  115.828769\n",
      "train loss is:  0.158403\n",
      "iter  93200  time  98.258566\n",
      "train loss is:  0.0816809\n",
      "iter  93300  time  101.23476\n",
      "train loss is:  0.193506\n",
      "iter  93400  time  109.808541\n",
      "train loss is:  0.0993541\n",
      "iter  93500  time  98.197737\n",
      "train loss is:  0.0903624\n",
      "iter  93600  time  104.223497\n",
      "train loss is:  0.0547856\n",
      "iter  93700  time  102.674686\n",
      "train loss is:  0.0892248\n",
      "iter  93800  time  107.194359\n",
      "train loss is:  0.0768877\n",
      "iter  93900  time  107.781443\n",
      "train loss is:  0.0890581\n",
      "iter  94000  time  99.080381\n",
      "train loss is:  0.0882413\n",
      "iter  94100  time  104.347489\n",
      "train loss is:  0.0797744\n",
      "iter  94200  time  101.227974\n",
      "train loss is:  0.0779902\n",
      "iter  94300  time  102.871471\n",
      "train loss is:  0.0933751\n",
      "iter  94400  time  98.698943\n",
      "train loss is:  0.0613077\n",
      "iter  94500  time  100.571498\n",
      "train loss is:  0.10087\n",
      "iter  94600  time  107.532413\n",
      "train loss is:  0.142239\n",
      "iter  94700  time  103.129664\n",
      "train loss is:  0.0854998\n",
      "iter  94800  time  97.646137\n",
      "train loss is:  0.0698465\n",
      "iter  94900  time  103.673456\n",
      "train loss is:  0.0787122\n",
      "iter  95000  time  108.280191\n",
      "train loss is:  0.0693007\n",
      "iter  95100  time  100.821978\n",
      "train loss is:  0.0866241\n",
      "iter  95200  time  105.740296\n",
      "train loss is:  0.0932734\n",
      "iter  95300  time  106.247834\n",
      "train loss is:  0.077009\n",
      "iter  95400  time  101.642463\n",
      "train loss is:  0.112263\n",
      "iter  95500  time  110.138932\n",
      "train loss is:  0.0602998\n",
      "iter  95600  time  102.949652\n",
      "train loss is:  0.0780237\n",
      "iter  95700  time  103.476697\n",
      "train loss is:  0.144458\n",
      "iter  95800  time  104.51829\n",
      "train loss is:  0.125278\n",
      "iter  95900  time  104.351371\n",
      "train loss is:  0.082015\n",
      "iter  96000  time  104.093325\n",
      "train loss is:  0.125525\n",
      "iter  96100  time  107.943086\n",
      "train loss is:  0.10595\n",
      "iter  96200  time  113.386732\n",
      "train loss is:  0.132156\n",
      "iter  96300  time  105.169942\n",
      "train loss is:  0.0767226\n",
      "iter  96400  time  105.797297\n",
      "train loss is:  0.141106\n",
      "iter  96500  time  105.817461\n",
      "train loss is:  0.116858\n",
      "iter  96600  time  105.513675\n",
      "train loss is:  0.0976586\n",
      "iter  96700  time  103.42023\n",
      "train loss is:  0.109528\n",
      "iter  96800  time  106.555232\n",
      "train loss is:  0.0892618\n",
      "iter  96900  time  107.699554\n",
      "train loss is:  0.269816\n",
      "iter  97000  time  104.898012\n",
      "train loss is:  0.328747\n",
      "iter  97100  time  107.763895\n",
      "train loss is:  0.100967\n",
      "iter  97200  time  105.609947\n",
      "train loss is:  0.0710939\n",
      "iter  97300  time  105.239602\n",
      "train loss is:  0.0915891\n",
      "iter  97400  time  107.397467\n",
      "train loss is:  0.0909674\n",
      "iter  97500  time  104.292934\n",
      "train loss is:  0.124734\n",
      "iter  97600  time  97.770789\n",
      "train loss is:  0.0670809\n",
      "iter  97700  time  104.089486\n",
      "train loss is:  0.0921836\n",
      "iter  97800  time  105.523932\n",
      "train loss is:  0.0625892\n",
      "iter  97900  time  100.065104\n",
      "train loss is:  0.104457\n",
      "iter  98000  time  102.641219\n",
      "train loss is:  0.14903\n",
      "iter  98100  time  102.731771\n",
      "train loss is:  0.136668\n",
      "iter  98200  time  105.847507\n",
      "train loss is:  0.0860886\n",
      "iter  98300  time  108.203151\n",
      "train loss is:  0.090391\n",
      "iter  98400  time  103.08976\n",
      "train loss is:  0.0895074\n",
      "iter  98500  time  102.281314\n",
      "train loss is:  0.0829199\n",
      "iter  98600  time  103.428594\n",
      "train loss is:  0.114585\n",
      "iter  98700  time  105.162072\n",
      "train loss is:  0.122829\n",
      "iter  98800  time  107.088576\n",
      "train loss is:  0.0707766\n",
      "iter  98900  time  113.358983\n",
      "train loss is:  0.0897313\n",
      "iter  99000  time  102.760552\n",
      "train loss is:  0.154488\n",
      "iter  99100  time  109.908601\n",
      "train loss is:  0.0839877\n",
      "iter  99200  time  103.607066\n",
      "train loss is:  0.195553\n",
      "iter  99300  time  104.334835\n",
      "train loss is:  0.0974889\n",
      "iter  99400  time  108.32868\n",
      "train loss is:  0.0761497\n",
      "iter  99500  time  104.863114\n",
      "train loss is:  0.0737065\n",
      "iter  99600  time  99.732765\n",
      "train loss is:  0.0805292\n",
      "iter  99700  time  98.033976\n",
      "train loss is:  0.162116\n",
      "iter  99800  time  103.313457\n",
      "train loss is:  0.0750598\n",
      "iter  99900  time  96.654684\n",
      "train loss is:  0.199458\n",
      "iter  100000  time  99.053579\n",
      "train loss is:  0.0719098\n",
      "iter  100100  time  103.640427\n",
      "train loss is:  0.196571\n",
      "iter  100200  time  101.030527\n",
      "train loss is:  0.0647439\n",
      "iter  100300  time  107.448908\n",
      "train loss is:  0.152044\n",
      "iter  100400  time  101.985584\n",
      "train loss is:  0.11292\n",
      "iter  100500  time  110.710354\n",
      "train loss is:  0.109898\n",
      "iter  100600  time  97.453713\n",
      "train loss is:  0.0772073\n",
      "iter  100700  time  101.034913\n",
      "train loss is:  0.132853\n",
      "iter  100800  time  107.76439\n",
      "train loss is:  0.110094\n",
      "iter  100900  time  99.33631\n",
      "train loss is:  0.112803\n",
      "iter  101000  time  100.553114\n",
      "train loss is:  0.0924347\n",
      "iter  101100  time  102.309145\n",
      "train loss is:  0.0993038\n",
      "iter  101200  time  101.031765\n",
      "train loss is:  0.153944\n",
      "iter  101300  time  115.056541\n",
      "train loss is:  0.0737617\n",
      "iter  101400  time  108.292119\n",
      "train loss is:  0.110131\n",
      "iter  101500  time  104.705989\n",
      "train loss is:  0.194299\n",
      "iter  101600  time  110.136901\n",
      "train loss is:  0.0636653\n",
      "iter  101700  time  106.73088\n",
      "train loss is:  0.113115\n",
      "iter  101800  time  99.359389\n",
      "train loss is:  0.119309\n",
      "iter  101900  time  106.079974\n",
      "train loss is:  0.0703054\n",
      "iter  102000  time  105.029132\n",
      "train loss is:  0.150677\n",
      "iter  102100  time  106.385928\n",
      "train loss is:  0.11596\n",
      "iter  102200  time  102.917858\n",
      "train loss is:  0.122687\n",
      "iter  102300  time  106.359055\n",
      "train loss is:  0.153926\n",
      "iter  102400  time  103.608798\n",
      "train loss is:  0.106251\n",
      "iter  102500  time  101.833831\n",
      "train loss is:  0.104054\n",
      "iter  102600  time  111.270346\n",
      "train loss is:  0.0893818\n",
      "iter  102700  time  106.829894\n",
      "train loss is:  0.0772924\n",
      "iter  102800  time  106.542102\n",
      "train loss is:  0.0774133\n",
      "iter  102900  time  101.671846\n",
      "train loss is:  0.0761377\n",
      "iter  103000  time  94.116377\n",
      "train loss is:  0.107023\n",
      "iter  103100  time  110.633823\n",
      "train loss is:  0.0859375\n",
      "iter  103200  time  97.782354\n",
      "train loss is:  0.0861697\n",
      "iter  103300  time  103.276106\n",
      "train loss is:  0.121781\n",
      "iter  103400  time  102.518349\n",
      "train loss is:  0.129945\n",
      "iter  103500  time  103.351362\n",
      "train loss is:  0.103873\n",
      "iter  103600  time  105.8232\n",
      "train loss is:  0.0608687\n",
      "iter  103700  time  105.550326\n",
      "train loss is:  0.0823294\n",
      "iter  103800  time  101.319447\n",
      "train loss is:  0.0778624\n",
      "iter  103900  time  103.393544\n",
      "train loss is:  0.102733\n",
      "iter  104000  time  102.87097\n",
      "train loss is:  0.0885712\n",
      "iter  104100  time  108.920327\n",
      "train loss is:  0.216411\n",
      "iter  104200  time  108.818729\n",
      "train loss is:  0.129029\n",
      "iter  104300  time  105.366688\n",
      "train loss is:  0.0676279\n",
      "iter  104400  time  106.328481\n",
      "train loss is:  0.0602337\n",
      "iter  104500  time  105.947055\n",
      "train loss is:  0.0809063\n",
      "iter  104600  time  103.276799\n",
      "train loss is:  0.0640531\n",
      "iter  104700  time  106.671134\n",
      "train loss is:  0.0962868\n",
      "iter  104800  time  102.835844\n",
      "train loss is:  0.107228\n",
      "iter  104900  time  104.191985\n",
      "train loss is:  0.0843692\n",
      "iter  105000  time  114.507827\n",
      "train loss is:  0.102351\n",
      "iter  105100  time  104.319463\n",
      "train loss is:  0.0717592\n",
      "iter  105200  time  102.178731\n",
      "train loss is:  0.092488\n",
      "iter  105300  time  105.023186\n",
      "train loss is:  0.102525\n",
      "iter  105400  time  99.163845\n",
      "train loss is:  0.0868143\n",
      "iter  105500  time  105.833376\n",
      "train loss is:  0.097241\n",
      "iter  105600  time  107.851161\n",
      "train loss is:  0.0958994\n",
      "iter  105700  time  100.018751\n",
      "train loss is:  0.0790272\n",
      "iter  105800  time  103.716487\n",
      "train loss is:  0.126614\n",
      "iter  105900  time  104.951393\n",
      "train loss is:  0.117464\n",
      "iter  106000  time  105.549626\n",
      "train loss is:  0.10375\n",
      "iter  106100  time  108.280798\n",
      "train loss is:  0.157639\n",
      "iter  106200  time  111.115869\n",
      "train loss is:  0.0989769\n",
      "iter  106300  time  99.059483\n",
      "train loss is:  0.0796909\n",
      "iter  106400  time  102.984172\n",
      "train loss is:  0.0918782\n",
      "iter  106500  time  104.140678\n",
      "train loss is:  0.0620865\n",
      "iter  106600  time  101.387917\n",
      "train loss is:  0.0906154\n",
      "iter  106700  time  107.32917\n",
      "train loss is:  0.117755\n",
      "iter  106800  time  102.076125\n",
      "train loss is:  0.0948893\n",
      "iter  106900  time  105.194127\n",
      "train loss is:  0.094208\n",
      "iter  107000  time  107.25983\n",
      "train loss is:  0.0795414\n",
      "iter  107100  time  105.901649\n",
      "train loss is:  0.0913322\n",
      "iter  107200  time  95.327501\n",
      "train loss is:  0.100815\n",
      "iter  107300  time  105.933342\n",
      "train loss is:  0.0681612\n",
      "iter  107400  time  102.271272\n",
      "train loss is:  0.112039\n",
      "iter  107500  time  101.093529\n",
      "train loss is:  0.0939239\n",
      "iter  107600  time  106.677019\n",
      "train loss is:  0.0619244\n",
      "iter  107700  time  102.4345\n",
      "train loss is:  0.164635\n",
      "iter  107800  time  108.475158\n",
      "train loss is:  0.0749607\n",
      "iter  107900  time  94.271687\n",
      "train loss is:  0.103137\n",
      "iter  108000  time  106.002341\n",
      "train loss is:  0.146255\n",
      "iter  108100  time  100.525355\n",
      "train loss is:  0.113241\n",
      "iter  108200  time  96.696768\n",
      "train loss is:  0.103733\n",
      "iter  108300  time  100.316204\n",
      "train loss is:  0.114458\n",
      "iter  108400  time  103.219703\n",
      "train loss is:  0.160143\n",
      "iter  108500  time  107.671662\n",
      "train loss is:  0.152417\n",
      "iter  108600  time  108.85207\n",
      "train loss is:  0.0749154\n",
      "iter  108700  time  97.30374\n",
      "train loss is:  0.120854\n",
      "iter  108800  time  103.257467\n",
      "train loss is:  0.105037\n",
      "iter  108900  time  107.999354\n",
      "train loss is:  0.0709924\n",
      "iter  109000  time  104.434972\n",
      "train loss is:  0.0576903\n",
      "iter  109100  time  111.175104\n",
      "train loss is:  0.0726923\n",
      "iter  109200  time  105.049693\n",
      "train loss is:  0.0777343\n",
      "iter  109300  time  105.809884\n",
      "train loss is:  0.111813\n",
      "iter  109400  time  111.315222\n",
      "train loss is:  0.118505\n",
      "iter  109500  time  108.33916\n",
      "train loss is:  0.141936\n",
      "iter  109600  time  104.184812\n",
      "train loss is:  0.170447\n",
      "iter  109700  time  95.020118\n",
      "train loss is:  0.0906476\n",
      "iter  109800  time  101.842963\n",
      "train loss is:  0.0812062\n",
      "iter  109900  time  105.386249\n",
      "train loss is:  0.100234\n",
      "iter  110000  time  99.675104\n",
      "train loss is:  0.115795\n",
      "iter  110100  time  105.387382\n",
      "train loss is:  0.0636807\n",
      "iter  110200  time  99.159775\n",
      "train loss is:  0.12371\n",
      "iter  110300  time  103.407895\n",
      "train loss is:  0.0780106\n",
      "iter  110400  time  104.040312\n",
      "train loss is:  0.0949626\n",
      "iter  110500  time  101.037177\n",
      "train loss is:  0.0742726\n",
      "iter  110600  time  102.78003\n",
      "train loss is:  0.0876688\n",
      "iter  110700  time  107.19731\n",
      "train loss is:  0.0953776\n",
      "iter  110800  time  99.761511\n",
      "train loss is:  0.120622\n",
      "iter  110900  time  102.61286\n",
      "train loss is:  0.0644009\n",
      "iter  111000  time  101.409984\n",
      "train loss is:  0.0828082\n",
      "iter  111100  time  108.816023\n",
      "train loss is:  0.0943671\n",
      "iter  111200  time  106.359021\n",
      "train loss is:  0.0699069\n",
      "iter  111300  time  97.797326\n",
      "train loss is:  0.087931\n",
      "iter  111400  time  99.739615\n",
      "train loss is:  0.150879\n",
      "iter  111500  time  104.909347\n",
      "train loss is:  0.14213\n",
      "iter  111600  time  109.592446\n",
      "train loss is:  0.117332\n",
      "iter  111700  time  105.905274\n",
      "train loss is:  0.0984257\n",
      "iter  111800  time  96.406606\n",
      "train loss is:  0.0990463\n",
      "iter  111900  time  102.73891\n",
      "train loss is:  0.0679239\n",
      "iter  112000  time  104.130068\n",
      "train loss is:  0.0746611\n",
      "iter  112100  time  106.814023\n",
      "train loss is:  0.197002\n",
      "iter  112200  time  109.122772\n",
      "train loss is:  0.0505657\n",
      "iter  112300  time  97.708803\n",
      "train loss is:  0.121298\n",
      "iter  112400  time  103.904186\n",
      "train loss is:  0.110742\n",
      "iter  112500  time  111.506404\n",
      "train loss is:  0.161687\n",
      "iter  112600  time  103.779595\n",
      "train loss is:  0.0489642\n",
      "iter  112700  time  110.458256\n",
      "train loss is:  0.0673711\n",
      "iter  112800  time  110.205991\n",
      "train loss is:  0.171861\n",
      "iter  112900  time  103.547988\n",
      "train loss is:  0.0845191\n",
      "iter  113000  time  107.965919\n",
      "train loss is:  0.0605812\n",
      "iter  113100  time  106.363266\n",
      "train loss is:  0.0474874\n",
      "iter  113200  time  103.178577\n",
      "train loss is:  0.121822\n",
      "iter  113300  time  107.646356\n",
      "train loss is:  0.0875231\n",
      "iter  113400  time  114.45462\n",
      "train loss is:  0.0623702\n",
      "iter  113500  time  103.787937\n",
      "train loss is:  0.107392\n",
      "iter  113600  time  105.831836\n",
      "train loss is:  0.124624\n",
      "iter  113700  time  104.95013\n",
      "train loss is:  0.111977\n",
      "iter  113800  time  107.246474\n",
      "train loss is:  0.114985\n",
      "iter  113900  time  98.118043\n",
      "train loss is:  0.0573045\n",
      "iter  114000  time  100.145493\n",
      "train loss is:  0.0718855\n",
      "iter  114100  time  108.469992\n",
      "train loss is:  0.105712\n",
      "iter  114200  time  103.70611\n",
      "train loss is:  0.0742674\n",
      "iter  114300  time  106.117669\n",
      "train loss is:  0.0663964\n",
      "iter  114400  time  102.823956\n",
      "train loss is:  0.0776057\n",
      "iter  114500  time  107.915061\n",
      "train loss is:  0.160507\n",
      "iter  114600  time  103.428549\n",
      "train loss is:  0.10501\n",
      "iter  114700  time  108.732588\n",
      "train loss is:  0.154017\n",
      "iter  114800  time  98.45838\n",
      "train loss is:  0.0846672\n",
      "iter  114900  time  99.376148\n",
      "train loss is:  0.0631796\n",
      "iter  115000  time  109.925764\n",
      "train loss is:  0.0648487\n",
      "iter  115100  time  113.421928\n",
      "train loss is:  0.0703947\n",
      "iter  115200  time  111.348677\n",
      "train loss is:  0.0705044\n",
      "iter  115300  time  103.331915\n",
      "train loss is:  0.0845828\n",
      "iter  115400  time  109.253313\n",
      "train loss is:  0.0694927\n",
      "iter  115500  time  103.895594\n",
      "train loss is:  0.0898334\n",
      "iter  115600  time  103.206299\n",
      "train loss is:  0.0766448\n",
      "iter  115700  time  108.463867\n",
      "train loss is:  0.118284\n",
      "iter  115800  time  111.106788\n",
      "train loss is:  0.132701\n",
      "iter  115900  time  104.183997\n",
      "train loss is:  0.11447\n",
      "iter  116000  time  102.395132\n",
      "train loss is:  0.0929435\n",
      "iter  116100  time  106.341064\n",
      "train loss is:  0.124034\n",
      "iter  116200  time  107.662211\n",
      "train loss is:  0.116269\n",
      "iter  116300  time  105.30824\n",
      "train loss is:  0.149946\n",
      "iter  116400  time  97.389405\n",
      "train loss is:  0.0965683\n",
      "iter  116500  time  103.603694\n",
      "train loss is:  0.0858006\n",
      "iter  116600  time  104.883055\n",
      "train loss is:  0.138396\n",
      "iter  116700  time  101.763402\n",
      "train loss is:  0.0570597\n",
      "iter  116800  time  99.67605\n",
      "train loss is:  0.0760761\n",
      "iter  116900  time  102.328779\n",
      "train loss is:  0.0646245\n",
      "iter  117000  time  99.734886\n",
      "train loss is:  0.13447\n",
      "iter  117100  time  109.629039\n",
      "train loss is:  0.0732575\n",
      "iter  117200  time  106.393933\n",
      "train loss is:  0.0721887\n",
      "iter  117300  time  108.550226\n",
      "train loss is:  0.057608\n",
      "iter  117400  time  101.428976\n",
      "train loss is:  0.0767567\n",
      "iter  117500  time  104.897579\n",
      "train loss is:  0.0887545\n",
      "iter  117600  time  107.40936\n",
      "train loss is:  0.106128\n",
      "iter  117700  time  108.426969\n",
      "train loss is:  0.0863558\n",
      "iter  117800  time  104.002451\n",
      "train loss is:  0.0616546\n",
      "iter  117900  time  104.995313\n",
      "train loss is:  0.0683954\n",
      "iter  118000  time  101.636618\n",
      "train loss is:  0.087269\n",
      "iter  118100  time  109.687993\n",
      "train loss is:  0.0706497\n",
      "iter  118200  time  100.781743\n",
      "train loss is:  0.0397659\n",
      "iter  118300  time  102.776315\n",
      "train loss is:  0.0737705\n",
      "iter  118400  time  105.944775\n",
      "train loss is:  0.136622\n",
      "iter  118500  time  112.034598\n",
      "train loss is:  0.101439\n",
      "iter  118600  time  107.202612\n",
      "train loss is:  0.174902\n",
      "iter  118700  time  101.034548\n",
      "train loss is:  0.0892445\n",
      "iter  118800  time  105.952401\n",
      "train loss is:  0.104783\n",
      "iter  118900  time  99.816145\n",
      "train loss is:  0.0589887\n",
      "iter  119000  time  106.289629\n",
      "train loss is:  0.103596\n",
      "iter  119100  time  105.535251\n",
      "train loss is:  0.194943\n",
      "iter  119200  time  101.620344\n",
      "train loss is:  0.140758\n",
      "iter  119300  time  105.723854\n",
      "train loss is:  0.0759784\n",
      "iter  119400  time  103.074503\n",
      "train loss is:  0.0670026\n",
      "iter  119500  time  98.410901\n",
      "train loss is:  0.0510839\n",
      "iter  119600  time  107.922584\n",
      "train loss is:  0.097439\n",
      "iter  119700  time  110.808911\n",
      "train loss is:  0.0675034\n",
      "iter  119800  time  104.450296\n",
      "train loss is:  0.136072\n",
      "iter  119900  time  102.544219\n",
      "train loss is:  0.0899826\n",
      "iter  120000  time  106.770249\n",
      "train loss is:  0.0989915\n",
      "iter  120100  time  107.621795\n",
      "train loss is:  0.0817452\n",
      "iter  120200  time  96.629804\n",
      "train loss is:  0.0748974\n",
      "iter  120300  time  107.232354\n",
      "train loss is:  0.106354\n",
      "iter  120400  time  97.142664\n",
      "train loss is:  0.0731596\n",
      "iter  120500  time  103.275309\n",
      "train loss is:  0.083908\n",
      "iter  120600  time  104.532503\n",
      "train loss is:  0.112483\n",
      "iter  120700  time  102.870297\n",
      "train loss is:  0.145077\n",
      "iter  120800  time  105.865382\n",
      "train loss is:  0.0657122\n",
      "iter  120900  time  103.118595\n",
      "train loss is:  0.100886\n",
      "iter  121000  time  104.298282\n",
      "train loss is:  0.127198\n",
      "iter  121100  time  103.661194\n",
      "train loss is:  0.107602\n",
      "iter  121200  time  102.00971\n",
      "train loss is:  0.0683857\n",
      "iter  121300  time  107.407003\n",
      "train loss is:  0.0805364\n",
      "iter  121400  time  103.170293\n",
      "train loss is:  0.0855935\n",
      "iter  121500  time  98.369167\n",
      "train loss is:  0.107118\n",
      "iter  121600  time  107.076195\n",
      "train loss is:  0.0509413\n",
      "iter  121700  time  105.500802\n",
      "train loss is:  0.114524\n",
      "iter  121800  time  111.304944\n",
      "train loss is:  0.11278\n",
      "iter  121900  time  104.683807\n",
      "train loss is:  0.0852977\n",
      "iter  122000  time  109.421071\n",
      "train loss is:  0.0517199\n",
      "iter  122100  time  109.153789\n",
      "train loss is:  0.082075\n",
      "iter  122200  time  104.394547\n",
      "train loss is:  0.116557\n",
      "iter  122300  time  106.930572\n",
      "train loss is:  0.0857536\n",
      "iter  122400  time  104.500738\n",
      "train loss is:  0.105957\n",
      "iter  122500  time  103.252652\n",
      "train loss is:  0.118579\n",
      "iter  122600  time  107.423131\n",
      "train loss is:  0.0475146\n",
      "iter  122700  time  106.661927\n",
      "train loss is:  0.0663657\n",
      "iter  122800  time  102.084864\n",
      "train loss is:  0.0667731\n",
      "iter  122900  time  104.211884\n",
      "train loss is:  0.118973\n",
      "iter  123000  time  101.50299\n",
      "train loss is:  0.0813738\n",
      "iter  123100  time  109.465547\n",
      "train loss is:  0.0882838\n",
      "iter  123200  time  110.173621\n",
      "train loss is:  0.064068\n",
      "iter  123300  time  101.816455\n",
      "train loss is:  0.116575\n",
      "iter  123400  time  103.413506\n",
      "train loss is:  0.107396\n",
      "iter  123500  time  110.943785\n",
      "train loss is:  0.0740977\n",
      "iter  123600  time  96.343205\n",
      "train loss is:  0.115069\n",
      "iter  123700  time  102.567756\n",
      "train loss is:  0.0798784\n",
      "iter  123800  time  104.201739\n",
      "train loss is:  0.11705\n",
      "iter  123900  time  101.036546\n",
      "train loss is:  0.0774354\n",
      "iter  124000  time  101.085965\n",
      "train loss is:  0.108854\n",
      "iter  124100  time  111.987579\n",
      "train loss is:  0.26626\n",
      "iter  124200  time  107.07696\n",
      "train loss is:  0.0890706\n",
      "iter  124300  time  105.755433\n",
      "train loss is:  0.104209\n",
      "iter  124400  time  101.632107\n",
      "train loss is:  0.0502969\n",
      "iter  124500  time  94.061095\n",
      "train loss is:  0.157325\n",
      "iter  124600  time  100.023428\n",
      "train loss is:  0.100453\n",
      "iter  124700  time  106.748057\n",
      "train loss is:  0.0719375\n",
      "iter  124800  time  107.053425\n",
      "train loss is:  0.0879658\n",
      "iter  124900  time  105.769283\n",
      "train loss is:  0.102383\n",
      "iter  125000  time  106.616733\n",
      "train loss is:  0.05821\n",
      "iter  125100  time  99.060058\n",
      "train loss is:  0.0525445\n",
      "iter  125200  time  109.233252\n",
      "train loss is:  0.121895\n",
      "iter  125300  time  108.407226\n",
      "train loss is:  0.0418207\n",
      "iter  125400  time  103.047064\n",
      "train loss is:  0.0695436\n",
      "iter  125500  time  110.234105\n",
      "train loss is:  0.0736377\n",
      "iter  125600  time  105.818011\n",
      "train loss is:  0.0886579\n",
      "iter  125700  time  106.295453\n",
      "train loss is:  0.11471\n",
      "iter  125800  time  106.385509\n",
      "train loss is:  0.0685467\n",
      "iter  125900  time  103.830808\n",
      "train loss is:  0.104582\n",
      "iter  126000  time  107.480512\n",
      "train loss is:  0.0928571\n",
      "iter  126100  time  102.617113\n",
      "train loss is:  0.0644517\n",
      "iter  126200  time  102.734242\n",
      "train loss is:  0.098348\n",
      "iter  126300  time  107.942339\n",
      "train loss is:  0.0667913\n",
      "iter  126400  time  106.322896\n",
      "train loss is:  0.0832138\n",
      "iter  126500  time  104.912926\n",
      "train loss is:  0.0830673\n",
      "iter  126600  time  111.34774\n",
      "train loss is:  0.0582935\n",
      "iter  126700  time  101.544557\n",
      "train loss is:  0.100614\n",
      "iter  126800  time  101.333833\n",
      "train loss is:  0.0593805\n",
      "iter  126900  time  106.684234\n",
      "train loss is:  0.0919769\n",
      "iter  127000  time  111.001407\n",
      "train loss is:  0.068184\n",
      "iter  127100  time  98.870478\n",
      "train loss is:  0.129154\n",
      "iter  127200  time  104.215345\n",
      "train loss is:  0.0775077\n",
      "iter  127300  time  111.673597\n",
      "train loss is:  0.102662\n",
      "iter  127400  time  109.582717\n",
      "train loss is:  0.077928\n",
      "iter  127500  time  104.508052\n",
      "train loss is:  0.0510964\n",
      "iter  127600  time  107.138694\n",
      "train loss is:  0.0423671\n",
      "iter  127700  time  107.63719\n",
      "train loss is:  0.0558499\n",
      "iter  127800  time  105.469777\n",
      "train loss is:  0.0447108\n",
      "iter  127900  time  104.76134\n",
      "train loss is:  0.123962\n",
      "iter  128000  time  97.989079\n",
      "train loss is:  0.0757389\n",
      "iter  128100  time  107.932714\n",
      "train loss is:  0.0862816\n",
      "iter  128200  time  99.976747\n",
      "train loss is:  0.0877623\n",
      "iter  128300  time  106.011721\n",
      "train loss is:  0.0783546\n",
      "iter  128400  time  103.110614\n",
      "train loss is:  0.0678537\n",
      "iter  128500  time  110.864623\n",
      "train loss is:  0.0567445\n",
      "iter  128600  time  106.46928\n",
      "train loss is:  0.0602679\n",
      "iter  128700  time  98.768529\n",
      "train loss is:  0.0805757\n",
      "iter  128800  time  109.191213\n",
      "train loss is:  0.0890653\n",
      "iter  128900  time  101.315823\n",
      "train loss is:  0.0681561\n",
      "iter  129000  time  108.853924\n",
      "train loss is:  0.0679556\n",
      "iter  129100  time  105.546255\n",
      "train loss is:  0.09251\n",
      "iter  129200  time  102.511842\n",
      "train loss is:  0.0609383\n",
      "iter  129300  time  108.595951\n",
      "train loss is:  0.078787\n",
      "iter  129400  time  102.431501\n",
      "train loss is:  0.0467566\n",
      "iter  129500  time  105.762056\n",
      "train loss is:  0.0778426\n",
      "iter  129600  time  103.349756\n",
      "train loss is:  0.101038\n",
      "iter  129700  time  104.824952\n",
      "train loss is:  0.0666622\n",
      "iter  129800  time  109.622838\n",
      "train loss is:  0.208931\n",
      "iter  129900  time  102.69189\n",
      "train loss is:  0.0860072\n",
      "iter  130000  time  110.835319\n",
      "train loss is:  0.0818059\n",
      "iter  130100  time  114.085522\n",
      "train loss is:  0.0726096\n",
      "iter  130200  time  100.666859\n",
      "train loss is:  0.0631635\n",
      "iter  130300  time  101.211297\n",
      "train loss is:  0.097723\n",
      "iter  130400  time  101.071271\n",
      "train loss is:  0.0704256\n",
      "iter  130500  time  107.3745\n",
      "train loss is:  0.0616898\n",
      "iter  130600  time  104.203535\n",
      "train loss is:  0.0787966\n",
      "iter  130700  time  110.673778\n",
      "train loss is:  0.04607\n",
      "iter  130800  time  105.41292\n",
      "train loss is:  0.113299\n",
      "iter  130900  time  103.92956\n",
      "train loss is:  0.162509\n",
      "iter  131000  time  109.756697\n",
      "train loss is:  0.0703157\n",
      "iter  131100  time  106.410888\n",
      "train loss is:  0.0708934\n",
      "iter  131200  time  110.103428\n",
      "train loss is:  0.0566239\n",
      "iter  131300  time  106.721402\n",
      "train loss is:  0.0818392\n",
      "iter  131400  time  103.474441\n",
      "train loss is:  0.105628\n",
      "iter  131500  time  103.947779\n",
      "train loss is:  0.133443\n",
      "iter  131600  time  102.771614\n",
      "train loss is:  0.0837736\n",
      "iter  131700  time  99.630102\n",
      "train loss is:  0.0902506\n",
      "iter  131800  time  98.275103\n",
      "train loss is:  0.0387395\n",
      "iter  131900  time  102.144922\n",
      "train loss is:  0.0870329\n",
      "iter  132000  time  101.176867\n",
      "train loss is:  0.0831269\n",
      "iter  132100  time  117.263281\n",
      "train loss is:  0.0741412\n",
      "iter  132200  time  101.9745\n",
      "train loss is:  0.0802692\n",
      "iter  132300  time  101.094358\n",
      "train loss is:  0.0622937\n",
      "iter  132400  time  100.521658\n",
      "train loss is:  0.0675915\n",
      "iter  132500  time  111.422144\n",
      "train loss is:  0.126118\n",
      "iter  132600  time  104.685087\n",
      "train loss is:  0.0857354\n",
      "iter  132700  time  107.44652\n",
      "train loss is:  0.15263\n",
      "iter  132800  time  102.576021\n",
      "train loss is:  0.0795989\n",
      "iter  132900  time  107.101556\n",
      "train loss is:  0.0723347\n",
      "iter  133000  time  101.380963\n",
      "train loss is:  0.0856935\n",
      "iter  133100  time  102.568316\n",
      "train loss is:  0.12616\n",
      "iter  133200  time  106.647126\n",
      "train loss is:  0.0867961\n",
      "iter  133300  time  105.555338\n",
      "train loss is:  0.0574761\n",
      "iter  133400  time  104.158119\n",
      "train loss is:  0.33732\n",
      "iter  133500  time  104.904769\n",
      "train loss is:  0.125295\n",
      "iter  133600  time  105.635749\n",
      "train loss is:  0.0616745\n",
      "iter  133700  time  102.736562\n",
      "train loss is:  0.139403\n",
      "iter  133800  time  103.280584\n",
      "train loss is:  0.0835459\n",
      "iter  133900  time  108.08338\n",
      "train loss is:  0.106793\n",
      "iter  134000  time  107.045725\n",
      "train loss is:  0.120767\n",
      "iter  134100  time  105.698741\n",
      "train loss is:  0.111171\n",
      "iter  134200  time  102.227262\n",
      "train loss is:  0.0897234\n",
      "iter  134300  time  106.253603\n",
      "train loss is:  0.0863083\n",
      "iter  134400  time  104.78644\n",
      "train loss is:  0.121702\n",
      "iter  134500  time  105.176302\n",
      "train loss is:  0.0622828\n",
      "iter  134600  time  104.600439\n",
      "train loss is:  0.0536875\n",
      "iter  134700  time  107.406606\n",
      "train loss is:  0.0734111\n",
      "iter  134800  time  104.94419\n",
      "train loss is:  0.0971693\n",
      "iter  134900  time  102.962141\n",
      "train loss is:  0.104668\n",
      "iter  135000  time  112.46809\n",
      "train loss is:  0.0699115\n",
      "iter  135100  time  107.87676\n",
      "train loss is:  0.112026\n",
      "iter  135200  time  104.48571\n",
      "train loss is:  0.0931622\n",
      "iter  135300  time  104.841385\n",
      "train loss is:  0.0596112\n",
      "iter  135400  time  106.493198\n",
      "train loss is:  0.0901836\n",
      "iter  135500  time  99.231054\n",
      "train loss is:  0.0998388\n",
      "iter  135600  time  111.39363\n",
      "train loss is:  0.0753803\n",
      "iter  135700  time  106.850931\n",
      "train loss is:  0.0490575\n",
      "iter  135800  time  104.681114\n",
      "train loss is:  0.0880884\n",
      "iter  135900  time  110.117399\n",
      "train loss is:  0.0458714\n",
      "iter  136000  time  103.964531\n",
      "train loss is:  0.0597844\n",
      "iter  136100  time  109.963966\n",
      "train loss is:  0.0518918\n",
      "iter  136200  time  103.086179\n",
      "train loss is:  0.169208\n",
      "iter  136300  time  107.52405\n",
      "train loss is:  0.0631085\n",
      "iter  136400  time  104.576463\n",
      "train loss is:  0.1459\n",
      "iter  136500  time  102.214407\n",
      "train loss is:  0.0661604\n",
      "iter  136600  time  107.111937\n",
      "train loss is:  0.138312\n",
      "iter  136700  time  109.364395\n",
      "train loss is:  0.10616\n",
      "iter  136800  time  108.140399\n",
      "train loss is:  0.0615333\n",
      "iter  136900  time  104.571453\n",
      "train loss is:  0.131852\n",
      "iter  137000  time  102.586506\n",
      "train loss is:  0.0771714\n",
      "iter  137100  time  104.621575\n",
      "train loss is:  0.05814\n",
      "iter  137200  time  99.680059\n",
      "train loss is:  0.0749846\n",
      "iter  137300  time  99.259723\n",
      "train loss is:  0.101557\n",
      "iter  137400  time  108.209324\n",
      "train loss is:  0.124646\n",
      "iter  137500  time  107.082292\n",
      "train loss is:  0.173464\n",
      "iter  137600  time  102.540594\n",
      "train loss is:  0.138207\n",
      "iter  137700  time  102.903004\n",
      "train loss is:  0.0620644\n",
      "iter  137800  time  102.645037\n",
      "train loss is:  0.0691534\n",
      "iter  137900  time  104.034974\n",
      "train loss is:  0.0745436\n",
      "iter  138000  time  107.370597\n",
      "train loss is:  0.119127\n",
      "iter  138100  time  108.844254\n",
      "train loss is:  0.0692155\n",
      "iter  138200  time  103.416483\n",
      "train loss is:  0.0829573\n",
      "iter  138300  time  107.289606\n",
      "train loss is:  0.109983\n",
      "iter  138400  time  108.179291\n",
      "train loss is:  0.0929591\n",
      "iter  138500  time  104.126887\n",
      "train loss is:  0.0441398\n",
      "iter  138600  time  110.640501\n",
      "train loss is:  0.131822\n",
      "iter  138700  time  104.431395\n",
      "train loss is:  0.0863843\n",
      "iter  138800  time  108.64432\n",
      "train loss is:  0.105601\n",
      "iter  138900  time  106.935685\n",
      "train loss is:  0.0546975\n",
      "iter  139000  time  109.248268\n",
      "train loss is:  0.0836382\n",
      "iter  139100  time  110.169694\n",
      "train loss is:  0.0462595\n",
      "iter  139200  time  107.937071\n",
      "train loss is:  0.104614\n",
      "iter  139300  time  98.99668\n",
      "train loss is:  0.0834745\n",
      "iter  139400  time  103.998558\n",
      "train loss is:  0.149709\n",
      "iter  139500  time  106.463317\n",
      "train loss is:  0.0446189\n",
      "iter  139600  time  100.84234\n",
      "train loss is:  0.111042\n",
      "iter  139700  time  103.150949\n",
      "train loss is:  0.127849\n",
      "iter  139800  time  102.731508\n",
      "train loss is:  0.0466795\n",
      "iter  139900  time  105.358062\n",
      "train loss is:  0.0839695\n",
      "iter  140000  time  105.010711\n",
      "train loss is:  0.157299\n",
      "iter  140100  time  115.479696\n",
      "train loss is:  0.0806399\n",
      "iter  140200  time  99.720795\n",
      "train loss is:  0.0568591\n",
      "iter  140300  time  99.980014\n",
      "train loss is:  0.0804009\n",
      "iter  140400  time  96.12662\n",
      "train loss is:  0.0901428\n",
      "iter  140500  time  98.79967\n",
      "train loss is:  0.0994729\n",
      "iter  140600  time  115.508202\n",
      "train loss is:  0.0792044\n",
      "iter  140700  time  106.475805\n",
      "train loss is:  0.073605\n",
      "iter  140800  time  104.471909\n",
      "train loss is:  0.0585894\n",
      "iter  140900  time  101.488196\n",
      "train loss is:  0.0849699\n",
      "iter  141000  time  97.839749\n",
      "train loss is:  0.0541734\n",
      "iter  141100  time  106.777019\n",
      "train loss is:  0.111425\n",
      "iter  141200  time  102.358676\n",
      "train loss is:  0.0598466\n",
      "iter  141300  time  100.728038\n",
      "train loss is:  0.0767746\n",
      "iter  141400  time  101.156021\n",
      "train loss is:  0.0422237\n",
      "iter  141500  time  101.310012\n",
      "train loss is:  0.0953357\n",
      "iter  141600  time  99.985343\n",
      "train loss is:  0.0764645\n",
      "iter  141700  time  111.039796\n",
      "train loss is:  0.111948\n",
      "iter  141800  time  102.047733\n",
      "train loss is:  0.0812034\n",
      "iter  141900  time  105.338556\n",
      "train loss is:  0.151473\n",
      "iter  142000  time  106.354612\n",
      "train loss is:  0.109203\n",
      "iter  142100  time  107.00165\n",
      "train loss is:  0.0597627\n",
      "iter  142200  time  105.042798\n",
      "train loss is:  0.102132\n",
      "iter  142300  time  108.573737\n",
      "train loss is:  0.0711983\n",
      "iter  142400  time  105.107916\n",
      "train loss is:  0.129727\n",
      "iter  142500  time  99.095015\n",
      "train loss is:  0.0715566\n",
      "iter  142600  time  102.619788\n",
      "train loss is:  0.0625973\n",
      "iter  142700  time  108.769481\n",
      "train loss is:  0.0634677\n",
      "iter  142800  time  107.376635\n",
      "train loss is:  0.0620554\n",
      "iter  142900  time  108.72717\n",
      "train loss is:  0.0736585\n",
      "iter  143000  time  105.163784\n",
      "train loss is:  0.0642557\n",
      "iter  143100  time  97.47895\n",
      "train loss is:  0.0951933\n",
      "iter  143200  time  99.383125\n",
      "train loss is:  0.0680738\n",
      "iter  143300  time  99.197575\n",
      "train loss is:  0.049841\n",
      "iter  143400  time  99.366743\n",
      "train loss is:  0.0550015\n",
      "iter  143500  time  107.829367\n",
      "train loss is:  0.0924793\n",
      "iter  143600  time  105.865914\n",
      "train loss is:  0.0903633\n",
      "iter  143700  time  100.342699\n",
      "train loss is:  0.0956237\n",
      "iter  143800  time  99.242672\n",
      "train loss is:  0.0719065\n",
      "iter  143900  time  103.097129\n",
      "train loss is:  0.105055\n",
      "iter  144000  time  103.292284\n",
      "train loss is:  0.0895579\n",
      "iter  144100  time  112.968978\n",
      "train loss is:  0.0695215\n",
      "iter  144200  time  108.446425\n",
      "train loss is:  0.0738771\n",
      "iter  144300  time  107.764787\n",
      "train loss is:  0.0909073\n",
      "iter  144400  time  100.437082\n",
      "train loss is:  0.0610838\n",
      "iter  144500  time  107.452777\n",
      "train loss is:  0.082055\n",
      "iter  144600  time  108.453019\n",
      "train loss is:  0.161794\n",
      "iter  144700  time  104.147969\n",
      "train loss is:  0.0963581\n",
      "iter  144800  time  98.631482\n",
      "train loss is:  0.0659348\n",
      "iter  144900  time  107.474064\n",
      "train loss is:  0.134607\n",
      "iter  145000  time  106.849102\n",
      "train loss is:  0.0775518\n",
      "iter  145100  time  104.890866\n",
      "train loss is:  0.0588145\n",
      "iter  145200  time  99.292731\n",
      "train loss is:  0.0556576\n",
      "iter  145300  time  106.892135\n",
      "train loss is:  0.0925084\n",
      "iter  145400  time  110.416831\n",
      "train loss is:  0.0717132\n",
      "iter  145500  time  106.653721\n",
      "train loss is:  0.0883429\n",
      "iter  145600  time  103.465391\n",
      "train loss is:  0.04513\n",
      "iter  145700  time  102.694796\n",
      "train loss is:  0.0415505\n",
      "iter  145800  time  97.212822\n",
      "train loss is:  0.0852294\n",
      "iter  145900  time  112.566886\n",
      "train loss is:  0.0498676\n",
      "iter  146000  time  100.442302\n",
      "train loss is:  0.0687971\n",
      "iter  146100  time  101.275879\n",
      "train loss is:  0.0881539\n",
      "iter  146200  time  110.543409\n",
      "train loss is:  0.100142\n",
      "iter  146300  time  105.699687\n",
      "train loss is:  0.0698265\n",
      "iter  146400  time  105.492838\n",
      "train loss is:  0.051852\n",
      "iter  146500  time  110.986549\n",
      "train loss is:  0.0611662\n",
      "iter  146600  time  110.657144\n",
      "train loss is:  0.112913\n",
      "iter  146700  time  105.833245\n",
      "train loss is:  0.0968349\n",
      "iter  146800  time  107.531442\n",
      "train loss is:  0.0808805\n",
      "iter  146900  time  97.272327\n",
      "train loss is:  0.124734\n",
      "iter  147000  time  101.770951\n",
      "train loss is:  0.188855\n",
      "iter  147100  time  107.917279\n",
      "train loss is:  0.0970221\n",
      "iter  147200  time  98.386206\n",
      "train loss is:  0.0728212\n",
      "iter  147300  time  106.451144\n",
      "train loss is:  0.0837579\n",
      "iter  147400  time  100.115022\n",
      "train loss is:  0.109847\n",
      "iter  147500  time  109.693182\n",
      "train loss is:  0.0810758\n",
      "iter  147600  time  109.252394\n",
      "train loss is:  0.0625254\n",
      "iter  147700  time  104.25146\n",
      "train loss is:  0.098278\n",
      "iter  147800  time  101.863216\n",
      "train loss is:  0.0793829\n",
      "iter  147900  time  102.191189\n",
      "train loss is:  0.064877\n",
      "iter  148000  time  105.149481\n",
      "train loss is:  0.0789523\n",
      "iter  148100  time  106.932544\n",
      "train loss is:  0.0596897\n",
      "iter  148200  time  100.308287\n",
      "train loss is:  0.0947643\n",
      "iter  148300  time  99.777771\n",
      "train loss is:  0.0785514\n",
      "iter  148400  time  103.077947\n",
      "train loss is:  0.0662033\n",
      "iter  148500  time  108.604865\n",
      "train loss is:  0.0399921\n",
      "iter  148600  time  104.198808\n",
      "train loss is:  0.0721566\n",
      "iter  148700  time  110.754819\n",
      "train loss is:  0.0501749\n",
      "iter  148800  time  111.700654\n",
      "train loss is:  0.051337\n",
      "iter  148900  time  104.926653\n",
      "train loss is:  0.0711224\n",
      "iter  149000  time  109.440348\n",
      "train loss is:  0.163082\n",
      "iter  149100  time  105.913229\n",
      "train loss is:  0.0879492\n",
      "iter  149200  time  107.480872\n",
      "train loss is:  0.0870363\n",
      "iter  149300  time  100.168166\n",
      "train loss is:  0.0866008\n",
      "iter  149400  time  99.133341\n",
      "train loss is:  0.100177\n",
      "iter  149500  time  99.829321\n",
      "train loss is:  0.0455439\n",
      "iter  149600  time  108.624017\n",
      "train loss is:  0.0557979\n",
      "iter  149700  time  105.783831\n",
      "train loss is:  0.144637\n",
      "iter  149800  time  109.109608\n",
      "train loss is:  0.0825475\n",
      "iter  149900  time  96.314916\n",
      "train loss is:  0.0950114\n",
      "iter  150000  time  99.136548\n",
      "train loss is:  0.156062\n",
      "iter  150100  time  110.072225\n",
      "train loss is:  0.0652689\n",
      "iter  150200  time  106.090729\n",
      "train loss is:  0.0650315\n",
      "iter  150300  time  101.735686\n",
      "train loss is:  0.0643409\n",
      "iter  150400  time  104.128465\n",
      "train loss is:  0.0611568\n",
      "iter  150500  time  105.414925\n",
      "train loss is:  0.0759268\n",
      "iter  150600  time  100.55241\n",
      "train loss is:  0.101217\n",
      "iter  150700  time  101.744208\n",
      "train loss is:  0.0714582\n",
      "iter  150800  time  105.230355\n",
      "train loss is:  0.0674418\n",
      "iter  150900  time  106.752374\n",
      "train loss is:  0.0652038\n",
      "iter  151000  time  104.590122\n",
      "train loss is:  0.137864\n",
      "iter  151100  time  105.466973\n",
      "train loss is:  0.125721\n",
      "iter  151200  time  100.21325\n",
      "train loss is:  0.108938\n",
      "iter  151300  time  99.568391\n",
      "train loss is:  0.0960268\n",
      "iter  151400  time  109.114952\n",
      "train loss is:  0.0418262\n",
      "iter  151500  time  100.702796\n",
      "train loss is:  0.0751487\n",
      "iter  151600  time  105.693595\n",
      "train loss is:  0.0588747\n",
      "iter  151700  time  105.562335\n",
      "train loss is:  0.0930054\n",
      "iter  151800  time  104.664352\n",
      "train loss is:  0.0955237\n",
      "iter  151900  time  102.488538\n",
      "train loss is:  0.0796764\n",
      "iter  152000  time  100.534613\n",
      "train loss is:  0.0929177\n",
      "iter  152100  time  106.724587\n",
      "train loss is:  0.0670358\n",
      "iter  152200  time  104.953601\n",
      "train loss is:  0.0824318\n",
      "iter  152300  time  101.606716\n",
      "train loss is:  0.0865524\n",
      "iter  152400  time  105.284796\n",
      "train loss is:  0.116113\n",
      "iter  152500  time  95.387495\n",
      "train loss is:  0.093144\n",
      "iter  152600  time  100.547923\n",
      "train loss is:  0.169188\n",
      "iter  152700  time  104.889468\n",
      "train loss is:  0.0765298\n",
      "iter  152800  time  103.935502\n",
      "train loss is:  0.0737565\n",
      "iter  152900  time  104.527452\n",
      "train loss is:  0.0581052\n",
      "iter  153000  time  101.9512\n",
      "train loss is:  0.0781155\n",
      "iter  153100  time  105.758624\n",
      "train loss is:  0.0561345\n",
      "iter  153200  time  107.736221\n",
      "train loss is:  0.0507016\n",
      "iter  153300  time  98.152577\n",
      "train loss is:  0.0887443\n",
      "iter  153400  time  101.733867\n",
      "train loss is:  0.0770564\n",
      "iter  153500  time  106.706835\n",
      "train loss is:  0.0669873\n",
      "iter  153600  time  99.910693\n",
      "train loss is:  0.119146\n",
      "iter  153700  time  101.754616\n",
      "train loss is:  0.127941\n",
      "iter  153800  time  106.951116\n",
      "train loss is:  0.0912754\n",
      "iter  153900  time  110.759448\n",
      "train loss is:  0.0358286\n",
      "iter  154000  time  106.295325\n",
      "train loss is:  0.0622351\n",
      "iter  154100  time  103.202351\n",
      "train loss is:  0.0667243\n",
      "iter  154200  time  99.386856\n",
      "train loss is:  0.203919\n",
      "iter  154300  time  104.590153\n",
      "train loss is:  0.0726349\n",
      "iter  154400  time  104.753485\n",
      "train loss is:  0.0713763\n",
      "iter  154500  time  99.933808\n",
      "train loss is:  0.0645955\n",
      "iter  154600  time  104.338979\n",
      "train loss is:  0.0769413\n",
      "iter  154700  time  97.946019\n",
      "train loss is:  0.0973341\n",
      "iter  154800  time  102.929761\n",
      "train loss is:  0.0653388\n",
      "iter  154900  time  103.179385\n",
      "train loss is:  0.0632732\n",
      "iter  155000  time  100.583026\n",
      "train loss is:  0.0619579\n",
      "iter  155100  time  120.89402\n",
      "train loss is:  0.0796655\n",
      "iter  155200  time  106.949814\n",
      "train loss is:  0.0341828\n",
      "iter  155300  time  107.617546\n",
      "train loss is:  0.0530772\n",
      "iter  155400  time  104.661581\n",
      "train loss is:  0.116048\n",
      "iter  155500  time  104.746225\n",
      "train loss is:  0.0575324\n",
      "iter  155600  time  102.267561\n",
      "train loss is:  0.0303452\n",
      "iter  155700  time  99.896677\n",
      "train loss is:  0.086088\n",
      "iter  155800  time  105.737365\n",
      "train loss is:  0.0775681\n",
      "iter  155900  time  112.230988\n",
      "train loss is:  0.0568333\n",
      "iter  156000  time  117.401971\n",
      "train loss is:  0.0594429\n",
      "iter  156100  time  124.556902\n",
      "train loss is:  0.0974601\n",
      "iter  156200  time  121.393221\n",
      "train loss is:  0.067117\n",
      "iter  156300  time  122.251092\n",
      "train loss is:  0.061338\n",
      "iter  156400  time  127.247397\n",
      "train loss is:  0.114698\n",
      "iter  156500  time  124.851071\n",
      "train loss is:  0.0712107\n",
      "iter  156600  time  126.228234\n",
      "train loss is:  0.070545\n",
      "iter  156700  time  123.200394\n",
      "train loss is:  0.0670772\n",
      "iter  156800  time  120.511359\n",
      "train loss is:  0.12367\n",
      "iter  156900  time  123.113999\n",
      "train loss is:  0.102325\n",
      "iter  157000  time  118.652823\n",
      "train loss is:  0.074973\n",
      "iter  157100  time  128.745435\n",
      "train loss is:  0.06308\n",
      "iter  157200  time  124.30514\n",
      "train loss is:  0.0498256\n",
      "iter  157300  time  126.273088\n",
      "train loss is:  0.0647905\n",
      "iter  157400  time  128.854271\n",
      "train loss is:  0.0721813\n",
      "iter  157500  time  132.571076\n",
      "train loss is:  0.0690674\n",
      "iter  157600  time  133.324182\n",
      "train loss is:  0.251858\n",
      "iter  157700  time  133.198778\n",
      "train loss is:  0.0671541\n",
      "iter  157800  time  131.399794\n",
      "train loss is:  0.085748\n",
      "iter  157900  time  133.100022\n",
      "train loss is:  0.0999908\n",
      "iter  158000  time  128.372007\n",
      "train loss is:  0.0828658\n",
      "iter  158100  time  122.841966\n",
      "train loss is:  0.109636\n",
      "iter  158200  time  126.145663\n",
      "train loss is:  0.103506\n",
      "iter  158300  time  127.983136\n",
      "train loss is:  0.0556879\n",
      "iter  158400  time  125.760652\n",
      "train loss is:  0.0616009\n",
      "iter  158500  time  128.254583\n",
      "train loss is:  0.0855208\n",
      "iter  158600  time  122.291137\n",
      "train loss is:  0.0906819\n",
      "iter  158700  time  121.273259\n",
      "train loss is:  0.0658138\n",
      "iter  158800  time  119.130513\n",
      "train loss is:  0.0603439\n",
      "iter  158900  time  127.476605\n",
      "train loss is:  0.231227\n",
      "iter  159000  time  123.497218\n",
      "train loss is:  0.223344\n",
      "iter  159100  time  125.889238\n",
      "train loss is:  0.0359172\n",
      "iter  159200  time  120.766536\n",
      "train loss is:  0.216693\n",
      "iter  159300  time  120.397366\n",
      "train loss is:  0.0872685\n",
      "iter  159400  time  127.612168\n",
      "train loss is:  0.0938479\n",
      "iter  159500  time  126.604399\n",
      "train loss is:  0.0626992\n",
      "iter  159600  time  123.539215\n",
      "train loss is:  0.103484\n",
      "iter  159700  time  123.53854\n",
      "train loss is:  0.0396467\n",
      "iter  159800  time  120.768713\n",
      "train loss is:  0.0877701\n",
      "iter  159900  time  125.658702\n",
      "train loss is:  0.0627931\n",
      "iter  160000  time  120.358255\n",
      "train loss is:  0.121729\n",
      "iter  160100  time  121.319911\n",
      "train loss is:  0.0686309\n",
      "iter  160200  time  125.662961\n",
      "train loss is:  0.0586181\n",
      "iter  160300  time  124.812843\n",
      "train loss is:  0.107015\n",
      "iter  160400  time  126.316842\n",
      "train loss is:  0.0852246\n",
      "iter  160500  time  121.799749\n",
      "train loss is:  0.0823784\n",
      "iter  160600  time  122.258196\n",
      "train loss is:  0.0638331\n",
      "iter  160700  time  127.599292\n",
      "train loss is:  0.0650108\n",
      "iter  160800  time  126.451625\n",
      "train loss is:  0.0621707\n",
      "iter  160900  time  119.101926\n",
      "train loss is:  0.0576723\n",
      "iter  161000  time  134.771717\n",
      "train loss is:  0.0404846\n",
      "iter  161100  time  126.992774\n",
      "train loss is:  0.0789459\n",
      "iter  161200  time  128.673828\n",
      "train loss is:  0.0983678\n",
      "iter  161300  time  124.815823\n",
      "train loss is:  0.127226\n",
      "iter  161400  time  124.964183\n",
      "train loss is:  0.0725856\n",
      "iter  161500  time  124.575856\n",
      "train loss is:  0.0655235\n",
      "iter  161600  time  124.869312\n",
      "train loss is:  0.106732\n",
      "iter  161700  time  123.569985\n",
      "train loss is:  0.0789751\n",
      "iter  161800  time  120.638661\n",
      "train loss is:  0.0992405\n",
      "iter  161900  time  110.114906\n",
      "train loss is:  0.161249\n",
      "iter  162000  time  107.60266\n",
      "train loss is:  0.0806327\n",
      "iter  162100  time  104.698929\n",
      "train loss is:  0.14596\n",
      "iter  162200  time  109.465812\n",
      "train loss is:  0.0480073\n",
      "iter  162300  time  109.0771\n",
      "train loss is:  0.0778144\n",
      "iter  162400  time  108.015746\n",
      "train loss is:  0.0626307\n",
      "iter  162500  time  109.217425\n",
      "train loss is:  0.0492942\n",
      "iter  162600  time  112.324511\n",
      "train loss is:  0.102197\n",
      "iter  162700  time  114.19763\n",
      "train loss is:  0.0547075\n",
      "iter  162800  time  109.089583\n",
      "train loss is:  0.0748981\n",
      "iter  162900  time  109.469625\n",
      "train loss is:  0.101807\n",
      "iter  163000  time  113.259079\n",
      "train loss is:  0.0719148\n",
      "iter  163100  time  119.628459\n",
      "train loss is:  0.135672\n",
      "iter  163200  time  109.52242\n",
      "train loss is:  0.0517764\n",
      "iter  163300  time  114.635115\n",
      "train loss is:  0.0666106\n",
      "iter  163400  time  113.149323\n",
      "train loss is:  0.0877674\n",
      "iter  163500  time  104.744785\n",
      "train loss is:  0.0679592\n",
      "iter  163600  time  106.345428\n",
      "train loss is:  0.0583459\n",
      "iter  163700  time  105.541112\n",
      "train loss is:  0.147479\n",
      "iter  163800  time  108.818975\n",
      "train loss is:  0.0879031\n",
      "iter  163900  time  103.474187\n",
      "train loss is:  0.137484\n",
      "iter  164000  time  119.554695\n",
      "train loss is:  0.10486\n",
      "iter  164100  time  109.807017\n",
      "train loss is:  0.0945536\n",
      "iter  164200  time  113.065761\n",
      "train loss is:  0.0759211\n",
      "iter  164300  time  125.124958\n",
      "train loss is:  0.0823213\n",
      "iter  164400  time  126.255905\n",
      "train loss is:  0.137381\n",
      "iter  164500  time  123.372212\n",
      "train loss is:  0.100897\n",
      "iter  164600  time  126.76584\n",
      "train loss is:  0.0604082\n",
      "iter  164700  time  123.265628\n",
      "train loss is:  0.0593365\n",
      "iter  164800  time  122.979097\n",
      "train loss is:  0.0423396\n",
      "iter  164900  time  122.289623\n",
      "train loss is:  0.0658934\n",
      "iter  165000  time  119.605771\n",
      "train loss is:  0.0818457\n",
      "iter  165100  time  126.015948\n",
      "train loss is:  0.0741379\n",
      "iter  165200  time  122.126474\n",
      "train loss is:  0.0709357\n",
      "iter  165300  time  126.648497\n",
      "train loss is:  0.175163\n",
      "iter  165400  time  130.100852\n",
      "train loss is:  0.0440539\n",
      "iter  165500  time  121.774443\n",
      "train loss is:  0.0715844\n",
      "iter  165600  time  121.145321\n",
      "train loss is:  0.0925224\n",
      "iter  165700  time  127.047429\n",
      "train loss is:  0.0399861\n",
      "iter  165800  time  126.501791\n",
      "train loss is:  0.0787989\n",
      "iter  165900  time  124.171496\n",
      "train loss is:  0.241176\n",
      "iter  166000  time  121.470136\n",
      "train loss is:  0.0978039\n",
      "iter  166100  time  124.057435\n",
      "train loss is:  0.0585373\n",
      "iter  166200  time  128.675762\n",
      "train loss is:  0.0819713\n",
      "iter  166300  time  130.220542\n",
      "train loss is:  0.0655533\n",
      "iter  166400  time  129.984199\n",
      "train loss is:  0.0767885\n",
      "iter  166500  time  124.377963\n",
      "train loss is:  0.0904792\n",
      "iter  166600  time  126.20453\n",
      "train loss is:  0.0568198\n",
      "iter  166700  time  121.75202\n",
      "train loss is:  0.0557955\n",
      "iter  166800  time  128.2047\n",
      "train loss is:  0.0814482\n",
      "iter  166900  time  119.476292\n",
      "train loss is:  0.0873876\n",
      "iter  167000  time  109.971412\n",
      "train loss is:  0.0892085\n",
      "iter  167100  time  113.610968\n",
      "train loss is:  0.0403085\n",
      "iter  167200  time  109.671976\n",
      "train loss is:  0.043244\n",
      "iter  167300  time  98.72205\n",
      "train loss is:  0.0759224\n",
      "iter  167400  time  105.16325\n",
      "train loss is:  0.0569401\n",
      "iter  167500  time  101.201949\n",
      "train loss is:  0.0757125\n",
      "iter  167600  time  101.01436\n",
      "train loss is:  0.104077\n",
      "iter  167700  time  107.996509\n",
      "train loss is:  0.0844759\n",
      "iter  167800  time  99.869461\n",
      "train loss is:  0.0711924\n",
      "iter  167900  time  100.231459\n",
      "train loss is:  0.0550002\n",
      "iter  168000  time  111.349759\n",
      "train loss is:  0.0540727\n",
      "iter  168100  time  104.533415\n",
      "train loss is:  0.0663535\n",
      "iter  168200  time  99.496821\n",
      "train loss is:  0.0998412\n",
      "iter  168300  time  109.233061\n",
      "train loss is:  0.0562582\n",
      "iter  168400  time  101.2035\n",
      "train loss is:  0.0525024\n",
      "iter  168500  time  103.725012\n",
      "train loss is:  0.0947893\n",
      "iter  168600  time  98.123763\n",
      "train loss is:  0.0935683\n",
      "iter  168700  time  106.128665\n",
      "train loss is:  0.0512842\n",
      "iter  168800  time  102.584146\n",
      "train loss is:  0.0704322\n",
      "iter  168900  time  97.38517\n",
      "train loss is:  0.0976658\n",
      "iter  169000  time  107.296755\n",
      "train loss is:  0.114382\n",
      "iter  169100  time  112.39095\n",
      "train loss is:  0.0629843\n",
      "iter  169200  time  101.384593\n",
      "train loss is:  0.0415105\n",
      "iter  169300  time  110.74778\n",
      "train loss is:  0.0694053\n",
      "iter  169400  time  105.258459\n",
      "train loss is:  0.19952\n",
      "iter  169500  time  100.54287\n",
      "train loss is:  0.0463423\n",
      "iter  169600  time  107.157873\n",
      "train loss is:  0.0358829\n",
      "iter  169700  time  107.495572\n",
      "train loss is:  0.0934105\n",
      "iter  169800  time  102.807408\n",
      "train loss is:  0.0740755\n",
      "iter  169900  time  114.367421\n",
      "train loss is:  0.0800761\n",
      "iter  170000  time  103.78838\n",
      "train loss is:  0.0804846\n",
      "iter  170100  time  123.56367\n",
      "train loss is:  0.0874698\n",
      "iter  170200  time  124.407716\n",
      "train loss is:  0.0796525\n",
      "iter  170300  time  119.723275\n",
      "train loss is:  0.0928578\n",
      "iter  170400  time  116.154292\n",
      "train loss is:  0.0743997\n",
      "iter  170500  time  120.53832\n",
      "train loss is:  0.056231\n",
      "iter  170600  time  123.714029\n",
      "train loss is:  0.0543071\n",
      "iter  170700  time  122.512451\n",
      "train loss is:  0.0541047\n",
      "iter  170800  time  118.792052\n",
      "train loss is:  0.132251\n",
      "iter  170900  time  121.862278\n",
      "train loss is:  0.0687283\n",
      "iter  171000  time  123.948604\n",
      "train loss is:  0.0450676\n",
      "iter  171100  time  125.436362\n",
      "train loss is:  0.110192\n",
      "iter  171200  time  121.955176\n",
      "train loss is:  0.0433332\n",
      "iter  171300  time  123.120052\n",
      "train loss is:  0.0539387\n",
      "iter  171400  time  116.980077\n",
      "train loss is:  0.10423\n",
      "iter  171500  time  119.554561\n",
      "train loss is:  0.0909283\n",
      "iter  171600  time  122.089083\n",
      "train loss is:  0.125903\n",
      "iter  171700  time  120.235765\n",
      "train loss is:  0.122083\n",
      "iter  171800  time  122.624203\n",
      "train loss is:  0.0640562\n",
      "iter  171900  time  123.732101\n",
      "train loss is:  0.0401238\n",
      "iter  172000  time  122.113418\n",
      "train loss is:  0.0759697\n",
      "iter  172100  time  125.096683\n",
      "train loss is:  0.0753659\n",
      "iter  172200  time  124.129446\n",
      "train loss is:  0.0550398\n",
      "iter  172300  time  126.020326\n",
      "train loss is:  0.0880789\n",
      "iter  172400  time  118.650715\n",
      "train loss is:  0.0729659\n",
      "iter  172500  time  122.916763\n",
      "train loss is:  0.0635918\n",
      "iter  172600  time  118.400669\n",
      "train loss is:  0.0980478\n",
      "iter  172700  time  121.793604\n",
      "train loss is:  0.137726\n",
      "iter  172800  time  116.503381\n",
      "train loss is:  0.0761808\n",
      "iter  172900  time  121.071193\n",
      "train loss is:  0.0777183\n",
      "iter  173000  time  119.461839\n",
      "train loss is:  0.0654543\n",
      "iter  173100  time  124.236856\n",
      "train loss is:  0.111325\n",
      "iter  173200  time  119.122505\n",
      "train loss is:  0.0649408\n",
      "iter  173300  time  118.401182\n",
      "train loss is:  0.0467804\n",
      "iter  173400  time  118.376784\n",
      "train loss is:  0.0578283\n",
      "iter  173500  time  120.529734\n",
      "train loss is:  0.0779761\n",
      "iter  173600  time  123.214826\n",
      "train loss is:  0.0855509\n",
      "iter  173700  time  126.042134\n",
      "train loss is:  0.092041\n",
      "iter  173800  time  132.964332\n",
      "train loss is:  0.0587117\n",
      "iter  173900  time  138.458535\n",
      "train loss is:  0.0676033\n",
      "iter  174000  time  129.685605\n",
      "train loss is:  0.0667536\n",
      "iter  174100  time  128.591891\n",
      "train loss is:  0.087539\n",
      "iter  174200  time  125.367609\n",
      "train loss is:  0.145358\n",
      "iter  174300  time  126.003678\n",
      "train loss is:  0.0681418\n",
      "iter  174400  time  122.638622\n",
      "train loss is:  0.0918568\n",
      "iter  174500  time  119.754849\n",
      "train loss is:  0.131334\n",
      "iter  174600  time  126.686701\n",
      "train loss is:  0.0590144\n",
      "iter  174700  time  128.688773\n",
      "train loss is:  0.0836719\n",
      "iter  174800  time  123.846578\n",
      "train loss is:  0.112115\n",
      "iter  174900  time  125.431501\n",
      "train loss is:  0.096178\n",
      "iter  175000  time  123.893826\n",
      "train loss is:  0.078688\n",
      "iter  175100  time  124.784476\n",
      "train loss is:  0.0837952\n",
      "iter  175200  time  123.397381\n",
      "train loss is:  0.106121\n",
      "iter  175300  time  127.306185\n",
      "train loss is:  0.0930376\n",
      "iter  175400  time  120.205648\n",
      "train loss is:  0.0540947\n",
      "iter  175500  time  120.853948\n",
      "train loss is:  0.0955519\n",
      "iter  175600  time  119.650568\n",
      "train loss is:  0.0387707\n",
      "iter  175700  time  115.864303\n",
      "train loss is:  0.0767091\n",
      "iter  175800  time  121.719684\n",
      "train loss is:  0.0576443\n",
      "iter  175900  time  125.289987\n",
      "train loss is:  0.0672285\n",
      "iter  176000  time  124.588317\n",
      "train loss is:  0.101867\n",
      "iter  176100  time  119.816942\n",
      "train loss is:  0.0649356\n",
      "iter  176200  time  127.174042\n",
      "train loss is:  0.0951819\n",
      "iter  176300  time  124.643929\n",
      "train loss is:  0.0591942\n",
      "iter  176400  time  122.418418\n",
      "train loss is:  0.0438245\n",
      "iter  176500  time  134.057388\n",
      "train loss is:  0.0535285\n",
      "iter  176600  time  132.285376\n",
      "train loss is:  0.110543\n",
      "iter  176700  time  132.538884\n",
      "train loss is:  0.0840978\n",
      "iter  176800  time  128.201077\n",
      "train loss is:  0.0583334\n",
      "iter  176900  time  128.433614\n",
      "train loss is:  0.0479716\n",
      "iter  177000  time  126.134363\n",
      "train loss is:  0.107886\n",
      "iter  177100  time  124.221846\n",
      "train loss is:  0.0702388\n",
      "iter  177200  time  120.570163\n",
      "train loss is:  0.0656355\n",
      "iter  177300  time  124.24719\n",
      "train loss is:  0.0555358\n",
      "iter  177400  time  124.560837\n",
      "train loss is:  0.0377479\n",
      "iter  177500  time  122.467862\n",
      "train loss is:  0.0535134\n",
      "iter  177600  time  120.144225\n",
      "train loss is:  0.0744812\n",
      "iter  177700  time  121.697144\n",
      "train loss is:  0.0717333\n",
      "iter  177800  time  119.901436\n",
      "train loss is:  0.112224\n",
      "iter  177900  time  124.373977\n",
      "train loss is:  0.0692937\n",
      "iter  178000  time  116.48075\n",
      "train loss is:  0.0562413\n",
      "iter  178100  time  123.478436\n",
      "train loss is:  0.0642496\n",
      "iter  178200  time  117.134959\n",
      "train loss is:  0.356213\n",
      "iter  178300  time  118.718072\n",
      "train loss is:  0.0822706\n",
      "iter  178400  time  123.294081\n",
      "train loss is:  0.0768253\n",
      "iter  178500  time  118.637656\n",
      "train loss is:  0.0680357\n",
      "iter  178600  time  116.577801\n",
      "train loss is:  0.0748097\n",
      "iter  178700  time  119.443732\n",
      "train loss is:  0.0667439\n",
      "iter  178800  time  121.723972\n",
      "train loss is:  0.0861902\n",
      "iter  178900  time  117.065842\n",
      "train loss is:  0.125801\n",
      "iter  179000  time  117.595261\n",
      "train loss is:  0.0553746\n",
      "iter  179100  time  126.838669\n",
      "train loss is:  0.0607488\n",
      "iter  179200  time  122.52616\n",
      "train loss is:  0.0620992\n",
      "iter  179300  time  123.341431\n",
      "train loss is:  0.0770834\n",
      "iter  179400  time  122.32741\n",
      "train loss is:  0.0858821\n",
      "iter  179500  time  123.771489\n",
      "train loss is:  0.0763272\n",
      "iter  179600  time  120.474868\n",
      "train loss is:  0.0619755\n",
      "iter  179700  time  122.315039\n",
      "train loss is:  0.0938426\n",
      "iter  179800  time  122.543098\n",
      "train loss is:  0.0406927\n",
      "iter  179900  time  125.40104\n",
      "train loss is:  0.0641911\n",
      "iter  180000  time  121.59512\n",
      "train loss is:  0.0541876\n",
      "iter  180100  time  122.707723\n",
      "train loss is:  0.074504\n",
      "iter  180200  time  119.82694\n",
      "train loss is:  0.0453684\n",
      "iter  180300  time  114.229275\n",
      "train loss is:  0.0611507\n",
      "iter  180400  time  111.154606\n",
      "train loss is:  0.0992553\n",
      "iter  180500  time  114.224897\n",
      "train loss is:  0.0687443\n",
      "iter  180600  time  114.934483\n",
      "train loss is:  0.0418257\n",
      "iter  180700  time  111.619419\n",
      "train loss is:  0.0642754\n",
      "iter  180800  time  114.066648\n",
      "train loss is:  0.134853\n",
      "iter  180900  time  109.2381\n",
      "train loss is:  0.0515608\n",
      "iter  181000  time  116.747629\n",
      "train loss is:  0.0811264\n",
      "iter  181100  time  119.184352\n",
      "train loss is:  0.0533521\n",
      "iter  181200  time  112.05471\n",
      "train loss is:  0.0749431\n",
      "iter  181300  time  115.777886\n",
      "train loss is:  0.0900415\n",
      "iter  181400  time  121.065853\n",
      "train loss is:  0.0482373\n",
      "iter  181500  time  112.828099\n",
      "train loss is:  0.117952\n",
      "iter  181600  time  119.568761\n",
      "train loss is:  0.11416\n",
      "iter  181700  time  107.86594\n",
      "train loss is:  0.0656991\n",
      "iter  181800  time  117.139724\n",
      "train loss is:  0.0475106\n",
      "iter  181900  time  117.386289\n",
      "train loss is:  0.150295\n",
      "iter  182000  time  111.179873\n",
      "train loss is:  0.0583273\n",
      "iter  182100  time  112.210258\n",
      "train loss is:  0.0530534\n",
      "iter  182200  time  113.481362\n",
      "train loss is:  0.0631411\n",
      "iter  182300  time  115.248407\n",
      "train loss is:  0.064687\n",
      "iter  182400  time  119.572147\n",
      "train loss is:  0.0516406\n",
      "iter  182500  time  112.079272\n",
      "train loss is:  0.0523164\n",
      "iter  182600  time  123.471017\n",
      "train loss is:  0.0445078\n",
      "iter  182700  time  116.03005\n",
      "train loss is:  0.106377\n",
      "iter  182800  time  116.576472\n",
      "train loss is:  0.0938817\n",
      "iter  182900  time  121.371697\n",
      "train loss is:  0.0623041\n",
      "iter  183000  time  112.135384\n",
      "train loss is:  0.0850475\n",
      "iter  183100  time  119.587211\n",
      "train loss is:  0.0503774\n",
      "iter  183200  time  116.149055\n",
      "train loss is:  0.0588953\n",
      "iter  183300  time  114.188885\n",
      "train loss is:  0.0619999\n",
      "iter  183400  time  117.660078\n",
      "train loss is:  0.0561255\n",
      "iter  183500  time  120.63958\n",
      "train loss is:  0.056602\n",
      "iter  183600  time  113.28381\n",
      "train loss is:  0.065811\n",
      "iter  183700  time  119.62824\n",
      "train loss is:  0.100194\n",
      "iter  183800  time  118.389344\n",
      "train loss is:  0.0696971\n",
      "iter  183900  time  121.115995\n",
      "train loss is:  0.116166\n",
      "iter  184000  time  113.618711\n",
      "train loss is:  0.0626666\n",
      "iter  184100  time  115.547221\n",
      "train loss is:  0.0406966\n",
      "iter  184200  time  111.927972\n",
      "train loss is:  0.0549104\n",
      "iter  184300  time  119.957208\n",
      "train loss is:  0.0932873\n",
      "iter  184400  time  117.850093\n",
      "train loss is:  0.0791243\n",
      "iter  184500  time  120.417347\n",
      "train loss is:  0.0420376\n",
      "iter  184600  time  112.890563\n",
      "train loss is:  0.0861224\n",
      "iter  184700  time  115.413793\n",
      "train loss is:  0.0434642\n",
      "iter  184800  time  118.858764\n",
      "train loss is:  0.0847049\n",
      "iter  184900  time  119.041183\n",
      "train loss is:  0.0880989\n",
      "iter  185000  time  117.272844\n",
      "train loss is:  0.0562936\n",
      "iter  185100  time  119.513203\n",
      "train loss is:  0.0604041\n",
      "iter  185200  time  121.519018\n",
      "train loss is:  0.171858\n",
      "iter  185300  time  117.670478\n",
      "train loss is:  0.058201\n",
      "iter  185400  time  121.599175\n",
      "train loss is:  0.146926\n",
      "iter  185500  time  112.961235\n",
      "train loss is:  0.0507459\n",
      "iter  185600  time  109.812362\n",
      "train loss is:  0.0591466\n",
      "iter  185700  time  114.331602\n",
      "train loss is:  0.0525393\n",
      "iter  185800  time  118.422355\n",
      "train loss is:  0.104289\n",
      "iter  185900  time  117.655526\n",
      "train loss is:  0.0613874\n",
      "iter  186000  time  123.170628\n",
      "train loss is:  0.0654324\n",
      "iter  186100  time  120.225198\n",
      "train loss is:  0.0951093\n",
      "iter  186200  time  118.666275\n",
      "train loss is:  0.0646586\n",
      "iter  186300  time  111.3101\n",
      "train loss is:  0.0840194\n",
      "iter  186400  time  112.339916\n",
      "train loss is:  0.0674316\n",
      "iter  186500  time  116.606217\n",
      "train loss is:  0.0680056\n",
      "iter  186600  time  114.142068\n",
      "train loss is:  0.0361869\n",
      "iter  186700  time  119.351365\n",
      "train loss is:  0.0551945\n",
      "iter  186800  time  114.222094\n",
      "train loss is:  0.0802004\n",
      "iter  186900  time  115.629862\n",
      "train loss is:  0.0489816\n",
      "iter  187000  time  106.815306\n",
      "train loss is:  0.0974386\n",
      "iter  187100  time  116.531907\n",
      "train loss is:  0.0602371\n",
      "iter  187200  time  116.798915\n",
      "train loss is:  0.0559009\n",
      "iter  187300  time  117.945407\n",
      "train loss is:  0.210598\n",
      "iter  187400  time  117.928089\n",
      "train loss is:  0.0800402\n",
      "iter  187500  time  125.055684\n",
      "train loss is:  0.0516359\n",
      "iter  187600  time  113.850937\n",
      "train loss is:  0.0665221\n",
      "iter  187700  time  117.258886\n",
      "train loss is:  0.134065\n",
      "iter  187800  time  120.729223\n",
      "train loss is:  0.0729525\n",
      "iter  187900  time  111.630061\n",
      "train loss is:  0.0349846\n",
      "iter  188000  time  116.343681\n",
      "train loss is:  0.099271\n",
      "iter  188100  time  119.193045\n",
      "train loss is:  0.0602145\n",
      "iter  188200  time  113.316186\n",
      "train loss is:  0.0829756\n",
      "iter  188300  time  118.470969\n",
      "train loss is:  0.0675696\n",
      "iter  188400  time  112.62209\n",
      "train loss is:  0.0663402\n",
      "iter  188500  time  117.499073\n",
      "train loss is:  0.050318\n",
      "iter  188600  time  122.762044\n",
      "train loss is:  0.0378531\n",
      "iter  188700  time  116.261449\n",
      "train loss is:  0.0885504\n",
      "iter  188800  time  115.521451\n",
      "train loss is:  0.0713709\n",
      "iter  188900  time  113.510025\n",
      "train loss is:  0.0660511\n",
      "iter  189000  time  118.772813\n",
      "train loss is:  0.044848\n",
      "iter  189100  time  117.755694\n",
      "train loss is:  0.0390256\n",
      "iter  189200  time  118.919296\n",
      "train loss is:  0.0610239\n",
      "iter  189300  time  112.644709\n",
      "train loss is:  0.0702966\n",
      "iter  189400  time  113.38689\n",
      "train loss is:  0.0414182\n",
      "iter  189500  time  114.153709\n",
      "train loss is:  0.0524767\n",
      "iter  189600  time  114.12669\n",
      "train loss is:  0.0662178\n",
      "iter  189700  time  117.49738\n",
      "train loss is:  0.0701974\n",
      "iter  189800  time  112.870788\n",
      "train loss is:  0.0662205\n",
      "iter  189900  time  118.737176\n",
      "train loss is:  0.0564152\n",
      "iter  190000  time  121.572786\n",
      "train loss is:  0.0537803\n",
      "iter  190100  time  126.172893\n",
      "train loss is:  0.0686182\n",
      "iter  190200  time  120.833627\n",
      "train loss is:  0.0296951\n",
      "iter  190300  time  116.297611\n",
      "train loss is:  0.106739\n",
      "iter  190400  time  112.824875\n",
      "train loss is:  0.0531794\n",
      "iter  190500  time  123.588081\n",
      "train loss is:  0.0814472\n",
      "iter  190600  time  114.255173\n",
      "train loss is:  0.0694195\n",
      "iter  190700  time  110.857156\n",
      "train loss is:  0.0762404\n",
      "iter  190800  time  114.565496\n",
      "train loss is:  0.0506706\n",
      "iter  190900  time  116.589184\n",
      "train loss is:  0.0545839\n",
      "iter  191000  time  112.833928\n",
      "train loss is:  0.0579349\n",
      "iter  191100  time  112.159392\n",
      "train loss is:  0.0778621\n",
      "iter  191200  time  114.916291\n",
      "train loss is:  0.0494105\n",
      "iter  191300  time  106.440685\n",
      "train loss is:  0.0618281\n",
      "iter  191400  time  119.314747\n",
      "train loss is:  0.0562131\n",
      "iter  191500  time  110.016949\n",
      "train loss is:  0.0645846\n",
      "iter  191600  time  111.917553\n",
      "train loss is:  0.0577633\n",
      "iter  191700  time  113.029795\n",
      "train loss is:  0.0405049\n",
      "iter  191800  time  112.950449\n",
      "train loss is:  0.0818967\n",
      "iter  191900  time  118.064703\n",
      "train loss is:  0.0505103\n",
      "iter  192000  time  115.739101\n",
      "train loss is:  0.0796908\n",
      "iter  192100  time  111.684031\n",
      "train loss is:  0.125095\n",
      "iter  192200  time  117.529376\n",
      "train loss is:  0.0809997\n",
      "iter  192300  time  112.364328\n",
      "train loss is:  0.0600032\n",
      "iter  192400  time  120.481874\n",
      "train loss is:  0.0531089\n",
      "iter  192500  time  109.775338\n",
      "train loss is:  0.0379735\n",
      "iter  192600  time  114.618484\n",
      "train loss is:  0.0844755\n",
      "iter  192700  time  109.081651\n",
      "train loss is:  0.0583232\n",
      "iter  192800  time  113.776556\n",
      "train loss is:  0.117693\n",
      "iter  192900  time  115.888756\n",
      "train loss is:  0.0637816\n",
      "iter  193000  time  122.718759\n",
      "train loss is:  0.0605149\n",
      "iter  193100  time  110.517968\n",
      "train loss is:  0.0767361\n",
      "iter  193200  time  122.172423\n",
      "train loss is:  0.0541334\n",
      "iter  193300  time  112.561578\n",
      "train loss is:  0.0755145\n",
      "iter  193400  time  108.932315\n",
      "train loss is:  0.0494321\n",
      "iter  193500  time  115.19213\n",
      "train loss is:  0.0379012\n",
      "iter  193600  time  118.136525\n",
      "train loss is:  0.0400971\n",
      "iter  193700  time  115.877614\n",
      "train loss is:  0.0629454\n",
      "iter  193800  time  107.18868\n",
      "train loss is:  0.0614118\n",
      "iter  193900  time  119.366829\n",
      "train loss is:  0.0633074\n",
      "iter  194000  time  117.094519\n",
      "train loss is:  0.0370408\n",
      "iter  194100  time  115.798852\n",
      "train loss is:  0.102133\n",
      "iter  194200  time  115.892868\n",
      "train loss is:  0.0797022\n",
      "iter  194300  time  122.586745\n",
      "train loss is:  0.115637\n",
      "iter  194400  time  113.568593\n",
      "train loss is:  0.0429697\n",
      "iter  194500  time  114.023915\n",
      "train loss is:  0.0601288\n",
      "iter  194600  time  115.158586\n",
      "train loss is:  0.0382513\n",
      "iter  194700  time  118.118987\n",
      "train loss is:  0.0596051\n",
      "iter  194800  time  116.336719\n",
      "train loss is:  0.0760565\n",
      "iter  194900  time  114.698222\n",
      "train loss is:  0.0824771\n",
      "iter  195000  time  118.37344\n",
      "train loss is:  0.0519173\n",
      "iter  195100  time  119.515043\n",
      "train loss is:  0.0305032\n",
      "iter  195200  time  112.325173\n",
      "train loss is:  0.0648791\n",
      "iter  195300  time  117.192228\n",
      "train loss is:  0.0716377\n",
      "iter  195400  time  108.036783\n",
      "train loss is:  0.0940004\n",
      "iter  195500  time  120.625576\n",
      "train loss is:  0.088365\n",
      "iter  195600  time  118.519821\n",
      "train loss is:  0.11607\n",
      "iter  195700  time  119.035242\n",
      "train loss is:  0.0561303\n",
      "iter  195800  time  116.209443\n",
      "train loss is:  0.0841654\n",
      "iter  195900  time  109.50044\n",
      "train loss is:  0.0465719\n",
      "iter  196000  time  115.760075\n",
      "train loss is:  0.0708774\n",
      "iter  196100  time  123.194928\n",
      "train loss is:  0.111528\n",
      "iter  196200  time  109.037231\n",
      "train loss is:  0.0613512\n",
      "iter  196300  time  116.069035\n",
      "train loss is:  0.0598687\n",
      "iter  196400  time  114.2198\n",
      "train loss is:  0.0634192\n",
      "iter  196500  time  113.131058\n",
      "train loss is:  0.10582\n",
      "iter  196600  time  114.35836\n",
      "train loss is:  0.0332507\n",
      "iter  196700  time  110.594976\n",
      "train loss is:  0.0766905\n",
      "iter  196800  time  116.926577\n",
      "train loss is:  0.0532655\n",
      "iter  196900  time  119.597121\n",
      "train loss is:  0.0626657\n",
      "iter  197000  time  113.723848\n",
      "train loss is:  0.246123\n",
      "iter  197100  time  124.653252\n",
      "train loss is:  0.0750865\n",
      "iter  197200  time  120.140897\n",
      "train loss is:  0.0817907\n",
      "iter  197300  time  111.020186\n",
      "train loss is:  0.089183\n",
      "iter  197400  time  110.256424\n",
      "train loss is:  0.137444\n",
      "iter  197500  time  108.736627\n",
      "train loss is:  0.0552713\n",
      "iter  197600  time  115.320113\n",
      "train loss is:  0.0460841\n",
      "iter  197700  time  119.66845\n",
      "train loss is:  0.0901834\n",
      "iter  197800  time  111.465885\n",
      "train loss is:  0.0593973\n",
      "iter  197900  time  116.513546\n",
      "train loss is:  0.0508239\n",
      "iter  198000  time  113.057717\n",
      "train loss is:  0.0461518\n",
      "iter  198100  time  114.623993\n",
      "train loss is:  0.0825879\n",
      "iter  198200  time  117.523381\n",
      "train loss is:  0.0410927\n",
      "iter  198300  time  117.623731\n",
      "train loss is:  0.0684952\n",
      "iter  198400  time  112.655958\n",
      "train loss is:  0.0601753\n",
      "iter  198500  time  110.726776\n",
      "train loss is:  0.129891\n",
      "iter  198600  time  110.723227\n",
      "train loss is:  0.0670152\n",
      "iter  198700  time  114.09732\n",
      "train loss is:  0.0524768\n",
      "iter  198800  time  110.024462\n",
      "train loss is:  0.0579883\n",
      "iter  198900  time  117.833148\n",
      "train loss is:  0.068009\n",
      "iter  199000  time  118.959835\n",
      "train loss is:  0.0331809\n",
      "iter  199100  time  120.498106\n",
      "train loss is:  0.0680911\n",
      "iter  199200  time  117.609923\n",
      "train loss is:  0.0639073\n",
      "iter  199300  time  115.086162\n",
      "train loss is:  0.0630215\n",
      "iter  199400  time  118.250201\n",
      "train loss is:  0.0654476\n",
      "iter  199500  time  115.500796\n",
      "train loss is:  0.0383481\n",
      "iter  199600  time  113.348324\n",
      "train loss is:  0.0574034\n",
      "iter  199700  time  120.226626\n",
      "train loss is:  0.040691\n",
      "iter  199800  time  114.818148\n",
      "train loss is:  0.0305482\n",
      "iter  199900  time  120.398502\n",
      "train loss is:  0.0754078\n",
      "iter  200000  time  118.368506\n",
      "train loss is:  0.0720781\n",
      "iter  200100  time  123.172793\n",
      "train loss is:  0.139981\n",
      "iter  200200  time  118.959195\n",
      "train loss is:  0.0603138\n",
      "iter  200300  time  109.863629\n",
      "train loss is:  0.0322487\n",
      "iter  200400  time  116.175373\n",
      "train loss is:  0.0589507\n",
      "iter  200500  time  117.772583\n",
      "train loss is:  0.0478831\n",
      "iter  200600  time  110.581126\n",
      "train loss is:  0.0508446\n",
      "iter  200700  time  115.823653\n",
      "train loss is:  0.0399682\n",
      "iter  200800  time  117.525321\n",
      "train loss is:  0.0786588\n",
      "iter  200900  time  115.683657\n",
      "train loss is:  0.0594594\n",
      "iter  201000  time  110.151766\n",
      "train loss is:  0.0639016\n",
      "iter  201100  time  114.094577\n",
      "train loss is:  0.0700223\n",
      "iter  201200  time  113.424162\n",
      "train loss is:  0.110732\n",
      "iter  201300  time  116.745715\n",
      "train loss is:  0.208949\n",
      "iter  201400  time  114.443032\n",
      "train loss is:  0.0584728\n",
      "iter  201500  time  110.306882\n",
      "train loss is:  0.0414589\n",
      "iter  201600  time  115.576874\n",
      "train loss is:  0.0726278\n",
      "iter  201700  time  108.458466\n",
      "train loss is:  0.0344262\n",
      "iter  201800  time  114.772039\n",
      "train loss is:  0.0806388\n",
      "iter  201900  time  113.429257\n",
      "train loss is:  0.0678798\n",
      "iter  202000  time  112.740935\n",
      "train loss is:  0.0696381\n",
      "iter  202100  time  120.026613\n",
      "train loss is:  0.0742792\n",
      "iter  202200  time  113.812704\n",
      "train loss is:  0.0432497\n",
      "iter  202300  time  116.087338\n",
      "train loss is:  0.0680943\n",
      "iter  202400  time  121.487178\n",
      "train loss is:  0.0705592\n",
      "iter  202500  time  117.982071\n",
      "train loss is:  0.043383\n",
      "iter  202600  time  118.641621\n",
      "train loss is:  0.0625182\n",
      "iter  202700  time  114.635896\n",
      "train loss is:  0.0556114\n",
      "iter  202800  time  122.429544\n",
      "train loss is:  0.0511689\n",
      "iter  202900  time  114.051651\n",
      "train loss is:  0.101966\n",
      "iter  203000  time  113.481264\n",
      "train loss is:  0.0812271\n",
      "iter  203100  time  117.794491\n",
      "train loss is:  0.0897065\n",
      "iter  203200  time  116.541326\n",
      "train loss is:  0.0556133\n",
      "iter  203300  time  113.927082\n",
      "train loss is:  0.0468415\n",
      "iter  203400  time  117.069101\n",
      "train loss is:  0.0443747\n",
      "iter  203500  time  115.784217\n",
      "train loss is:  0.0657299\n",
      "iter  203600  time  115.689566\n",
      "train loss is:  0.0668813\n",
      "iter  203700  time  119.585247\n",
      "train loss is:  0.0488852\n",
      "iter  203800  time  119.392491\n",
      "train loss is:  0.0554113\n",
      "iter  203900  time  115.430037\n",
      "train loss is:  0.0901862\n",
      "iter  204000  time  113.419266\n",
      "train loss is:  0.0861479\n",
      "iter  204100  time  116.78014\n",
      "train loss is:  0.0607818\n",
      "iter  204200  time  118.069573\n",
      "train loss is:  0.0528028\n",
      "iter  204300  time  116.533773\n",
      "train loss is:  0.0599867\n",
      "iter  204400  time  102.360836\n",
      "train loss is:  0.0634788\n",
      "iter  204500  time  115.357312\n",
      "train loss is:  0.0541592\n",
      "iter  204600  time  107.769098\n",
      "train loss is:  0.0422151\n",
      "iter  204700  time  119.567256\n",
      "train loss is:  0.0445186\n",
      "iter  204800  time  108.782812\n",
      "train loss is:  0.0822431\n",
      "iter  204900  time  115.425097\n",
      "train loss is:  0.0683169\n",
      "iter  205000  time  117.523015\n",
      "train loss is:  0.112146\n",
      "iter  205100  time  119.584573\n",
      "train loss is:  0.0361772\n",
      "iter  205200  time  111.601991\n",
      "train loss is:  0.114959\n",
      "iter  205300  time  119.263809\n",
      "train loss is:  0.0717213\n",
      "iter  205400  time  120.155462\n",
      "train loss is:  0.0483577\n",
      "iter  205500  time  113.368523\n",
      "train loss is:  0.054882\n",
      "iter  205600  time  114.816273\n",
      "train loss is:  0.142387\n",
      "iter  205700  time  112.398775\n",
      "train loss is:  0.0550858\n",
      "iter  205800  time  110.431051\n",
      "train loss is:  0.0655267\n",
      "iter  205900  time  121.236833\n",
      "train loss is:  0.0859224\n",
      "iter  206000  time  117.556969\n",
      "train loss is:  0.0757608\n",
      "iter  206100  time  114.579002\n",
      "train loss is:  0.105408\n",
      "iter  206200  time  107.864872\n",
      "train loss is:  0.0854016\n",
      "iter  206300  time  114.737427\n",
      "train loss is:  0.0684519\n",
      "iter  206400  time  116.829065\n",
      "train loss is:  0.0479889\n",
      "iter  206500  time  113.724686\n",
      "train loss is:  0.112728\n",
      "iter  206600  time  113.69185\n",
      "train loss is:  0.0471618\n",
      "iter  206700  time  116.878238\n",
      "train loss is:  0.0671785\n",
      "iter  206800  time  114.298399\n",
      "train loss is:  0.0492823\n",
      "iter  206900  time  121.034651\n",
      "train loss is:  0.150879\n",
      "iter  207000  time  117.715616\n",
      "train loss is:  0.0838852\n",
      "iter  207100  time  118.271706\n",
      "train loss is:  0.104437\n",
      "iter  207200  time  120.174912\n",
      "train loss is:  0.0600964\n",
      "iter  207300  time  123.234973\n",
      "train loss is:  0.061652\n",
      "iter  207400  time  116.720598\n",
      "train loss is:  0.0576583\n",
      "iter  207500  time  117.254866\n",
      "train loss is:  0.0477728\n",
      "iter  207600  time  115.832858\n",
      "train loss is:  0.0551638\n",
      "iter  207700  time  117.410567\n",
      "train loss is:  0.0695801\n",
      "iter  207800  time  118.226613\n",
      "train loss is:  0.0597831\n",
      "iter  207900  time  118.241863\n",
      "train loss is:  0.0859876\n",
      "iter  208000  time  123.993541\n",
      "train loss is:  0.0730209\n",
      "iter  208100  time  118.13734\n",
      "train loss is:  0.0545098\n",
      "iter  208200  time  120.753579\n",
      "train loss is:  0.0879582\n",
      "iter  208300  time  117.388306\n",
      "train loss is:  0.0778565\n",
      "iter  208400  time  116.376712\n",
      "train loss is:  0.075619\n",
      "iter  208500  time  116.182197\n",
      "train loss is:  0.0878818\n",
      "iter  208600  time  116.52002\n",
      "train loss is:  0.111097\n",
      "iter  208700  time  115.298367\n",
      "train loss is:  0.10954\n",
      "iter  208800  time  117.920421\n",
      "train loss is:  0.0358342\n",
      "iter  208900  time  112.633772\n",
      "train loss is:  0.0928132\n",
      "iter  209000  time  114.100958\n",
      "train loss is:  0.0600031\n",
      "iter  209100  time  118.650844\n",
      "train loss is:  0.0609222\n",
      "iter  209200  time  121.073329\n",
      "train loss is:  0.0864362\n",
      "iter  209300  time  116.34524\n",
      "train loss is:  0.0585674\n",
      "iter  209400  time  109.978222\n",
      "train loss is:  0.0480259\n",
      "iter  209500  time  110.045054\n",
      "train loss is:  0.0558857\n",
      "iter  209600  time  122.419535\n",
      "train loss is:  0.0551428\n",
      "iter  209700  time  116.830434\n",
      "train loss is:  0.0382825\n",
      "iter  209800  time  115.600111\n",
      "train loss is:  0.0293475\n",
      "iter  209900  time  111.879005\n",
      "train loss is:  0.0328366\n",
      "iter  210000  time  118.318435\n",
      "train loss is:  0.0683673\n",
      "iter  210100  time  120.996531\n",
      "train loss is:  0.0383912\n",
      "iter  210200  time  115.144115\n",
      "train loss is:  0.0407655\n",
      "iter  210300  time  115.235195\n",
      "train loss is:  0.0698105\n",
      "iter  210400  time  110.674676\n",
      "train loss is:  0.0734223\n",
      "iter  210500  time  110.76462\n",
      "train loss is:  0.0373727\n",
      "iter  210600  time  109.215499\n",
      "train loss is:  0.0770482\n",
      "iter  210700  time  120.237756\n",
      "train loss is:  0.0391944\n",
      "iter  210800  time  116.250715\n",
      "train loss is:  0.0729615\n",
      "iter  210900  time  117.133841\n",
      "train loss is:  0.0426608\n",
      "iter  211000  time  114.352928\n",
      "train loss is:  0.0531213\n",
      "iter  211100  time  116.673011\n",
      "train loss is:  0.0430447\n",
      "iter  211200  time  124.992441\n",
      "train loss is:  0.140655\n",
      "iter  211300  time  125.226724\n",
      "train loss is:  0.0471934\n",
      "iter  211400  time  120.110704\n",
      "train loss is:  0.0447146\n",
      "iter  211500  time  123.326295\n",
      "train loss is:  0.0801555\n",
      "iter  211600  time  122.497052\n",
      "train loss is:  0.12424\n",
      "iter  211700  time  121.260116\n",
      "train loss is:  0.0806083\n",
      "iter  211800  time  123.962513\n",
      "train loss is:  0.0706683\n",
      "iter  211900  time  124.953144\n",
      "train loss is:  0.0668309\n",
      "iter  212000  time  125.640568\n",
      "train loss is:  0.063235\n",
      "iter  212100  time  127.514252\n",
      "train loss is:  0.0604336\n",
      "iter  212200  time  117.64264\n",
      "train loss is:  0.0647269\n",
      "iter  212300  time  124.862761\n",
      "train loss is:  0.0830078\n",
      "iter  212400  time  131.305593\n",
      "train loss is:  0.0622389\n",
      "iter  212500  time  131.807411\n",
      "train loss is:  0.0656668\n",
      "iter  212600  time  126.130915\n",
      "train loss is:  0.0754615\n",
      "iter  212700  time  115.557394\n",
      "train loss is:  0.0517461\n",
      "iter  212800  time  120.975656\n",
      "train loss is:  0.133486\n",
      "iter  212900  time  113.619719\n",
      "train loss is:  0.045794\n",
      "iter  213000  time  112.347473\n",
      "train loss is:  0.0517249\n",
      "iter  213100  time  119.933103\n",
      "train loss is:  0.0474631\n",
      "iter  213200  time  113.462807\n",
      "train loss is:  0.0738676\n",
      "iter  213300  time  115.626333\n",
      "train loss is:  0.0549072\n",
      "iter  213400  time  110.011012\n",
      "train loss is:  0.115795\n",
      "iter  213500  time  110.502232\n",
      "train loss is:  0.065806\n",
      "iter  213600  time  105.541532\n",
      "train loss is:  0.059312\n",
      "iter  213700  time  107.217229\n",
      "train loss is:  0.0379017\n",
      "iter  213800  time  116.879157\n",
      "train loss is:  0.0483496\n",
      "iter  213900  time  117.022831\n",
      "train loss is:  0.0546478\n",
      "iter  214000  time  111.743264\n",
      "train loss is:  0.0410323\n",
      "iter  214100  time  125.386515\n",
      "train loss is:  0.0388988\n",
      "iter  214200  time  117.195622\n",
      "train loss is:  0.041087\n",
      "iter  214300  time  114.263077\n",
      "train loss is:  0.0715023\n",
      "iter  214400  time  120.000244\n",
      "train loss is:  0.0532448\n",
      "iter  214500  time  118.103045\n",
      "train loss is:  0.0456474\n",
      "iter  214600  time  116.252759\n",
      "train loss is:  0.0648125\n",
      "iter  214700  time  111.966276\n",
      "train loss is:  0.0694085\n",
      "iter  214800  time  112.771861\n",
      "train loss is:  0.0538882\n",
      "iter  214900  time  118.517408\n",
      "train loss is:  0.0545363\n",
      "iter  215000  time  119.096302\n",
      "train loss is:  0.0463998\n",
      "iter  215100  time  117.542218\n",
      "train loss is:  0.0564264\n",
      "iter  215200  time  109.226989\n",
      "train loss is:  0.0679876\n",
      "iter  215300  time  118.544826\n",
      "train loss is:  0.0649267\n",
      "iter  215400  time  119.454337\n",
      "train loss is:  0.0432855\n",
      "iter  215500  time  112.285056\n",
      "train loss is:  0.0511873\n",
      "iter  215600  time  116.356786\n",
      "train loss is:  0.0482425\n",
      "iter  215700  time  108.947712\n",
      "train loss is:  0.059553\n",
      "iter  215800  time  110.294662\n",
      "train loss is:  0.135819\n",
      "iter  215900  time  113.337551\n",
      "train loss is:  0.0476175\n",
      "iter  216000  time  119.701593\n",
      "train loss is:  0.0621301\n",
      "iter  216100  time  117.243589\n",
      "train loss is:  0.0591443\n",
      "iter  216200  time  106.539753\n",
      "train loss is:  0.0685343\n",
      "iter  216300  time  116.503003\n",
      "train loss is:  0.0948608\n",
      "iter  216400  time  106.87761\n",
      "train loss is:  0.0432537\n",
      "iter  216500  time  114.048803\n",
      "train loss is:  0.0430189\n",
      "iter  216600  time  107.598882\n",
      "train loss is:  0.0914292\n",
      "iter  216700  time  113.065398\n",
      "train loss is:  0.081784\n",
      "iter  216800  time  105.342927\n",
      "train loss is:  0.118253\n",
      "iter  216900  time  109.706223\n",
      "train loss is:  0.0692383\n",
      "iter  217000  time  114.880785\n",
      "train loss is:  0.0722479\n",
      "iter  217100  time  119.111497\n",
      "train loss is:  0.0346366\n",
      "iter  217200  time  118.959922\n",
      "train loss is:  0.14586\n",
      "iter  217300  time  113.575039\n",
      "train loss is:  0.069867\n",
      "iter  217400  time  113.843001\n",
      "train loss is:  0.0728112\n",
      "iter  217500  time  111.819942\n",
      "train loss is:  0.050836\n",
      "iter  217600  time  110.903319\n",
      "train loss is:  0.0698672\n",
      "iter  217700  time  113.603753\n",
      "train loss is:  0.0336847\n",
      "iter  217800  time  113.566336\n",
      "train loss is:  0.110836\n",
      "iter  217900  time  111.952831\n",
      "train loss is:  0.0700162\n",
      "iter  218000  time  113.938792\n",
      "train loss is:  0.0631953\n",
      "iter  218100  time  123.346711\n",
      "train loss is:  0.0252658\n",
      "iter  218200  time  107.301671\n",
      "train loss is:  0.0668463\n",
      "iter  218300  time  117.482724\n",
      "train loss is:  0.0483158\n",
      "iter  218400  time  109.63325\n",
      "train loss is:  0.0580207\n",
      "iter  218500  time  114.805467\n",
      "train loss is:  0.131381\n",
      "iter  218600  time  117.005506\n",
      "train loss is:  0.0466004\n",
      "iter  218700  time  112.174062\n",
      "train loss is:  0.10462\n",
      "iter  218800  time  109.805297\n",
      "train loss is:  0.0450109\n",
      "iter  218900  time  109.676199\n",
      "train loss is:  0.0669948\n",
      "iter  219000  time  113.047741\n",
      "train loss is:  0.0913986\n",
      "iter  219100  time  111.641794\n",
      "train loss is:  0.0583157\n",
      "iter  219200  time  112.787634\n",
      "train loss is:  0.0498865\n",
      "iter  219300  time  113.339682\n",
      "train loss is:  0.0715834\n",
      "iter  219400  time  114.488105\n",
      "train loss is:  0.0645479\n",
      "iter  219500  time  112.281125\n",
      "train loss is:  0.120945\n",
      "iter  219600  time  117.379247\n",
      "train loss is:  0.122656\n",
      "iter  219700  time  115.851801\n",
      "train loss is:  0.0533019\n",
      "iter  219800  time  120.653307\n",
      "train loss is:  0.04039\n",
      "iter  219900  time  118.293904\n",
      "train loss is:  0.0635413\n",
      "iter  220000  time  113.375863\n",
      "train loss is:  0.0566588\n",
      "iter  220100  time  117.061299\n",
      "train loss is:  0.0581849\n",
      "iter  220200  time  108.732882\n",
      "train loss is:  0.0617722\n",
      "iter  220300  time  109.755922\n",
      "train loss is:  0.04184\n",
      "iter  220400  time  119.791462\n",
      "train loss is:  0.0553249\n",
      "iter  220500  time  113.157498\n",
      "train loss is:  0.0408928\n",
      "iter  220600  time  116.830192\n",
      "train loss is:  0.0494566\n",
      "iter  220700  time  107.991991\n",
      "train loss is:  0.0590984\n",
      "iter  220800  time  105.985986\n",
      "train loss is:  0.0444274\n",
      "iter  220900  time  108.603921\n",
      "train loss is:  0.0511746\n",
      "iter  221000  time  108.893601\n",
      "train loss is:  0.0569209\n",
      "iter  221100  time  105.820905\n",
      "train loss is:  0.0734765\n",
      "iter  221200  time  110.259842\n",
      "train loss is:  0.0665499\n",
      "iter  221300  time  111.126949\n",
      "train loss is:  0.106551\n",
      "iter  221400  time  108.281086\n",
      "train loss is:  0.134602\n",
      "iter  221500  time  109.34633\n",
      "train loss is:  0.0701001\n",
      "iter  221600  time  110.882751\n",
      "train loss is:  0.149786\n",
      "iter  221700  time  107.603075\n",
      "train loss is:  0.040375\n",
      "iter  221800  time  114.36506\n",
      "train loss is:  0.0416147\n",
      "iter  221900  time  108.080721\n",
      "train loss is:  0.0470247\n",
      "iter  222000  time  110.186844\n",
      "train loss is:  0.0601633\n",
      "iter  222100  time  108.203871\n",
      "train loss is:  0.0377156\n",
      "iter  222200  time  114.358433\n",
      "train loss is:  0.047239\n",
      "iter  222300  time  102.845092\n",
      "train loss is:  0.0476452\n",
      "iter  222400  time  115.982877\n",
      "train loss is:  0.0463209\n",
      "iter  222500  time  112.634362\n",
      "train loss is:  0.0409832\n",
      "iter  222600  time  116.046863\n",
      "train loss is:  0.0416101\n",
      "iter  222700  time  119.010287\n",
      "train loss is:  0.135984\n",
      "iter  222800  time  109.982115\n",
      "train loss is:  0.0974834\n",
      "iter  222900  time  113.422337\n",
      "train loss is:  0.0425725\n",
      "iter  223000  time  110.866463\n",
      "train loss is:  0.0467504\n",
      "iter  223100  time  112.298948\n",
      "train loss is:  0.0778115\n",
      "iter  223200  time  110.662887\n",
      "train loss is:  0.0400449\n",
      "iter  223300  time  110.857474\n",
      "train loss is:  0.0746526\n",
      "iter  223400  time  108.261946\n",
      "train loss is:  0.0287661\n",
      "iter  223500  time  111.095014\n",
      "train loss is:  0.0730969\n",
      "iter  223600  time  111.711709\n",
      "train loss is:  0.107319\n",
      "iter  223700  time  111.88528\n",
      "train loss is:  0.06255\n",
      "iter  223800  time  111.102482\n",
      "train loss is:  0.0631866\n",
      "iter  223900  time  104.953112\n",
      "train loss is:  0.0918572\n",
      "iter  224000  time  106.000862\n",
      "train loss is:  0.0804781\n",
      "iter  224100  time  116.548597\n",
      "train loss is:  0.0373607\n",
      "iter  224200  time  100.448973\n",
      "train loss is:  0.0741208\n",
      "iter  224300  time  109.617053\n",
      "train loss is:  0.0651001\n",
      "iter  224400  time  109.315635\n",
      "train loss is:  0.0773186\n",
      "iter  224500  time  109.496368\n",
      "train loss is:  0.0830706\n",
      "iter  224600  time  101.341893\n",
      "train loss is:  0.0915912\n",
      "iter  224700  time  105.916427\n",
      "train loss is:  0.0607229\n",
      "iter  224800  time  104.04558\n",
      "train loss is:  0.0525243\n",
      "iter  224900  time  106.310212\n",
      "train loss is:  0.0605554\n",
      "iter  225000  time  112.531057\n",
      "train loss is:  0.0329165\n",
      "iter  225100  time  114.599428\n",
      "train loss is:  0.0666995\n",
      "iter  225200  time  114.158435\n",
      "train loss is:  0.0611845\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4,64,97,129]\n\t [[Node: gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/AddN_1, gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Shape, FSRCNN/concat3)]]\n\nCaused by op u'gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Conv2DBackpropFilter', defined at:\n  File \"/home/sensetime/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/sensetime/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-00e46ef4a9f6>\", line 1, in <module>\n    myNet = Model()\n  File \"<ipython-input-6-42dc6636c5aa>\", line 57, in __init__\n    grads2 = tf.gradients(self.loss_train, update_vars2)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 46, in _Conv2DBackpropInputGrad\n    op.get_attr(\"data_format\")),\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 450, in conv2d_backprop_filter\n    data_format=data_format, name=name)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'FSRCNN/deconv2/conv2d_transpose', defined at:\n  File \"/home/sensetime/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-7-00e46ef4a9f6>\", line 1, in <module>\n    myNet = Model()\n  File \"<ipython-input-6-42dc6636c5aa>\", line 20, in __init__\n    predict_64, predict_32, predict_16, predict_8, predict_4 = self.FLOWNETS(self.inputs)\n  File \"<ipython-input-6-42dc6636c5aa>\", line 103, in FLOWNETS\n    deconv2 = deconv(concat3, 64, [5, 5], 2, 'SAME', scope='deconv2')\n  File \"<ipython-input-5-b11479c28f8e>\", line 15, in deconv\n    conv_val = slim.conv2d_transpose(inputs, output_num, ks, stride, padding, scope=scope, activation_fn=None, weights_initializer=initializer)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 181, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1136, in convolution2d_transpose\n    outputs = layer.apply(inputs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 320, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 290, in __call__\n    outputs = self.call(inputs, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/convolutional.py\", line 1102, in call\n    data_format=utils.convert_data_format(self.data_format, ndim=4))\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1104, in conv2d_transpose\n    name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,64,97,129]\n\t [[Node: gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/AddN_1, gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Shape, FSRCNN/concat3)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-00e46ef4a9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmyNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmyNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-42dc6636c5aa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./result/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_pred.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_loss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate_mult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_rate_mult\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4,64,97,129]\n\t [[Node: gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/AddN_1, gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Shape, FSRCNN/concat3)]]\n\nCaused by op u'gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Conv2DBackpropFilter', defined at:\n  File \"/home/sensetime/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/sensetime/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-00e46ef4a9f6>\", line 1, in <module>\n    myNet = Model()\n  File \"<ipython-input-6-42dc6636c5aa>\", line 57, in __init__\n    grads2 = tf.gradients(self.loss_train, update_vars2)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 46, in _Conv2DBackpropInputGrad\n    op.get_attr(\"data_format\")),\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 450, in conv2d_backprop_filter\n    data_format=data_format, name=name)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'FSRCNN/deconv2/conv2d_transpose', defined at:\n  File \"/home/sensetime/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 19 identical lines from previous traceback]\n  File \"<ipython-input-7-00e46ef4a9f6>\", line 1, in <module>\n    myNet = Model()\n  File \"<ipython-input-6-42dc6636c5aa>\", line 20, in __init__\n    predict_64, predict_32, predict_16, predict_8, predict_4 = self.FLOWNETS(self.inputs)\n  File \"<ipython-input-6-42dc6636c5aa>\", line 103, in FLOWNETS\n    deconv2 = deconv(concat3, 64, [5, 5], 2, 'SAME', scope='deconv2')\n  File \"<ipython-input-5-b11479c28f8e>\", line 15, in deconv\n    conv_val = slim.conv2d_transpose(inputs, output_num, ks, stride, padding, scope=scope, activation_fn=None, weights_initializer=initializer)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 181, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1136, in convolution2d_transpose\n    outputs = layer.apply(inputs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 320, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 290, in __call__\n    outputs = self.call(inputs, **kwargs)\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/convolutional.py\", line 1102, in call\n    data_format=utils.convert_data_format(self.data_format, ndim=4))\n  File \"/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1104, in conv2d_transpose\n    name=name)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[4,64,97,129]\n\t [[Node: gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients_1/AddN_1, gradients_1/FSRCNN/deconv2/conv2d_transpose_grad/Shape, FSRCNN/concat3)]]\n"
     ]
    }
   ],
   "source": [
    "myNet = Model()\n",
    "myNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
