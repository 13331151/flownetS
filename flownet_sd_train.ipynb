{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import scipy.io as sio   \n",
    "# gpu_id = 0\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "config = Config()\n",
    "config.input_height = 384\n",
    "config.input_width = 512\n",
    "config.input_channel = 6\n",
    "config.label_height = 384\n",
    "config.label_width = 512\n",
    "config.label_channel = 2\n",
    "\n",
    "config.patch_size = 320\n",
    "config.gradient_clip = 0.01\n",
    "\n",
    "config.batch_size = 4\n",
    "config.num_batches = 1200000\n",
    "config.learning_rate = 1e-3\n",
    "config.min_queue_examples = 20\n",
    "config.num_threads = 16\n",
    "config.EPS = 1e-8\n",
    "\n",
    "config.train_data_path = '/data/kitti/FlyingChairs_release/train_tfrecord'\n",
    "config.test_data_path = '/data/kitti/FlyingChairs_release/test_tfrecord'\n",
    "config.finetune_data_path = './finetune_tfrecord'\n",
    "config.isFinetune = False\n",
    "\n",
    "if config.isFinetune:\n",
    "    config.learning_rate *= .5\n",
    "\n",
    "config.save_dir ='./model_sd/'\n",
    "config.log_dir = './log_sd'\n",
    "config.result_dir = './result_sd'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(config.log_dir)\n",
    "except:\n",
    "    if not config.isFinetune:\n",
    "        os.system(\"rm \"+config.log_dir+\"/*\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(config.save_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(config.result_dir)\n",
    "except:\n",
    "    os.system(\"rm \"+config.result_dir+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename, shuffle=False):\n",
    "    \"\"\" Return tensor to read from TFRecord \"\"\"\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'input' : tf.FixedLenFeature([], tf.string),\n",
    "                                           'label' : tf.FixedLenFeature([], tf.string)\n",
    "                                       })\n",
    "    \n",
    "    img = tf.decode_raw(features['input'], tf.uint8)\n",
    "    img = tf.reshape(img, [config.input_height, config.input_width, config.input_channel])\n",
    "    img = tf.random_crop(img, [config.patch_size, config.patch_size, config.input_channel], seed=0)\n",
    "    img = tf.to_float(img)\n",
    "    img = (img-127.)/255.\n",
    "    \n",
    "    dep = tf.decode_raw(features['label'], tf.float32)\n",
    "    dep = tf.reshape(dep, [config.label_height, config.label_width, config.label_channel])\n",
    "    dep = tf.random_crop(dep, [config.patch_size, config.patch_size, config.label_channel], seed=0)\n",
    "    dep = tf.to_float(dep)\n",
    "\n",
    "    \n",
    "    return _generate_image_and_label_batch(img, dep, config.min_queue_examples,\n",
    "                                           config.batch_size, shuffle = shuffle, num_threads = config.num_threads)\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle, num_threads):\n",
    "    num_preprocess_threads = num_threads\n",
    "    if shuffle:\n",
    "        images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads, capacity=min_queue_examples + 3 * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, labels = tf.train.batch([image, label], batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads, capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leakyrelu(inputs, alpha=0.1):\n",
    "    return tf.maximum(alpha*inputs, inputs)\n",
    "\n",
    "def msra(ks, output_num):\n",
    "    return tf.truncated_normal_initializer(mean=0, stddev=np.sqrt(2./(ks[0]*ks[1]*output_num)))\n",
    "\n",
    "def conv(inputs, output_num, ks, stride, padding, scope, alpha=0.1):\n",
    "    initializer =  msra(ks, output_num)\n",
    "    conv_val = slim.conv2d(inputs, output_num, ks, stride, padding, scope=scope, activation_fn=None, weights_initializer=initializer)\n",
    "    conv_val = leakyrelu(conv_val, alpha=alpha)\n",
    "    return conv_val\n",
    "\n",
    "def deconv(inputs, output_num, ks, stride, padding, scope, alpha=0.1):\n",
    "    initializer = msra(ks, output_num)\n",
    "    conv_val = slim.conv2d_transpose(inputs, output_num, ks, stride, padding, scope=scope, activation_fn=None, weights_initializer=initializer)\n",
    "    conv_val = leakyrelu(conv_val, alpha=alpha)\n",
    "    return conv_val\n",
    "\n",
    "def epe_loss(predict, labels):\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum((predict-labels)**2, axis=3)+config.EPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "#         \n",
    "        tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "        tfconfig.gpu_options.allow_growth=True\n",
    "        self.sess = tf.Session(config = tfconfig)\n",
    "        \n",
    "        self.inputs, self.labels = read_and_decode(config.train_data_path, shuffle=True)\n",
    "        self.test_inputs, self.test_labels = read_and_decode(config.test_data_path, shuffle=False)\n",
    "        self.labels_small_64 = tf.image.resize_images(self.labels, [config.patch_size/64, config.patch_size/64])\n",
    "        self.labels_small_32 = tf.image.resize_images(self.labels, [config.patch_size/32, config.patch_size/32])\n",
    "        self.labels_small_16 = tf.image.resize_images(self.labels, [config.patch_size/16, config.patch_size/16])\n",
    "        self.labels_small_8 = tf.image.resize_images(self.labels, [config.patch_size/8, config.patch_size/8])\n",
    "        self.labels_small_4 = tf.image.resize_images(self.labels, [config.patch_size/4, config.patch_size/4])\n",
    "        \n",
    "        self.summary_inputs_0 = tf.summary.image('train/input/image1', self.inputs[:, :, :, :3], max_outputs=1)\n",
    "        self.summary_inputs_1 = tf.summary.image('train/input/image2', self.inputs[:, :, :, 3:], max_outputs=1)\n",
    "        self.summary_labels = tf.summary.image('train/labels', self.labels[:, :, :, :1], max_outputs=1)\n",
    "        self.summary_labels_small_4 = tf.summary.image('train/labels_small_4', self.labels_small_4[:, :, :, :1], max_outputs=1)\n",
    "        \n",
    "        predict_64, predict_32, predict_16, predict_8, predict_4 = self.FLOWNETS(self.inputs)\n",
    "        self.summary_outputs = tf.summary.image('train/predict_4', predict_4[:, :, :, :1], max_outputs=1)\n",
    "        \n",
    "        self.predict_4 = predict_4\n",
    "        \n",
    "#         loss_train_4 = tf.losses.absolute_difference(predict_4, self.labels_small_4)\n",
    "#         loss_train_8 = tf.losses.absolute_difference(predict_8, self.labels_small_8)\n",
    "#         loss_train_16 = tf.losses.absolute_difference(predict_16, self.labels_small_16)\n",
    "#         loss_train_32 = tf.losses.absolute_difference(predict_32, self.labels_small_32)\n",
    "#         loss_train_64 = tf.losses.absolute_difference(predict_64, self.labels_small_64)\n",
    "        loss_train_4 = epe_loss(predict_4, self.labels_small_4)\n",
    "        loss_train_8 = epe_loss(predict_8, self.labels_small_8)\n",
    "        loss_train_16 = epe_loss(predict_16, self.labels_small_16)\n",
    "        loss_train_32 = epe_loss(predict_32, self.labels_small_32)\n",
    "        loss_train_64 = epe_loss(predict_64, self.labels_small_64)\n",
    "        \n",
    "        self.loss_train = 0.005*loss_train_4+0.01*loss_train_8+0.02*loss_train_16+0.08*loss_train_32+0.32*loss_train_64\n",
    "        self.summary_loss_train = tf.summary.scalar('train/loss', self.loss_train)\n",
    "        \n",
    "        update_vars = tf.global_variables()\n",
    "        print \"All variables \", [v.name for v in update_vars]\n",
    "        update_vars1 = []\n",
    "        update_vars2 = []\n",
    "        for var in update_vars:\n",
    "            if 'bias' in var.name or 'deconv' in var.name:\n",
    "                update_vars2.append(var)\n",
    "            else:\n",
    "                update_vars1.append(var)\n",
    "        print \"Learning rate = \", config.learning_rate, \" vars: \", [v.name for v in update_vars1]\n",
    "        print \"Learning rate = \", config.learning_rate*.1, \" vars: \", [v.name for v in update_vars2]\n",
    "        \n",
    "        \n",
    "        self.learning_rate_mult = tf.placeholder(tf.float32)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate_mult*config.learning_rate)\n",
    "        \n",
    "        grads1 = tf.gradients(self.loss_train, update_vars1)\n",
    "        grads2 = tf.gradients(self.loss_train, update_vars2)\n",
    "        grads2 = [v*.1 for v in grads2]\n",
    "        \n",
    "        if config.gradient_clip > 0:\n",
    "            grads1 = [tf.clip_by_value(v, -config.gradient_clip, config.gradient_clip) for v in grads1]\n",
    "            grads2 = [tf.clip_by_value(v, -config.gradient_clip, config.gradient_clip) for v in grads2]\n",
    "        \n",
    "        train_op1 = opt.apply_gradients(zip(grads1, update_vars1))\n",
    "        train_op2 = opt.apply_gradients(zip(grads2, update_vars2))\n",
    "        self.opt = tf.group(train_op1, train_op2)\n",
    "        \n",
    "        self.merge_summary_train = tf.summary.merge([self.summary_loss_train])\n",
    "        \n",
    "    \n",
    "    \n",
    "            \n",
    "    def FLOWNETS(self, inputs, reuse = False):\n",
    "        with tf.variable_scope('FSRCNN') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "            \n",
    "            # shrink part\n",
    "            conv0 = conv(inputs, 64, [3, 3], 1, 'SAME', scope='conv0')\n",
    "            conv1 = conv(conv0, 64, [3, 3], 2, 'SAME', scope='conv1')\n",
    "            conv1_1 = conv(conv1, 128, [3, 3], 1, 'SAME', scope='conv1_1')\n",
    "            conv2 = conv(conv1_1, 128, [3, 3], 2, 'SAME', scope='conv2')\n",
    "            conv2_1 = conv(conv2, 128, [3, 3], 1, 'SAME', scope='conv2_1')\n",
    "            conv3 = conv(conv2_1, 256, [3, 3], 2, 'SAME', scope='conv3')\n",
    "            conv3_1 = conv(conv3, 256, [3, 3], 1, 'SAME', scope='conv3_1')\n",
    "            conv4 = conv(conv3_1, 512, [3, 3], 2, 'SAME', scope='conv4')\n",
    "            conv4_1 = conv(conv4, 512, [3, 3], 1, 'SAME', scope='conv4_1')\n",
    "            conv5 = conv(conv4_1, 512, [3, 3], 2, 'SAME', scope='conv5')\n",
    "            conv5_1 = conv(conv5, 512, [3, 3], 1, 'SAME', scope='conv5_1')\n",
    "            conv6 = conv(conv5_1, 1024, [3, 3], 2, 'SAME', scope='conv6')\n",
    "            conv6_1 = conv(conv6, 1024, [3, 3], 1, 'SAME', scope='conv6_1')\n",
    "            # 6 * 8 flow\n",
    "            predict6 = conv(conv6_1, 2, [3, 3], 1, 'SAME', scope='predict6')  #0.32\n",
    "            # 12 * 16 flow\n",
    "            deconv5 = deconv(conv6_1, 512, [4, 4], 2, 'SAME', scope='deconv5')\n",
    "            deconvflow6 = deconv(predict6, 2, [4, 4], 2, 'SAME', scope='deconvflow6')\n",
    "            concat5 = tf.concat([deconv5, conv5_1, deconvflow6], 3, name='concat5')\n",
    "            interconv5 = conv(concat5, 512, [3, 3], 1, 'SAME', scope='interconv5')  # ????不用非线性？\n",
    "            predict5 = conv(interconv5, 2, [3, 3], 1, 'SAME', scope='predict5')   #0.08\n",
    "            # 24 * 32 flow\n",
    "            deconv4 = deconv(concat5, 256, [4, 4], 2, 'SAME', scope='deconv4')\n",
    "            deconvflow5 = deconv(predict5, 2, [4, 4], 2, 'SAME', scope='deconvflow5')\n",
    "            concat4 = tf.concat([deconv4, conv4_1, deconvflow5], 3, name='concat4')\n",
    "            interconv4 = conv(concat4, 256, [3, 3], 1, 'SAME', scope='interconv4')\n",
    "            predict4 = conv(interconv4, 2, [3, 3], 1, 'SAME', scope='predict4')  #0.02\n",
    "            # 48 * 64 flow\n",
    "            deconv3 = deconv(concat4, 128, [4, 4], 2, 'SAME', scope='deconv3')\n",
    "            deconvflow4 = deconv(predict4, 2, [4, 4], 2, 'SAME', scope='deconvflow4')\n",
    "            concat3 = tf.concat([deconv3, conv3_1, deconvflow4], 3, name='concat3')\n",
    "            interconv3 = conv(concat3, 128, [3, 3], 1, 'SAME', scope='interconv3')\n",
    "            predict3 = conv(interconv3, 2, [3, 3], 1, 'SAME', scope='predict3')  #0.01\n",
    "            # 96 * 128 flow\n",
    "            deconv2 = deconv(concat3, 64, [4, 4], 2, 'SAME', scope='deconv2')\n",
    "            deconvflow3 = deconv(predict3, 2, [4, 4], 2, 'SAME', scope='deconvflow3')\n",
    "            concat2 = tf.concat([deconv2, conv2, deconvflow3], 3, name='concat2')\n",
    "            interconv2 = conv(concat2, 64, [3, 3], 1, 'SAME', scope='interconv2')\n",
    "            predict2 = conv(interconv2, 2, [3, 3], 1, 'SAME', scope='predict2') #0.005\n",
    "\n",
    "            return predict6, predict5, predict4, predict3, predict2\n",
    "    \n",
    "    def test(self):\n",
    "        writer = tf.summary.FileWriter(config.log_dir, tf.get_default_graph())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        self.sess.run(init_op)\n",
    "        \n",
    "        ckpt = tf.train.get_checkpoint_state(config.save_dir)\n",
    "        saver.restore(self.sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=self.sess, coord=coord)\n",
    "        \n",
    "        time_ = time.clock()\n",
    "        \n",
    "        input_data = np.zeros((config.batch_size, config.input_height, config.input_width, config.input_channel))\n",
    "        input_label = np.zeros((config.batch_size, config.label_height, config.label_width, config.label_channel))\n",
    "    \n",
    "        \n",
    "        learning_rate_mult = 1.\n",
    "        \n",
    "        \n",
    "        predict_ = self.sess.run(self.predict_4[:, :, :, 0], feed_dict={self.inputs:input_data, self.labels:input_label, self.learning_rate_mult:learning_rate_mult})\n",
    "        \n",
    "        for i in xrange(predict_.shape[0]):\n",
    "            cv2.imwrite('./result/test/'+str(i)+'_pred.jpg', np.clip(predict_*20, 0, 255).astype(uint8))\n",
    "                \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "        writer.close()\n",
    "\n",
    "  \n",
    "    def train(self):\n",
    "        writer = tf.summary.FileWriter(config.log_dir, tf.get_default_graph())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        self.sess.run(init_op)\n",
    "        \n",
    "        if config.isFinetune:\n",
    "            ckpt = tf.train.get_checkpoint_state(config.save_dir)\n",
    "            saver.restore(self.sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=self.sess, coord=coord)\n",
    "        \n",
    "        time_ = time.clock()\n",
    "        \n",
    "#         input_data = np.zeros((config.batch_size, config.input_height, config.input_width, config.input_channel))\n",
    "#         input_label = np.zeros((config.batch_size, config.label_height, config.label_width, config.label_channel))\n",
    "    \n",
    "        \n",
    "        learning_rate_mult = 1.\n",
    "        for t in range(0, config.num_batches):\n",
    "            if t % 100 == 0:\n",
    "                print \"iter \", t, \" time \", time.clock()-time_\n",
    "                time_ = time.clock()\n",
    "            \n",
    "            if t > 2000000 and (t % 1000000 == 0):\n",
    "                learning_rate_mult/=2\n",
    "\n",
    "#             _, merge_summary = \\\n",
    "#                 self.sess.run([self.opt, self.merge_summary_train], feed_dict={self.inputs:input_data, self.labels:input_label, self.learning_rate:config.learning_rate})\n",
    "            if t % 1000 == 0:\n",
    "                _, merge_summary, loss, label_, predict_ = \\\n",
    "                   self.sess.run([self.opt, self.merge_summary_train, self.loss_train, self.labels_small_4[0, :, :, 0], self.predict_4[0, :, :, 0]], feed_dict={self.learning_rate_mult:learning_rate_mult})\n",
    "                cv2.imwrite('./result/'+str(t)+'_label.jpg', np.clip(label_*20, 0, 255).astype(uint8))\n",
    "                cv2.imwrite('./result/'+str(t)+'_pred.jpg', np.clip(predict_*20, 0, 255).astype(uint8))\n",
    "            else:\n",
    "                _, merge_summary, loss = \\\n",
    "                    self.sess.run([self.opt, self.summary_loss_train, self.loss_train], feed_dict={self.learning_rate_mult:learning_rate_mult})\n",
    "            \n",
    "            if t%100 == 0:\n",
    "                print \"train loss is: \", loss\n",
    "                writer.add_summary(merge_summary, t)\n",
    "                \n",
    "           \n",
    "            if t%10000 == 0:\n",
    "                saver.save(self.sess, config.save_dir, global_step=t)\n",
    "                \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "        writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All variables  [u'FSRCNN/conv0/weights:0', u'FSRCNN/conv0/biases:0', u'FSRCNN/conv1/weights:0', u'FSRCNN/conv1/biases:0', u'FSRCNN/conv1_1/weights:0', u'FSRCNN/conv1_1/biases:0', u'FSRCNN/conv2/weights:0', u'FSRCNN/conv2/biases:0', u'FSRCNN/conv2_1/weights:0', u'FSRCNN/conv2_1/biases:0', u'FSRCNN/conv3/weights:0', u'FSRCNN/conv3/biases:0', u'FSRCNN/conv3_1/weights:0', u'FSRCNN/conv3_1/biases:0', u'FSRCNN/conv4/weights:0', u'FSRCNN/conv4/biases:0', u'FSRCNN/conv4_1/weights:0', u'FSRCNN/conv4_1/biases:0', u'FSRCNN/conv5/weights:0', u'FSRCNN/conv5/biases:0', u'FSRCNN/conv5_1/weights:0', u'FSRCNN/conv5_1/biases:0', u'FSRCNN/conv6/weights:0', u'FSRCNN/conv6/biases:0', u'FSRCNN/conv6_1/weights:0', u'FSRCNN/conv6_1/biases:0', u'FSRCNN/predict6/weights:0', u'FSRCNN/predict6/biases:0', u'FSRCNN/deconv5/weights:0', u'FSRCNN/deconv5/biases:0', u'FSRCNN/deconvflow6/weights:0', u'FSRCNN/deconvflow6/biases:0', u'FSRCNN/interconv5/weights:0', u'FSRCNN/interconv5/biases:0', u'FSRCNN/predict5/weights:0', u'FSRCNN/predict5/biases:0', u'FSRCNN/deconv4/weights:0', u'FSRCNN/deconv4/biases:0', u'FSRCNN/deconvflow5/weights:0', u'FSRCNN/deconvflow5/biases:0', u'FSRCNN/interconv4/weights:0', u'FSRCNN/interconv4/biases:0', u'FSRCNN/predict4/weights:0', u'FSRCNN/predict4/biases:0', u'FSRCNN/deconv3/weights:0', u'FSRCNN/deconv3/biases:0', u'FSRCNN/deconvflow4/weights:0', u'FSRCNN/deconvflow4/biases:0', u'FSRCNN/interconv3/weights:0', u'FSRCNN/interconv3/biases:0', u'FSRCNN/predict3/weights:0', u'FSRCNN/predict3/biases:0', u'FSRCNN/deconv2/weights:0', u'FSRCNN/deconv2/biases:0', u'FSRCNN/deconvflow3/weights:0', u'FSRCNN/deconvflow3/biases:0', u'FSRCNN/interconv2/weights:0', u'FSRCNN/interconv2/biases:0', u'FSRCNN/predict2/weights:0', u'FSRCNN/predict2/biases:0']\n",
      "Learning rate =  0.001  vars:  [u'FSRCNN/conv0/weights:0', u'FSRCNN/conv1/weights:0', u'FSRCNN/conv1_1/weights:0', u'FSRCNN/conv2/weights:0', u'FSRCNN/conv2_1/weights:0', u'FSRCNN/conv3/weights:0', u'FSRCNN/conv3_1/weights:0', u'FSRCNN/conv4/weights:0', u'FSRCNN/conv4_1/weights:0', u'FSRCNN/conv5/weights:0', u'FSRCNN/conv5_1/weights:0', u'FSRCNN/conv6/weights:0', u'FSRCNN/conv6_1/weights:0', u'FSRCNN/predict6/weights:0', u'FSRCNN/interconv5/weights:0', u'FSRCNN/predict5/weights:0', u'FSRCNN/interconv4/weights:0', u'FSRCNN/predict4/weights:0', u'FSRCNN/interconv3/weights:0', u'FSRCNN/predict3/weights:0', u'FSRCNN/interconv2/weights:0', u'FSRCNN/predict2/weights:0']\n",
      "Learning rate =  0.0001  vars:  [u'FSRCNN/conv0/biases:0', u'FSRCNN/conv1/biases:0', u'FSRCNN/conv1_1/biases:0', u'FSRCNN/conv2/biases:0', u'FSRCNN/conv2_1/biases:0', u'FSRCNN/conv3/biases:0', u'FSRCNN/conv3_1/biases:0', u'FSRCNN/conv4/biases:0', u'FSRCNN/conv4_1/biases:0', u'FSRCNN/conv5/biases:0', u'FSRCNN/conv5_1/biases:0', u'FSRCNN/conv6/biases:0', u'FSRCNN/conv6_1/biases:0', u'FSRCNN/predict6/biases:0', u'FSRCNN/deconv5/weights:0', u'FSRCNN/deconv5/biases:0', u'FSRCNN/deconvflow6/weights:0', u'FSRCNN/deconvflow6/biases:0', u'FSRCNN/interconv5/biases:0', u'FSRCNN/predict5/biases:0', u'FSRCNN/deconv4/weights:0', u'FSRCNN/deconv4/biases:0', u'FSRCNN/deconvflow5/weights:0', u'FSRCNN/deconvflow5/biases:0', u'FSRCNN/interconv4/biases:0', u'FSRCNN/predict4/biases:0', u'FSRCNN/deconv3/weights:0', u'FSRCNN/deconv3/biases:0', u'FSRCNN/deconvflow4/weights:0', u'FSRCNN/deconvflow4/biases:0', u'FSRCNN/interconv3/biases:0', u'FSRCNN/predict3/biases:0', u'FSRCNN/deconv2/weights:0', u'FSRCNN/deconv2/biases:0', u'FSRCNN/deconvflow3/weights:0', u'FSRCNN/deconvflow3/biases:0', u'FSRCNN/interconv2/biases:0', u'FSRCNN/predict2/biases:0']\n",
      "iter  0  time  0.024374\n",
      "train loss is:  7.70606\n",
      "iter  100  time  62.267457\n",
      "train loss is:  6.68921\n",
      "iter  200  time  41.112946\n",
      "train loss is:  1988.21\n",
      "iter  300  time  41.696579\n",
      "train loss is:  382.592\n",
      "iter  400  time  41.536752\n",
      "train loss is:  68.2865\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-00e46ef4a9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmyNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmyNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-91e32f9ffc6f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./result/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_pred.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_loss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate_mult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_rate_mult\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sensetime/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myNet = Model()\n",
    "myNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
